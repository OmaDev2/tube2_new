import streamlit as st
import os
import uuid
from pathlib import Path
from datetime import datetime
import json
import math
import asyncio
from moviepy.editor import AudioFileClip

# Importar funciones necesarias
try:
    from utils.config import load_config
    from utils.ai_services import list_openai_models, list_gemini_models, list_ollama_models
    from pages.prompts_manager_page import list_prompts
    from pages.efectos_ui import show_effects_ui
    from pages.overlays_ui import show_overlays_ui
    from utils.subtitle_utils import get_available_fonts
    import edge_tts
except ImportError as e:
    st.error(f"Error importando dependencias: {e}")

def show_batch_processor():
    st.title("ðŸš€ Procesador por Lotes de Videos")
    
    st.info("""
    **Automatiza completamente** la creaciÃ³n de videos desde tÃ­tulo + contexto:
    
    ðŸ“ GuiÃ³n â†’ ðŸ”Š Audio â†’ ðŸŽ¯ TranscripciÃ³n â†’ ðŸŽ¬ Escenas â†’ ðŸ–¼ï¸ ImÃ¡genes â†’ ðŸŽ¥ Video â†’ ðŸ“ SubtÃ­tulos
    """)
    
    st.markdown("---")
    
    # Cargar configuraciÃ³n de la aplicaciÃ³n
    try:
        app_config = load_config()
    except:
        app_config = {"ai": {"default_models": {}}}
    
    # ===== SECCIÃ“N 1: GESTIÃ“N DE PROYECTOS =====
    st.header("1. ðŸ“‹ GestiÃ³n de Proyectos por Lotes")
    
    # AÃ±adir nuevos proyectos
    st.subheader("âž• AÃ±adir Nuevo Proyecto")
    
    # OpciÃ³n para elegir tipo de guiÃ³n (fuera del formulario para que sea reactiva)
    script_type = st.radio(
        "ðŸ“œ Tipo de guiÃ³n:",
        ["ðŸ¤– Generar automÃ¡ticamente con IA", "âœï¸ Usar guiÃ³n manual"],
        index=1,  # Por defecto seleccionar guiÃ³n manual
        help="Elige si quieres que la IA genere el guiÃ³n o usar tu propio guiÃ³n",
        key="script_type_selector"
    )
    
    with st.form("add_project"):
        col1, col2 = st.columns(2)
        
        with col1:
            titulo = st.text_input("ðŸ“ TÃ­tulo del proyecto", help="Ej: CÃ³mo hacer pan casero")
            contexto = st.text_area("ðŸ“– Contexto/DescripciÃ³n", help="InformaciÃ³n adicional sobre el contenido del video")
        
        with col2:
            guion_manual = None
            if script_type == "âœï¸ Usar guiÃ³n manual":
                guion_manual = st.text_area(
                    "ðŸ“ Escribe tu guiÃ³n:",
                    height=100,
                    help="Escribe aquÃ­ el guiÃ³n completo que quieres usar para el video",
                    placeholder="Ejemplo:\n\nHola y bienvenidos a mi canal...\n\nEn el video de hoy vamos a aprender...\n\nÂ¡No olviden suscribirse!"
                )
            else:
                st.info("ðŸ¤– El guiÃ³n se generarÃ¡ automÃ¡ticamente con IA usando el tÃ­tulo y contexto proporcionados.")
        
        if st.form_submit_button("âœ… AÃ±adir al Batch", use_container_width=True):
            if titulo and contexto:
                # Validar guiÃ³n manual si es necesario
                if script_type == "âœï¸ Usar guiÃ³n manual" and not guion_manual:
                    st.error("âš ï¸ Por favor, escribe el guiÃ³n manual.")
                else:
                    if "batch_projects" not in st.session_state:
                        st.session_state.batch_projects = []
                    
                    nuevo_proyecto = {
                        "titulo": titulo,
                        "contexto": contexto,
                        "script_type": script_type,
                        "guion_manual": guion_manual if script_type == "âœï¸ Usar guiÃ³n manual" else None,
                        "id": str(uuid.uuid4())[:8],
                        "fecha_aÃ±adido": datetime.now().isoformat()
                    }
                    
                    st.session_state.batch_projects.append(nuevo_proyecto)
                    script_info = "con guiÃ³n manual" if script_type == "âœï¸ Usar guiÃ³n manual" else "con IA"
                    st.success(f"âœ… Proyecto '{titulo}' aÃ±adido al batch {script_info}!")
                    st.rerun()
            else:
                st.error("âš ï¸ Por favor, completa el tÃ­tulo y contexto.")
    
    # Mostrar proyectos existentes
    if "batch_projects" in st.session_state and st.session_state.batch_projects:
        st.subheader(f"ðŸ“Š Proyectos en cola ({len(st.session_state.batch_projects)})")
        
        # Mostrar cada proyecto
        for i, proyecto in enumerate(st.session_state.batch_projects):
            # Icono segÃºn el tipo de guiÃ³n
            icon = "âœï¸" if proyecto.get("script_type") == "âœï¸ Usar guiÃ³n manual" else "ðŸ¤–"
            script_label = "Manual" if proyecto.get("script_type") == "âœï¸ Usar guiÃ³n manual" else "IA"
            
            # Detectar si viene del CMS
            is_from_cms = "cms_publicacion_id" in proyecto
            cms_icon = " ðŸ“š" if is_from_cms else ""
            
            col1, col2, col3 = st.columns([3, 1, 1])
            
            with col1:
                st.write(f"{icon} **{proyecto['titulo']}** ({script_label}){cms_icon}")
                if is_from_cms:
                    st.caption(f"ðŸ“º **Canal:** {proyecto.get('cms_canal', 'N/A')} | ðŸ†” **Pub ID:** {proyecto.get('cms_publicacion_id')}")
                st.caption(f"ðŸ“– {proyecto['contexto'][:100]}{'...' if len(proyecto['contexto']) > 100 else ''}")
                
                # Mostrar preview del guiÃ³n manual si existe
                if proyecto.get("guion_manual"):
                    if st.button("ðŸ‘€ Ver/Ocultar GuiÃ³n", key=f"toggle_script_{proyecto['id']}"):
                        show_key = f"show_script_{proyecto['id']}"
                        st.session_state[show_key] = not st.session_state.get(show_key, False)
                    
                    if st.session_state.get(f"show_script_{proyecto['id']}", False):
                        st.text_area(
                            "ðŸ“ GuiÃ³n completo:",
                            value=proyecto["guion_manual"],
                            height=100,
                            disabled=True,
                            key=f"preview_script_{proyecto['id']}"
                        )
            
            with col2:
                if st.button("âœï¸ Editar", key=f"edit_{proyecto['id']}"):
                    st.session_state[f"editing_{proyecto['id']}"] = True
                    st.rerun()
            
            with col3:
                if st.button("ðŸ—‘ï¸ Eliminar", key=f"delete_{proyecto['id']}"):
                    st.session_state.batch_projects.pop(i)
                    st.success(f"âœ… Proyecto '{proyecto['titulo']}' eliminado!")
                    st.rerun()
            
            # Formulario de ediciÃ³n inline
            if st.session_state.get(f"editing_{proyecto['id']}", False):
                st.markdown("---")
                with st.form(f"edit_project_{proyecto['id']}"):
                    st.subheader("âœï¸ Editar Proyecto")
                    
                    edit_col1, edit_col2 = st.columns(2)
                    with edit_col1:
                        nuevo_titulo = st.text_input("TÃ­tulo", value=proyecto['titulo'])
                        nuevo_contexto = st.text_area("Contexto", value=proyecto['contexto'])
                    
                    with edit_col2:
                        nuevo_script_type = st.radio(
                            "Tipo de guiÃ³n:",
                            ["ðŸ¤– Generar automÃ¡ticamente con IA", "âœï¸ Usar guiÃ³n manual"],
                            index=1 if proyecto.get("script_type") == "âœï¸ Usar guiÃ³n manual" else 0
                        )
                        
                        nuevo_guion_manual = None
                        if nuevo_script_type == "âœï¸ Usar guiÃ³n manual":
                            nuevo_guion_manual = st.text_area(
                                "GuiÃ³n manual:",
                                value=proyecto.get("guion_manual", ""),
                                height=100
                            )
                    
                    col_edit1, col_edit2 = st.columns(2)
                    with col_edit1:
                        if st.form_submit_button("ðŸ’¾ Guardar cambios"):
                            proyecto.update({
                                "titulo": nuevo_titulo,
                                "contexto": nuevo_contexto,
                                "script_type": nuevo_script_type,
                                "guion_manual": nuevo_guion_manual if nuevo_script_type == "âœï¸ Usar guiÃ³n manual" else None
                            })
                            st.session_state[f"editing_{proyecto['id']}"] = False
                            st.success("âœ… Proyecto actualizado!")
                            st.rerun()
                    
                    with col_edit2:
                        if st.form_submit_button("âŒ Cancelar"):
                            st.session_state[f"editing_{proyecto['id']}"] = False
                            st.rerun()
            
            st.markdown("---")
        
        # BotÃ³n para limpiar todos los proyectos
        if st.button("ðŸ§¹ Limpiar toda la cola", type="secondary"):
            st.session_state.batch_projects = []
            st.success("âœ… Cola de proyectos limpiada!")
            st.rerun()
    else:
        st.info("ðŸ“ No hay proyectos en la cola. AÃ±ade algunos proyectos para comenzar.")
    
    st.markdown("---")
    
    # ===== SECCIÃ“N 2: RE-PROCESAR PROYECTOS EXISTENTES =====
    st.header("2. ðŸ”§ Re-procesar o Reparar Proyecto Existente")
    
    # FunciÃ³n para obtener la lista de proyectos existentes
    def get_existing_projects(projects_dir="projects"):
        projects_path = Path(projects_dir)
        if not projects_path.exists():
            return []
        return [d.name for d in projects_path.iterdir() if d.is_dir() and (d / "project_info.json").exists()]
    
    # Obtener la lista de proyectos
    projects_dir = app_config.get("video_generation", {}).get("paths", {}).get("projects_dir", "projects")
    existing_projects = get_existing_projects(projects_dir)
    
    if not existing_projects:
        st.warning("ðŸ“ No se encontraron proyectos existentes para re-procesar.")
    else:
        # Crear un selector para que el usuario elija el proyecto
        selected_project_id = st.selectbox(
            "ðŸŽ¯ Selecciona un proyecto para re-procesar",
            options=existing_projects,
            index=None,
            placeholder="Elige un proyecto...",
            help="Selecciona un proyecto existente para reanudar su procesamiento desde donde se quedÃ³"
        )
        
        if selected_project_id:
            # Cargar informaciÃ³n del proyecto seleccionado
            project_dir = Path(projects_dir) / selected_project_id
            project_info_path = project_dir / "project_info.json"
            
            try:
                with open(project_info_path, 'r', encoding='utf-8') as f:
                    project_info = json.load(f)
                
                # Mostrar informaciÃ³n del proyecto
                st.subheader(f"ðŸ“‹ InformaciÃ³n del Proyecto: {selected_project_id}")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**TÃ­tulo:** {project_info.get('title', 'N/A')}")
                    st.write(f"**Estado:** {project_info.get('status', 'N/A')}")
                    st.write(f"**Fecha:** {project_info.get('created_at', 'N/A')}")
                
                with col2:
                    st.write(f"**DuraciÃ³n Audio:** {project_info.get('audio_duration', 0):.1f}s")
                    st.write(f"**ImÃ¡genes:** {len(project_info.get('image_paths', []))}")
                    st.write(f"**Escenas:** {len(project_info.get('scenes', [])) if project_info.get('scenes') else 'N/A'}")
                
                # Mostrar estado detallado
                status = project_info.get('status', 'unknown')
                status_icon = {
                    'script_ok': 'ðŸ“',
                    'audio_ok': 'ðŸ”Š', 
                    'transcription_ok': 'ðŸŽ¯',
                    'scenes_ok': 'ðŸŽ¬',
                    'images_ok': 'ðŸ–¼ï¸',
                    'video_ok': 'ðŸŽ¥',
                    'error_en_transcription_ok': 'âš ï¸',
                    'unknown': 'â“'
                }.get(status, 'â“')
                
                st.info(f"{status_icon} **Estado actual:** {status}")
                
                # Mostrar error si existe
                if project_info.get('error'):
                    st.error(f"âŒ **Error anterior:** {project_info['error']}")
                
                # BotÃ³n de re-procesamiento
                if st.button(f"ðŸš€ Reanudar Procesamiento", type="primary", use_container_width=True):
                    with st.spinner(f"ðŸ”„ Reanudando el procesamiento para {selected_project_id}..."):
                        try:
                            # Importar el procesador de video
                            from utils.video_processing import VideoProcessor
                            
                            # Crear la instancia del procesador
                            video_processor = VideoProcessor(config=app_config)
                            
                            # Obtener la configuraciÃ³n completa de la UI
                            full_config = get_full_config_from_ui(app_config)
                            
                            # Reanudar el procesamiento
                            final_video_path = video_processor.process_single_video(
                                full_config=full_config,
                                existing_project_info=project_info
                            )
                            
                            if final_video_path and final_video_path.exists():
                                st.success(f"âœ… Â¡Proyecto '{selected_project_id}' completado exitosamente!")
                                st.video(str(final_video_path))
                                
                                # Mostrar informaciÃ³n del video final
                                st.info(f"ðŸ“ **Video guardado en:** {final_video_path}")
                                st.info(f"â±ï¸ **DuraciÃ³n:** {project_info.get('audio_duration', 0):.1f} segundos")
                            else:
                                st.error(f"âŒ El procesamiento para '{selected_project_id}' fallÃ³. Revisa los logs.")
                                
                        except Exception as e:
                            st.error(f"âŒ OcurriÃ³ un error crÃ­tico al re-procesar: {e}")
                            st.exception(e)
                
                # BotÃ³n para ver el video existente si existe
                video_path = project_dir / "video" / f"{selected_project_id}_final_subtitled.mp4"
                if video_path.exists():
                    st.subheader("ðŸŽ¥ Video Actual")
                    st.video(str(video_path))
                    
                    col_v1, col_v2 = st.columns(2)
                    with col_v1:
                        if st.button("ðŸ“ Abrir carpeta del proyecto", key=f"open_folder_{selected_project_id}"):
                            import subprocess
                            try:
                                subprocess.run(["open", str(project_dir)])
                                st.success("ðŸ“ Carpeta abierta!")
                            except:
                                st.info(f"ðŸ“ Ruta del proyecto: {project_dir}")
                    
                    with col_v2:
                        if st.button("ðŸ—‘ï¸ Eliminar proyecto", key=f"delete_project_{selected_project_id}", type="secondary"):
                            st.warning("âš ï¸ Esta acciÃ³n eliminarÃ¡ completamente el proyecto y todos sus archivos.")
                            if st.button("âœ… Confirmar eliminaciÃ³n", key=f"confirm_delete_{selected_project_id}", type="primary"):
                                import shutil
                                try:
                                    shutil.rmtree(project_dir)
                                    st.success(f"âœ… Proyecto '{selected_project_id}' eliminado!")
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"âŒ Error al eliminar: {e}")
                
            except Exception as e:
                st.error(f"âŒ Error al cargar el proyecto: {e}")
    
    st.markdown("---")
    
    # ===== SECCIÃ“N 2: CONFIGURACIÃ“N DE INTELIGENCIA ARTIFICIAL =====
    st.header("2. ðŸ¤– ConfiguraciÃ³n de Inteligencia Artificial")
    
    with st.expander("ðŸ¤– Opciones de IA", expanded=True):
        # Verificar si hay proyectos que necesitan IA para guiones
        proyectos_con_ia = [p for p in st.session_state.get("batch_projects", []) if p.get("script_type") != "âœï¸ Usar guiÃ³n manual"]
        
        col1, col2 = st.columns(2)
        
        # CONFIGURACIÃ“N DE GUIONES
        with col1:
            st.subheader("ðŸ“ GeneraciÃ³n de Guiones")
            if proyectos_con_ia:
                st.info(f"ðŸ“Š {len(proyectos_con_ia)} proyecto(s) usarÃ¡n IA para generar guiÃ³n.")
                
                script_provider = st.selectbox(
                    "Proveedor de IA para Guiones", 
                    ["OpenAI", "Gemini", "Ollama"], 
                    key="batch_script_provider"
                )
                
                if script_provider == "OpenAI":
                    script_model = st.selectbox("Modelo OpenAI", ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"], key="batch_script_model")
                elif script_provider == "Gemini":
                    script_model = st.selectbox("Modelo Gemini", ["gemini-pro", "gemini-pro-vision"], key="batch_script_model")
                else:
                    script_model = st.text_input("Modelo Ollama", "llama2", key="batch_script_model")
                
                try:
                    prompts_guion_list = list_prompts("guion")
                    prompt_guion_names = [p.get("nombre", f"Prompt InvÃ¡lido {i}") for i, p in enumerate(prompts_guion_list)]
                    default_script_prompt_name = "Guion BÃ¡sico (Default)"
                    default_script_index = prompt_guion_names.index(default_script_prompt_name) if default_script_prompt_name in prompt_guion_names else 0
                    selected_prompt_guion_name = st.selectbox("Plantilla de GuiÃ³n", prompt_guion_names, index=default_script_index, key="batch_script_prompt")
                    script_prompt_obj = next((p for p in prompts_guion_list if p.get("nombre") == selected_prompt_guion_name), None)
                except Exception as e:
                    st.warning(f"No se pudieron cargar los prompts de guiÃ³n: {e}")
                    script_prompt_obj = None
            else:
                script_provider, script_model, script_prompt_obj = "OpenAI", "gpt-3.5-turbo", None
                st.info("â„¹ï¸ Todos los proyectos usan guiÃ³n manual.")
        
        # CONFIGURACIÃ“N DE PROMPTS DE IMAGEN
        with col2:
            st.subheader("ðŸ–¼ï¸ GeneraciÃ³n de Prompts de Imagen")
            
            # Inicializar img_style
            img_style = ""
            
            img_prompt_provider = st.selectbox(
                "Proveedor para Prompts de Imagen", 
                ["gemini", "openai", "ollama"], 
                index=0, 
                key="batch_img_prompt_provider"
            )
            
            if img_prompt_provider == "gemini":
                default_gemini_model = app_config.get('ai', {}).get('default_models', {}).get('image_prompt_generation', 'models/gemini-1.5-flash-latest')
                gemini_models = [
                    "models/gemini-1.5-flash-latest",
                    "models/gemini-1.5-pro-latest", 
                    "models/gemini-2.5-flash-lite-preview-06-17",
                    "gemini-pro",
                    "gemini-pro-vision"
                ]
                default_index = gemini_models.index(default_gemini_model) if default_gemini_model in gemini_models else 0
                img_prompt_model = st.selectbox("Modelo Gemini", gemini_models, index=default_index, key="batch_img_prompt_model")
            elif img_prompt_provider == "openai":
                default_openai_model = app_config.get('ai', {}).get('default_models', {}).get('openai', 'gpt-4o-mini')
                openai_models = ["gpt-4", "gpt-3.5-turbo", "gpt-4-turbo", "gpt-4o-mini"]
                default_index = openai_models.index(default_openai_model) if default_openai_model in openai_models else 0
                img_prompt_model = st.selectbox("Modelo OpenAI", openai_models, index=default_index, key="batch_img_prompt_model")
            else:
                default_ollama_model = app_config.get('ai', {}).get('default_models', {}).get('ollama', 'llama3')
                img_prompt_model = st.text_input("Modelo Ollama", default_ollama_model, key="batch_img_prompt_model")
            
            try:
                prompts_img_list = list_prompts("imagenes")
                prompt_img_names = [p.get("nombre", f"Prompt InvÃ¡lido {i}") for i, p in enumerate(prompts_img_list)]
                default_img_prompt_name = "Escenas Fotorrealistas HistÃ³ricamente Precisas"
                default_img_index = prompt_img_names.index(default_img_prompt_name) if default_img_prompt_name in prompt_img_names else 0
                selected_prompt_img_name = st.selectbox("Plantilla de ImÃ¡genes", prompt_img_names, index=default_img_index, key="batch_image_prompt")
                img_prompt_obj = next((p for p in prompts_img_list if p.get("nombre") == selected_prompt_img_name), None)
                
                # ðŸ›ï¸ CONFIGURACIÃ“N ESPECIAL PARA PROMPT HISTÃ“RICO
                if selected_prompt_img_name == "Escenas Fotorrealistas HistÃ³ricamente Precisas":
                    st.markdown("---")
                    st.subheader("ðŸ›ï¸ ConfiguraciÃ³n HistÃ³rica")
                    st.info("ðŸ’¡ Este prompt requiere informaciÃ³n histÃ³rica especÃ­fica para generar imÃ¡genes precisas")
                    
                    # OpciÃ³n de configuraciÃ³n
                    config_mode = st.radio(
                        "Â¿CÃ³mo quieres configurar el contexto histÃ³rico?",
                        ["ðŸ¤– Generar automÃ¡ticamente con IA", "âœï¸ Configurar manualmente"],
                        key="batch_historical_config_mode",
                        help="IA analizarÃ¡ el tÃ­tulo/contexto para extraer informaciÃ³n histÃ³rica, o puedes configurarla manualmente"
                    )
                    
                    if config_mode == "âœï¸ Configurar manualmente":
                        col_hist1, col_hist2 = st.columns(2)
                        with col_hist1:
                            periodo_historico = st.text_input(
                                "ðŸ“… PerÃ­odo HistÃ³rico",
                                placeholder="Ej: Siglo IV d.C., Imperio Romano tardÃ­o",
                                key="batch_periodo_historico",
                                help="Especifica la Ã©poca exacta con fechas aproximadas"
                            )
                            ubicacion = st.text_input(
                                "ðŸŒ UbicaciÃ³n GeogrÃ¡fica", 
                                placeholder="Ej: Sebastea, Armenia histÃ³rica",
                                key="batch_ubicacion",
                                help="RegiÃ³n, ciudad o Ã¡rea geogrÃ¡fica especÃ­fica"
                            )
                        with col_hist2:
                            contexto_cultural = st.text_area(
                                "ðŸ›ï¸ Contexto Cultural",
                                placeholder="Ej: Cristianismo primitivo bajo persecuciÃ³n...",
                                key="batch_contexto_cultural",
                                help="Contexto religioso, polÃ­tico, social de la Ã©poca",
                                height=100
                            )
                        
                        # Guardar configuraciÃ³n manual
                        historical_config = {
                            "mode": "manual",
                            "periodo_historico": periodo_historico,
                            "ubicacion": ubicacion, 
                            "contexto_cultural": contexto_cultural
                        }
                    else:
                        st.success("ðŸ¤– La IA analizarÃ¡ automÃ¡ticamente cada proyecto para extraer:")
                        st.write("â€¢ ðŸ“… PerÃ­odo histÃ³rico exacto")
                        st.write("â€¢ ðŸŒ UbicaciÃ³n geogrÃ¡fica")
                        st.write("â€¢ ðŸ›ï¸ Contexto cultural especÃ­fico")
                        
                        # ConfiguraciÃ³n del LLM para anÃ¡lisis histÃ³rico
                        st.markdown("**ðŸ¤– ConfiguraciÃ³n del LLM para AnÃ¡lisis HistÃ³rico:**")
                        col_hist_ai1, col_hist_ai2 = st.columns(2)
                        
                        with col_hist_ai1:
                            from utils.ai_services import get_available_providers_info
                            providers_info = get_available_providers_info()
                            available_providers = [name for name, info in providers_info.items() if info['configured']]
                            
                            if available_providers:
                                provider_display_names = {
                                    'openai': 'OpenAI',
                                    'gemini': 'Google Gemini',
                                    'ollama': 'Ollama (Local)'
                                }
                                
                                # Obtener configuraciÃ³n por defecto desde config.yaml
                                historical_config = app_config.get('video_generation', {}).get('historical_analysis', {})
                                config_default_provider = historical_config.get('default_provider', 'gemini')
                                
                                # Usar configuraciÃ³n del config.yaml si estÃ¡ disponible, sino priorizar Gemini
                                default_provider_index = 0
                                if config_default_provider in available_providers:
                                    default_provider_index = available_providers.index(config_default_provider)
                                elif 'gemini' in available_providers:
                                    default_provider_index = available_providers.index('gemini')
                                
                                historical_ai_provider = st.selectbox(
                                    "Proveedor IA", 
                                    available_providers,
                                    index=default_provider_index,
                                    key="batch_historical_ai_provider",
                                    format_func=lambda x: provider_display_names.get(x, x.title())
                                )
                            else:
                                st.error("âŒ No hay proveedores de IA configurados")
                                historical_ai_provider = "gemini"  # Fallback
                        
                        with col_hist_ai2:
                            # Modelos segÃºn el proveedor seleccionado
                            if available_providers and historical_ai_provider in providers_info:
                                available_models = providers_info[historical_ai_provider]['models']
                                
                                # Configurar modelo por defecto segÃºn el proveedor
                                default_model_index = 0
                                
                                # Primero intentar usar configuraciÃ³n especÃ­fica de anÃ¡lisis histÃ³rico
                                historical_config = app_config.get('video_generation', {}).get('historical_analysis', {})
                                config_default_model = historical_config.get('default_model', '')
                                
                                if config_default_model and config_default_model in available_models:
                                    default_model_index = available_models.index(config_default_model)
                                else:
                                    # Fallback a configuraciÃ³n general por proveedor
                                    if historical_ai_provider == 'gemini':
                                        default_gemini_model = app_config.get('ai', {}).get('default_models', {}).get('gemini', 'models/gemini-1.5-flash-latest')
                                        if default_gemini_model in available_models:
                                            default_model_index = available_models.index(default_gemini_model)
                                    elif historical_ai_provider == 'openai':
                                        default_openai_model = app_config.get('ai', {}).get('default_models', {}).get('openai', 'gpt-4o-mini')
                                        if default_openai_model in available_models:
                                            default_model_index = available_models.index(default_openai_model)
                                    elif historical_ai_provider == 'ollama':
                                        default_ollama_model = app_config.get('ai', {}).get('default_models', {}).get('ollama', 'llama3')
                                        if default_ollama_model in available_models:
                                            default_model_index = available_models.index(default_ollama_model)
                                
                                historical_ai_model = st.selectbox(
                                    "Modelo", 
                                    available_models, 
                                    index=default_model_index,
                                    key="batch_historical_ai_model"
                                )
                            else:
                                default_gemini_model = app_config.get('ai', {}).get('default_models', {}).get('gemini', 'models/gemini-1.5-flash-latest')
                                historical_ai_model = default_gemini_model  # Fallback
                        
                        # ConfiguraciÃ³n automÃ¡tica con LLM seleccionado
                        historical_config = {
                            "mode": "auto",
                            "ai_provider": historical_ai_provider,
                            "ai_model": historical_ai_model
                        }
                    
                    # Guardar en session_state para usar despuÃ©s
                    st.session_state["batch_historical_config"] = historical_config
                else:
                    # Limpiar configuraciÃ³n histÃ³rica si no se usa el prompt histÃ³rico
                    if "batch_historical_config" in st.session_state:
                        del st.session_state["batch_historical_config"]
                        
            except Exception as e:
                st.warning(f"No se pudieron cargar los prompts de imÃ¡genes: {e}")
                img_prompt_obj = None
            
            # ConfiguraciÃ³n de estilo (movida aquÃ­ para mayor coherencia)
            st.markdown("---")
            st.subheader("ðŸŽ¨ ConfiguraciÃ³n de Estilo para {style}")
            
            # Verificar si la plantilla seleccionada usa la variable {style}
            template_uses_style = False
            if img_prompt_obj and 'style' in img_prompt_obj.get('variables', []):
                template_uses_style = True
            
            if template_uses_style:
                st.info("ðŸ’¡ **La plantilla seleccionada usa la variable `{style}`. Configura quÃ© estilo aplicar:**")
                
                # Importar estilos desde el gestor de prompts para consistencia
                from pages.prompts_manager_page import get_style_options
                
                # Estilos predefinidos (sincronizados con el gestor)
                style_options_from_manager = get_style_options()
                style_options = {
                    "sin_estilo": "Usar el estilo definido en la plantilla (no aplicar {style})",
                    **style_options_from_manager,
                    "personalizado": "Escribir estilo personalizado..."
                }
                
                col1, col2 = st.columns([1, 2])
                with col1:
                    style_preset = st.selectbox(
                        "Aplicar Estilo",
                        options=list(style_options.keys()),
                        format_func=lambda x: "Sin estilo adicional" if x == "sin_estilo" else "Personalizado" if x == "personalizado" else x.title(),
                        key="batch_style_preset",
                        help="Solo disponible si la plantilla usa {style}"
                    )
                
                with col2:
                    if style_preset == "sin_estilo":
                        img_style = ""  # No aplicar estilo
                        st.info("âœ¨ Se usarÃ¡ solo el estilo definido en la plantilla")
                    elif style_preset == "personalizado":
                        img_style = st.text_input(
                            "Estilo Personalizado",
                            value="cinematic, high detail, professional photography",
                            key="batch_img_style"
                        )
                    else:
                        img_style = st.text_input(
                            "Estilo para Variable {style}",
                            value=style_options[style_preset],
                            key="batch_img_style",
                            help="Este texto reemplazarÃ¡ {style} en la plantilla"
                        )
            else:
                st.success("âœ… **La plantilla seleccionada ya define su propio estilo.** No necesitas configurar nada mÃ¡s.")
                img_style = ""  # No hay variable {style} en la plantilla
        
        # CONFIGURACIÃ“N DE OPTIMIZACIÃ“N YOUTUBE (CONSOLIDADA AQUÃ)
        st.markdown("---")
        st.subheader("ðŸŽ¯ OptimizaciÃ³n para YouTube")
        
        optimization_config = {}
        optimization_config['generate_optimized_content'] = st.checkbox(
            "Generar contenido optimizado para TODOS los videos", 
            value=True, 
            key="batch_optimize_content",
            help="Genera tÃ­tulos alternativos, descripciÃ³n SEO, tags relevantes y capÃ­tulos con timestamps para cada video"
        )
        
        if optimization_config['generate_optimized_content']:
            st.info("ðŸ’¡ Se generarÃ¡n archivos `content_optimization.txt` y `youtube_metadata.json` en cada carpeta de proyecto")
            
            # ConfiguraciÃ³n del LLM para optimizaciÃ³n (en la misma secciÃ³n)
            from utils.ai_services import get_available_providers_info
            providers_info = get_available_providers_info()
            available_providers = [name for name, info in providers_info.items() if info['configured']]
            
            if available_providers:
                col_opt1, col_opt2, col_opt3 = st.columns(3)
                
                with col_opt1:
                    provider_display_names = {
                        'openai': 'OpenAI',
                        'gemini': 'Google Gemini',
                        'ollama': 'Ollama (Local)'
                    }
                    
                    # Priorizar Gemini si estÃ¡ disponible
                    default_provider_index = 0
                    if 'gemini' in available_providers:
                        default_provider_index = available_providers.index('gemini')
                    
                    optimization_config['optimization_provider'] = st.selectbox(
                        "Proveedor IA para OptimizaciÃ³n", 
                        available_providers,
                        index=default_provider_index,
                        key="batch_opt_provider",
                        format_func=lambda x: provider_display_names.get(x, x.title())
                    )
                
                with col_opt2:
                    # Modelos segÃºn el proveedor seleccionado
                    selected_provider = optimization_config['optimization_provider']
                    if selected_provider in providers_info:
                        available_models = providers_info[selected_provider]['models']
                        
                        # Configurar modelo por defecto segÃºn el proveedor
                        default_model_index = 0
                        if selected_provider == 'gemini':
                            default_gemini_model = app_config.get('ai', {}).get('default_models', {}).get('gemini', 'models/gemini-1.5-flash-latest')
                            if default_gemini_model in available_models:
                                default_model_index = available_models.index(default_gemini_model)
                        
                        optimization_config['optimization_model'] = st.selectbox(
                            "Modelo", 
                            available_models, 
                            index=default_model_index,
                            key="batch_opt_model"
                        )
                    else:
                        default_openai_model = app_config.get('ai', {}).get('default_models', {}).get('openai', 'gpt-4o-mini')
                        optimization_config['optimization_model'] = default_openai_model  # Fallback
                
                with col_opt3:
                    optimization_config['use_same_style'] = st.checkbox(
                        "Estilo consistente", 
                        value=True,
                        key="batch_opt_consistent",
                        help="Mantener un estilo similar en tÃ­tulos y descripciones entre videos"
                    )
                    optimization_config['generate_series_tags'] = st.checkbox(
                        "Tags de serie", 
                        value=True,
                        key="batch_opt_series",
                        help="AÃ±adir tags que conecten todos los videos como una serie"
                    )
            else:
                st.warning("âš ï¸ **No hay proveedores de IA configurados**")
                st.info("Ve a la pÃ¡gina de **ConfiguraciÃ³n** para configurar al menos un proveedor (OpenAI, Gemini o Ollama)")
                default_provider = app_config.get('ai', {}).get('default_models', {}).get('openai', 'gpt-4o-mini')
                optimization_config['optimization_provider'] = 'openai'  # Fallback
                optimization_config['optimization_model'] = default_provider  # Fallback
    
    # FunciÃ³n para obtener la configuraciÃ³n completa de la UI
    def get_full_config_from_ui(app_config):
        """Recolecta toda la configuraciÃ³n de la UI para el procesamiento"""
        full_config = {
            "ai": app_config.get("ai", {}),
            "tts": app_config.get("tts", {}),
            "transcription": app_config.get("transcription", {}),
            "image": app_config.get("image", {}),
            "video": app_config.get("video", {}),
            "audio": app_config.get("audio", {}),
            "subtitles": app_config.get("subtitles", {}),
            "scenes_config": app_config.get("scenes_config", {}),
            "effects": app_config.get("effects", {}),
            "overlays": app_config.get("overlays", {})
        }
        return full_config
    
    # ===== SECCIÃ“N 3: CONFIGURACIÃ“N DE CONTENIDO =====
    st.header("3. ðŸŽ¬ ConfiguraciÃ³n de Contenido")
    
    # ESCENAS - CONSOLIDADO (SegmentaciÃ³n + DuraciÃ³n)
    with st.expander("ðŸŽ¬ ConfiguraciÃ³n de Escenas", expanded=True):
        st.subheader("ðŸ“‘ SegmentaciÃ³n de Escenas")
        segmentation_mode = st.selectbox(
            "MÃ©todo de SegmentaciÃ³n",
            ["Por PÃ¡rrafos (HÃ­brido)", "Por DuraciÃ³n (Basado en Audio)", "AutomÃ¡tico (Texto)"],
            index=0,
            key="batch_segmentation_mode",
            help="â€¢ Por PÃ¡rrafos (HÃ­brido): Alinea pÃ¡rrafos del guion con el audio (Recomendado).\nâ€¢ Por DuraciÃ³n: Agrupa palabras del audio para alcanzar una duraciÃ³n fija.\nâ€¢ AutomÃ¡tico: Divide el texto por pÃ¡rrafos/caracteres."
        )
        
        st.markdown("---")
        st.subheader("â±ï¸ DuraciÃ³n de Escenas")
        
        max_scene_duration = st.slider(
            "DuraciÃ³n MÃ¡xima por Escena (s)",
            min_value=5.0,
            max_value=25.0,
            value=12.0,
            step=0.5,
            key="batch_max_scene_duration",
            help="Define el tiempo mÃ¡ximo para una escena antes de que se subdivida automÃ¡ticamente. Afecta principalmente a la segmentaciÃ³n 'HÃ­brida'."
        )

        # Mostrar informaciÃ³n contextual segÃºn el mÃ©todo de segmentaciÃ³n
        if segmentation_mode == "Por DuraciÃ³n (Basado en Audio)":
            st.info("ðŸ’¡ Con segmentaciÃ³n por duraciÃ³n, se recomienda usar duraciÃ³n automÃ¡tica para consistencia.")
        elif segmentation_mode == "Por PÃ¡rrafos (HÃ­brido)":
            st.info("ðŸ’¡ Con segmentaciÃ³n hÃ­brida, la duraciÃ³n automÃ¡tica se adapta mejor al contenido de cada pÃ¡rrafo.")
        
        col1, col2 = st.columns(2)
        with col1:
            use_auto_duration = st.checkbox(
                "DuraciÃ³n automÃ¡tica basada en audio",
                value=True,
                help="Calcular duraciÃ³n por imagen segÃºn el audio transcrito. Es la opciÃ³n recomendada.",
                key="batch_use_auto_duration"
            )
        with col2:
            duration_per_image = st.slider(
                "DuraciÃ³n manual por imagen (s)",
                min_value=1.0,
                max_value=15.0,
                value=10.0,
                step=0.5,
                key="batch_duration_manual",
                disabled=use_auto_duration,
                help="Establece una duraciÃ³n fija para cada imagen si la duraciÃ³n automÃ¡tica estÃ¡ desactivada."
            )
    
    # CONFIGURACIÃ“N DE IMÃGENES (CONSOLIDADA)
    with st.expander("ðŸ–¼ï¸ ConfiguraciÃ³n de ImÃ¡genes", expanded=True):
        st.info("Actualmente configurado para usar Replicate (flux-schnell).")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            img_aspect_ratio = st.selectbox("Aspect Ratio", ["16:9", "1:1", "9:16"], index=0, key="batch_img_aspect")
        with col2:
            img_output_format = st.selectbox("Formato", ["webp", "png", "jpeg"], index=0, key="batch_img_format")
        with col3:
            img_output_quality = st.slider("Calidad", 50, 100, 85, 5, key="batch_img_quality")
        with col4:
            img_megapixels = st.select_slider("Megapixels", ["1", "2", "4"], value="1", key="batch_img_mp")
        
        # ConfiguraciÃ³n movida a la secciÃ³n de IA
    
    # CONFIGURACIÃ“N DE VIDEO (Transiciones y Efectos)
    with st.expander("ðŸŽ¥ Transiciones y Efectos de Video", expanded=True):
        # Transiciones y Fades
        st.subheader("ðŸ”„ Transiciones y Fades")
        col1, col2, col3 = st.columns(3)
        with col1:
            from utils.transitions import TransitionEffect
            transition_type = st.selectbox(
                "Tipo de transiciÃ³n",
                options=TransitionEffect.get_available_transitions(),
                format_func=lambda x: "Sin transiciÃ³n" if x == "none" else "DisoluciÃ³n" if x == "dissolve" else x.replace('_', ' ').title(),
                index=1,
                key="batch_transition_type"
            )
        with col2:
            transition_duration = st.slider(
                "DuraciÃ³n de transiciÃ³n (s)", 0.0, 5.0, 1.0, 0.1, key="batch_transition_duration"
            )
        with col3:
            fade_in_duration = st.slider(
                "Fade In (s)", 0.0, 5.0, 1.0, 0.1, key="batch_fade_in"
            )
            fade_out_duration = st.slider(
                "Fade Out (s)", 0.0, 5.0, 1.0, 0.1, key="batch_fade_out"
            )

    # EFECTOS Y OVERLAYS
    with st.expander("âœ¨ Efectos y Overlays", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("âœ¨ Efectos Visuales")
            try:
                effects_sequence = show_effects_ui(key_prefix="batch_")
            except Exception as e:
                st.warning(f"âš ï¸ La interfaz de efectos no estÃ¡ disponible ({e}). Se usarÃ¡ configuraciÃ³n bÃ¡sica.")
                effects_sequence = []
        
        with col2:
            st.subheader("ðŸ–¼ï¸ Superposiciones (Overlays)")
            try:
                overlay_sequence = show_overlays_ui(key_prefix="batch_")
            except Exception as e:
                st.warning(f"âš ï¸ La interfaz de overlays no estÃ¡ disponible ({e}). Se usarÃ¡ configuraciÃ³n bÃ¡sica.")
                overlay_sequence = []
        
        # ConfiguraciÃ³n avanzada de efectos para batch
        st.markdown("---")
        st.subheader("âš™ï¸ ConfiguraciÃ³n Avanzada para Lotes")
        col1, col2 = st.columns(2)
        with col1:
            randomize_effects = st.checkbox(
                "ðŸŽ² Randomizar efectos entre proyectos",
                help="Cada proyecto tendrÃ¡ efectos ligeramente diferentes",
                key="batch_randomize_effects"
            )
            if randomize_effects:
                effect_variation = st.slider(
                    "VariaciÃ³n de efectos", 0.1, 0.5, 0.2, 0.1, key="batch_effect_variation"
                )
        with col2:
            vary_intensity = st.checkbox(
                "ðŸ“Š Variar intensidad por proyecto",
                help="La intensidad de efectos aumentarÃ¡ gradualmente",
                key="batch_vary_intensity"
            )
            if vary_intensity:
                intensity_range = st.slider(
                    "Rango de intensidad", 0.5, 2.0, (0.8, 1.5), key="batch_intensity_range"
                )

    # Construir el diccionario de configuraciÃ³n de video
    video_config = {
        'use_auto_duration': use_auto_duration,
        'duration_per_image_manual': duration_per_image if not use_auto_duration else 10.0,
        'transition_type': transition_type,
        'transition_duration': transition_duration,
        'fade_in': fade_in_duration,
        'fade_out': fade_out_duration,
        'effects': effects_sequence,
        'overlays': overlay_sequence
    }

    # ===== SECCIÃ“N 4: CONFIGURACIÃ“N DE AUDIO Y SUBTÃTULOS =====
    st.header("4. ðŸ”Š ConfiguraciÃ³n de Audio y SubtÃ­tulos")
    
    # CONFIGURACIÃ“N DE AUDIO
    with st.expander("ðŸ”Š ConfiguraciÃ³n de Audio", expanded=True):
        audio_config = _render_batch_audio_config(app_config)
    
    # CONFIGURACIÃ“N DE SUBTÃTULOS
    with st.expander("ðŸ“ ConfiguraciÃ³n de SubtÃ­tulos", expanded=True):
        subtitles_config = _render_batch_subtitles_config(app_config)

    # ===== SECCIÃ“N 5: PROCESAR BATCH =====
    st.header("5. ðŸŽ¬ Procesar Batch")
    
    # Mostrar resumen antes del procesamiento
    if st.session_state.get("batch_projects"):
        st.subheader("ðŸ“‹ Resumen de ConfiguraciÃ³n")
        
        # MÃ©tricas principales
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ðŸŽ¬ Proyectos", len(st.session_state.batch_projects))
        with col2:
            efectos_count = len(video_config.get('effects', [])) if video_config.get('effects') else 0
            st.metric("âœ¨ Efectos", efectos_count)
        with col3:
            overlays_count = len(video_config.get('overlays', [])) if video_config.get('overlays') else 0
            st.metric("ðŸ–¼ï¸ Overlays", overlays_count)
        with col4:
            music_status = "âœ… SÃ­" if audio_config.get('bg_music_selection') else "âŒ No"
            st.metric("ðŸŽµ MÃºsica", music_status)
        
        # Detalles de configuraciÃ³n
        with st.expander("ðŸ” Ver Detalles de ConfiguraciÃ³n"):
            col_det1, col_det2 = st.columns(2)
            
            with col_det1:
                st.write("**ðŸŽµ Audio:**")
                if audio_config.get('bg_music_selection'):
                    try:
                        music_name = Path(audio_config['bg_music_selection']).name
                    except:
                        music_name = audio_config['bg_music_selection']
                    st.write(f"â€¢ MÃºsica: {music_name}")
                    st.write(f"â€¢ Volumen mÃºsica: {audio_config.get('music_volume', 0.06)}")
                else:
                    st.write("â€¢ âŒ Sin mÃºsica de fondo")
                
                st.write(f"â€¢ Voz: {audio_config.get('tts_voice', 'N/A')}")
                st.write(f"â€¢ Velocidad: {audio_config.get('tts_speed_percent', 0)}%")
            
            with col_det2:
                st.write("**âœ¨ Efectos Visuales:**")
                if efectos_count > 0:
                    st.write(f"â€¢ {efectos_count} efecto(s) configurado(s)")
                else:
                    st.write("â€¢ âŒ Sin efectos configurados")
                
                st.write("**ðŸ–¼ï¸ Overlays:**")
                if overlays_count > 0:
                    st.write(f"â€¢ {overlays_count} overlay(s) configurado(s)")
                else:
                    st.write("â€¢ âŒ Sin overlays configurados")
    
    if st.button("ðŸŽ¬ PROCESAR TODOS LOS PROYECTOS", type="primary", use_container_width=True):
        if not st.session_state.batch_projects:
            st.warning("âš ï¸ No hay proyectos para procesar. AÃ±ade al menos un proyecto.")
            return
        
        # ===== VALIDACIONES ANTES DEL PROCESAMIENTO =====
        validaciones_faltantes = []
        validaciones_recomendadas = []
        continuar_sin_config = False  # Inicializar variable
        
        # Verificar mÃºsica de fondo (recomendado, no obligatorio)
        if not audio_config.get('bg_music_selection'):
            validaciones_recomendadas.append("ðŸŽµ **MÃºsica de fondo**: No has seleccionado mÃºsica de fondo")
        
        # Verificar overlays (recomendado, no obligatorio)
        overlays_configurados = video_config.get('overlays', [])
        if not overlays_configurados or len(overlays_configurados) == 0:
            validaciones_recomendadas.append("ðŸ–¼ï¸ **Overlays**: No has configurado ningÃºn overlay")
        
        # Verificar efectos (recomendado, no obligatorio)
        efectos_configurados = video_config.get('effects', [])
        if not efectos_configurados or len(efectos_configurados) == 0:
            validaciones_recomendadas.append("âœ¨ **Efectos visuales**: No has configurado efectos visuales")
        
        # Mostrar recomendaciones si faltan configuraciones (pero permitir continuar)
        if validaciones_recomendadas:
            st.warning("ðŸ’¡ **Configuraciones recomendadas faltantes:**")
            for validacion in validaciones_recomendadas:
                st.write(f"â€¢ {validacion}")
            
            st.info("â„¹ï¸ **Puedes continuar sin estas configuraciones, pero se recomienda configurarlas para mejores resultados.**")
            
            st.markdown("---")
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("âš™ï¸ Configurar Antes de Continuar", type="secondary", use_container_width=True):
                    st.info("ðŸ’¡ **Sugerencias para mejorar tus videos:**")
                    if not audio_config.get('bg_music_selection'):
                        st.write("â€¢ Ve a la secciÃ³n **'ðŸ”Š ConfiguraciÃ³n de Audio'** y selecciona una mÃºsica de fondo")
                    if not overlays_configurados:
                        st.write("â€¢ Ve a la secciÃ³n **'âœ¨ Efectos y Overlays'** y configura algunos overlays")
                    if not efectos_configurados:
                        st.write("â€¢ Ve a la secciÃ³n **'âœ¨ Efectos y Overlays'** y configura algunos efectos visuales")
                    return
            
            with col2:
                continuar_sin_config = st.button("ðŸš€ Continuar de Todas Formas", type="primary", use_container_width=True)
                if not continuar_sin_config:
                    return
                else:
                    st.success("âœ… Continuando con la configuraciÃ³n actual...")
        else:
            st.success("âœ… Todas las configuraciones recomendadas estÃ¡n presentes!")
            # Si no hay configuraciones faltantes, procesar directamente
            continuar_sin_config = True
        
        # Solo procesar si se confirmÃ³ continuar
        if not continuar_sin_config:
            return
        
        st.info("ðŸ”„ Iniciando procesamiento por lotes... Esto puede tardar varios minutos.")
        
        # Crear contenedores para la barra de progreso
        progress_container = st.empty()
        status_container = st.empty()
        progress_bar = progress_container.progress(0)
        
        def update_progress(progress: float, message: str):
            progress_bar.progress(progress)
            status_container.text(message)
        
        # Crear carpeta principal de proyectos
        projects_dir = Path("projects")
        projects_dir.mkdir(exist_ok=True)
        update_progress(0.05, "ðŸ“ Preparando estructura de carpetas...")
        
        resultados = []
        total_projects = len(st.session_state.batch_projects)
        
        # Recopilar configuraciÃ³n completa
        batch_config = {
            "script": {
                "provider": script_provider,
                "model": script_model,
                "prompt_obj": script_prompt_obj
            },
            "image": {
                "img_provider": "Replicate",
                "img_model": "black-forest-labs/flux-schnell",
                "img_prompt_provider": img_prompt_provider,
                "img_prompt_model": img_prompt_model,
                "aspect_ratio": img_aspect_ratio,
                "output_format": img_output_format,
                "output_quality": img_output_quality,
                "megapixels": img_megapixels,
                "style": img_style,
                "prompt_obj": img_prompt_obj
            },
            "scenes_config": {
                "segmentation_mode": segmentation_mode,
                "max_scene_duration": max_scene_duration
            },
            "video": video_config,
            "audio": audio_config,
            "subtitles": subtitles_config,
            **optimization_config
        }
        
        # Procesar cada proyecto
        for i, proyecto in enumerate(st.session_state.batch_projects):
            current_progress = (i / total_projects) * 0.9
            update_progress(current_progress, f"ðŸ”„ Procesando {i+1}/{total_projects}: {proyecto['titulo']}")
            
            try:
                resultado = procesar_proyecto_individual(
                    proyecto=proyecto,
                    batch_config=batch_config,
                    progress_callback=lambda prog, msg: update_progress(
                        current_progress + (prog * 0.9 / total_projects),
                        f"ðŸ”„ {proyecto['titulo']}: {msg}"
                    )
                )
                
                resultados.append(resultado)
                
            except Exception as e:
                st.error(f"âŒ Error procesando '{proyecto['titulo']}': {str(e)}")
                resultados.append({
                    "titulo": proyecto["titulo"],
                    "estado": "error",
                    "error": str(e)
                })
        
        # Progreso final
        update_progress(1.0, "ðŸŽ‰ Â¡Procesamiento completado!")
        
        # Mostrar resultados
        mostrar_resultados_batch(resultados)
        
        # Limpiar automÃ¡ticamente proyectos completados del CMS de la cola
        proyectos_completados_cms = [r for r in resultados if r.get("cms_updated", False) and r["estado"] == "completado"]
        if proyectos_completados_cms:
            st.session_state.batch_projects = [
                p for p in st.session_state.batch_projects 
                if not (p.get("cms_publicacion_id") in [r.get("cms_publicacion_id") for r in proyectos_completados_cms])
            ]
            st.info(f"ðŸ§¹ Limpieza automÃ¡tica: {len(proyectos_completados_cms)} proyecto(s) del CMS eliminados de la cola")
        
        # Limpiar progreso
        progress_container.empty()
        status_container.empty()


def procesar_proyecto_individual(proyecto, batch_config, progress_callback):
    """
    Procesa un proyecto individual del batch con todas las configuraciones reutilizadas.
    """
    try:
        from utils.video_processing import VideoProcessor
        
        progress_callback(0.05, "Preparando procesador de video")
        
        # ðŸ›ï¸ PROCESAMIENTO ESPECIAL PARA PROMPT HISTÃ“RICO
        image_config = batch_config["image"].copy()
        
        # Verificar si se estÃ¡ usando el prompt histÃ³rico
        prompt_obj = batch_config["image"].get("prompt_obj", {})
        if prompt_obj and prompt_obj.get("nombre") == "Escenas Fotorrealistas HistÃ³ricamente Precisas":
            progress_callback(0.07, "ðŸ›ï¸ Analizando contexto histÃ³rico...")
            
            # Obtener configuraciÃ³n histÃ³rica del session_state
            historical_config = st.session_state.get("batch_historical_config", {})
            
            if historical_config.get("mode") == "manual":
                # Usar configuraciÃ³n manual
                periodo_historico = historical_config.get("periodo_historico", "")
                ubicacion = historical_config.get("ubicacion", "")
                contexto_cultural = historical_config.get("contexto_cultural", "")
                
                progress_callback(0.08, "âœï¸ Usando configuraciÃ³n histÃ³rica manual")
                
            elif historical_config.get("mode") == "auto":
                # Extraer automÃ¡ticamente con IA
                try:
                    from utils.ai_services import extract_historical_context
                    
                    ai_provider = historical_config.get("ai_provider", "gemini")
                    default_gemini_model = app_config.get('ai', {}).get('default_models', {}).get('gemini', 'models/gemini-1.5-flash-latest')
                    ai_model = historical_config.get("ai_model", default_gemini_model)
                    
                    progress_callback(0.08, f"ðŸ¤– Extrayendo contexto histÃ³rico con {ai_provider}...")
                    
                    historical_data = extract_historical_context(
                        titulo=proyecto["titulo"],
                        contexto=proyecto["contexto"],
                        provider=ai_provider,
                        model=ai_model
                    )
                    
                    periodo_historico = historical_data.get("periodo_historico", "")
                    ubicacion = historical_data.get("ubicacion", "")
                    contexto_cultural = historical_data.get("contexto_cultural", "")
                    
                    progress_callback(0.09, "âœ… Contexto histÃ³rico extraÃ­do exitosamente")
                    
                except Exception as e:
                    progress_callback(0.09, f"âš ï¸ Error extrayendo contexto histÃ³rico: {str(e)}")
                    # Usar valores por defecto si falla
                    periodo_historico = "InformaciÃ³n no especificada"
                    ubicacion = "InformaciÃ³n no especificada"
                    contexto_cultural = "InformaciÃ³n no especificada"
            else:
                # Fallback si no hay configuraciÃ³n
                periodo_historico = "InformaciÃ³n no especificada"
                ubicacion = "InformaciÃ³n no especificada"
                contexto_cultural = "InformaciÃ³n no especificada"
            
            # Actualizar la configuraciÃ³n de imagen con las variables histÃ³ricas
            image_config["prompt_obj"] = prompt_obj  # Mantener el prompt original
            image_config["historical_context"] = {
                "periodo_historico": periodo_historico,
                "ubicacion": ubicacion,
                "contexto_cultural": contexto_cultural,
                "extraction_mode": historical_config.get("mode", "fallback")
            }
            
            # AÃ±adir las variables histÃ³ricas a las variables disponibles para el prompt
            image_config["historical_variables"] = {
                "periodo_historico": periodo_historico,
                "ubicacion": ubicacion,
                "contexto_cultural": contexto_cultural
            }

        # Preparar configuraciÃ³n completa para el procesador
        full_config = {
            "titulo": proyecto["titulo"],
            "contexto": proyecto["contexto"],
            "script": {
                "mode": "Proporcionar Manualmente" if proyecto.get("script_type") == "âœï¸ Usar guiÃ³n manual" else "Generar con IA",
                "manual_script": proyecto.get("guion_manual"),
                **batch_config["script"]
            },
            "image": image_config,  # Usar la configuraciÃ³n de imagen actualizada
            "scenes_config": batch_config["scenes_config"],
            "video": batch_config["video"],
            "audio": batch_config["audio"],
            "subtitles": batch_config["subtitles"],
            # AÃ±adir configuraciÃ³n de optimizaciÃ³n
            "generate_optimized_content": batch_config.get("generate_optimized_content", False),
            "use_same_style": batch_config.get("use_same_style", False),
            "generate_series_tags": batch_config.get("generate_series_tags", False)
        }
        
        progress_callback(0.1, "Iniciando procesamiento con VideoProcessor...")
        
        # Usar el VideoProcessor del generador individual
        processor = VideoProcessor(config=batch_config)
        result_path = processor.process_single_video(full_config)
        
        progress_callback(1.0, "Â¡Completado!")
        
        # Obtener directorio del proyecto desde el result_path
        if result_path:
            proyecto_dir = Path(result_path).parent.parent  # video/file.mp4 -> project_dir
            
            # Guardar metadata del proyecto
            metadata = {
                "titulo": proyecto["titulo"],
                "contexto": proyecto["contexto"],
                "script_type": proyecto.get("script_type"),
                "fecha_procesado": datetime.now().isoformat(),
                "config_used": full_config,
                "cms_info": {
                    "publicacion_id": proyecto.get("cms_publicacion_id"),
                    "canal": proyecto.get("cms_canal")
                } if "cms_publicacion_id" in proyecto else None
            }
            
            metadata_path = proyecto_dir / "batch_metadata.json"
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # Actualizar estado en CMS si el proyecto viene del CMS
            cms_updated = False
            if "cms_publicacion_id" in proyecto:
                try:
                    # Importar y usar DatabaseManager para actualizar estado
                    import sys
                    project_root = Path(__file__).resolve().parent.parent
                    if str(project_root) not in sys.path:
                        sys.path.append(str(project_root))
                    
                    from utils.database_manager import DatabaseManager
                    db_manager = DatabaseManager()
                    db_manager.update_publicacion_status(
                        proyecto["cms_publicacion_id"], 
                        'Generado', 
                        str(proyecto_dir)
                    )
                    cms_updated = True
                    print(f"âœ… CMS actualizado: PublicaciÃ³n {proyecto['cms_publicacion_id']} â†’ 'Generado'")
                    
                    # TambiÃ©n actualizar el metadata con el resultado
                    metadata["cms_update_result"] = "success"
                    metadata["cms_update_timestamp"] = datetime.now().isoformat()
                    
                except Exception as e:
                    # Si falla la actualizaciÃ³n del CMS, continuar pero registrar el error
                    print(f"âŒ Error actualizando CMS: {e}")
                    import traceback
                    traceback.print_exc()
                    
                    # Guardar error en metadata
                    metadata["cms_update_result"] = "error"
                    metadata["cms_update_error"] = str(e)
                    metadata["cms_update_timestamp"] = datetime.now().isoformat()
                    
                # Re-escribir metadata con informaciÃ³n de CMS
                try:
                    with open(metadata_path, "w", encoding="utf-8") as f:
                        json.dump(metadata, f, indent=2, ensure_ascii=False)
                except Exception as e:
                    print(f"Warning: No se pudo actualizar metadata: {e}")
            
            return {
                "titulo": proyecto["titulo"],
                "estado": "completado",
                "video_path": str(result_path) if result_path else None,
                "proyecto_dir": str(proyecto_dir),
                "metadata": metadata,
                "cms_updated": cms_updated,
                "cms_publicacion_id": proyecto.get("cms_publicacion_id")
            }
        else:
            return {
                "titulo": proyecto["titulo"],
                "estado": "error",
                "error": "No se generÃ³ video final"
            }
        
    except Exception as e:
        return {
            "titulo": proyecto["titulo"],
            "estado": "error",
            "error": str(e)
        }


def mostrar_resultados_batch(resultados):
    """
    Muestra los resultados del procesamiento por lotes.
    """
    st.header("ðŸ“Š Resultados del Procesamiento")
    
    # Resumen general
    total = len(resultados)
    completados = len([r for r in resultados if r["estado"] == "completado"])
    errores = len([r for r in resultados if r["estado"] == "error"])
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ðŸ“Š Total", total)
    with col2:
        st.metric("âœ… Completados", completados)
    with col3:
        st.metric("âŒ Errores", errores)
    
    # Mostrar cada resultado
    for resultado in resultados:
        if resultado["estado"] == "completado":
            st.success(f"âœ… **{resultado['titulo']}** - Â¡Completado exitosamente!")
            
            # Mostrar informaciÃ³n del video generado
            if "video_path" in resultado and resultado["video_path"]:
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.write(f"ðŸ“ **Carpeta:** {resultado.get('proyecto_dir', 'N/A')}")
                    st.write(f"ðŸŽ¥ **Video:** {resultado['video_path']}")
                    
                    # Mostrar el video si existe
                    if Path(resultado['video_path']).exists():
                        st.video(resultado['video_path'])
                    
                    # Mostrar metadata si estÃ¡ disponible
                    if "metadata" in resultado:
                        metadata = resultado["metadata"]
                        with st.expander("ðŸ“‹ Detalles del proyecto"):
                            st.json(metadata)
                
                with col2:
                    # BotÃ³n para descargar si existe el archivo
                    if Path(resultado['video_path']).exists():
                        with open(resultado['video_path'], "rb") as f:
                            st.download_button(
                                "â¬‡ï¸ Descargar Video",
                                f,
                                file_name=f"{resultado['titulo']}.mp4",
                                mime="video/mp4",
                                key=f"download_{resultado['titulo']}"
                            )
            
        else:  # Error
            st.error(f"âŒ **{resultado['titulo']}** - Error durante el procesamiento")
            if "error" in resultado:
                st.code(resultado["error"])
        
        st.markdown("---")
    
    # Opciones post-procesamiento
    st.subheader("ðŸ“‹ Acciones")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ðŸ§¹ Limpiar cola de proyectos"):
            st.session_state.batch_projects = []
            st.success("âœ… Cola limpiada!")
            st.rerun()
    
    with col2:
        if completados > 0:
            st.success(f"ðŸŽ‰ Â¡{completados} video(s) generado(s) exitosamente!")
            st.info("ðŸ’¡ Los videos estÃ¡n guardados en la carpeta 'projects/'")

def _render_batch_audio_config(app_config):
    """ConfiguraciÃ³n de audio especÃ­fica para batch (sin duplicaciones de UI)"""
    
    # --- SELECCIÃ“N DE PROVEEDOR TTS ---
    st.markdown("**ðŸŽ¤ SÃ­ntesis de Voz (TTS)**")
    
    # Obtener configuraciÃ³n TTS desde config.yaml
    tts_defaults = app_config.get('tts', {})
    default_provider = tts_defaults.get('default_provider', 'edge')
    
    # Seleccionar proveedor TTS
    provider_options = ["Edge TTS", "Fish Audio"]
    provider_mapping = {"edge": "Edge TTS", "fish": "Fish Audio"}
    default_provider_ui = provider_mapping.get(default_provider, "Edge TTS")
    provider_index = provider_options.index(default_provider_ui) if default_provider_ui in provider_options else 0
    
    tts_provider = st.selectbox(
        "Proveedor TTS",
        provider_options,
        index=provider_index,
        key="batch_tts_provider",
        help="Edge TTS: Gratuito, voces de Microsoft. Fish Audio: Calidad premium, requiere API key."
    )
    
    # ConfiguraciÃ³n especÃ­fica segÃºn el proveedor
    if tts_provider == "Edge TTS":
        # --- CONFIGURACIÃ“N EDGE TTS ---
        col_voz1, col_voz2, col_voz3, col_voz4 = st.columns(4)
        
        async def obtener_voces_es_tts():
            voces = await edge_tts.list_voices()
            return [(v['ShortName'], v['Name']) for v in voces if v['Locale'].startswith('es-')]

        try:
            voces_esp_tuplas = asyncio.run(obtener_voces_es_tts())
            nombres_cortos = [v[0] for v in voces_esp_tuplas]
            nombres_completos = [v[1] for v in voces_esp_tuplas]
            default_voice_short = app_config.get("ai", {}).get("default_models", {}).get("voice", "es-ES-AlvaroNeural")
            voice_index = nombres_cortos.index(default_voice_short) if default_voice_short in nombres_cortos else 0
        except Exception as e:
            st.warning(f"No se pudieron cargar las voces de EdgeTTS: {e}. Usando default.")
            nombres_cortos = ["es-ES-AlvaroNeural"]
            nombres_completos = ["Microsoft Server Speech Text to Speech Voice (es-ES, AlvaroNeural)"]
            voice_index = 0

        with col_voz1:
            selected_voice_short = st.selectbox("Voz", nombres_cortos, index=voice_index, key="batch_tts_voice")
            tts_voice = nombres_completos[nombres_cortos.index(selected_voice_short)]
             
        with col_voz2:
            edge_defaults = tts_defaults.get('edge', {})
            default_rate = edge_defaults.get('default_rate', '+0%')
            # Convertir formato +X% a nÃºmero
            rate_value = int(default_rate.replace('%', '').replace('+', '')) if default_rate != '+0%' else 0
            tts_speed_percent = st.slider("Velocidad (%)", -50, 50, rate_value, 1, key="batch_tts_speed")
        with col_voz3:
            default_pitch = edge_defaults.get('default_pitch', '+0Hz')
            # Convertir formato +XHz a nÃºmero
            pitch_value = int(default_pitch.replace('Hz', '').replace('+', '')) if default_pitch != '+0Hz' else 0
            tts_pitch_hz = st.slider("Tono (Hz)", -50, 50, pitch_value, 1, key="batch_tts_pitch")
        with col_voz4:
            default_volume = app_config.get('video_generation', {}).get('audio', {}).get('default_voice_volume', 1.0)
            tts_volume = st.slider("Volumen Voz", 0.0, 2.0, default_volume, 0.1, key="batch_tts_volume")
        
        # ConfiguraciÃ³n para Edge TTS
        tts_config = {
            'tts_provider': 'edge',
            'tts_voice': tts_voice,
            'tts_speed_percent': tts_speed_percent,
            'tts_pitch_hz': tts_pitch_hz,
            'tts_volume': tts_volume
        }
        
    else:  # Fish Audio
        # --- CONFIGURACIÃ“N FISH AUDIO ---
        st.info("ðŸŸ **Fish Audio**: Calidad premium de sÃ­ntesis de voz. Requiere API key configurada.")
        
        # Verificar si Fish Audio estÃ¡ disponible
        try:
            from utils.audio_services import FISH_AUDIO_AVAILABLE
            if not FISH_AUDIO_AVAILABLE:
                st.error("âŒ Fish Audio SDK no estÃ¡ disponible. Instala 'fish-audio-sdk' para usar Fish Audio TTS.")
                st.stop()
        except ImportError:
            st.error("âŒ No se pudo verificar la disponibilidad de Fish Audio.")
            st.stop()
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Modelo de Fish Audio
            fish_models = [
                ("speech-1.5", "Fish Audio Speech 1.5"),
                ("speech-1.6", "Fish Audio Speech 1.6 (Recomendado)"),
                ("s1", "Fish Audio S1")
            ]
            selected_fish_model = st.selectbox(
                "Modelo",
                [m[0] for m in fish_models],
                index=1,  # speech-1.6 por defecto
                key="batch_fish_model",
                format_func=lambda x: dict(fish_models)[x]
            )
            
            # Formato de salida
            fish_format = st.selectbox(
                "Formato",
                ["mp3", "wav", "pcm"],
                index=0,
                key="batch_fish_format"
            )
            
            # Bitrate para MP3
            fish_defaults = tts_defaults.get('fish_audio', {})
            default_bitrate = fish_defaults.get('default_mp3_bitrate', 128)
            bitrate_options = [64, 128, 192]
            bitrate_index = bitrate_options.index(default_bitrate) if default_bitrate in bitrate_options else 1
            fish_bitrate = st.selectbox(
                "Bitrate MP3",
                bitrate_options,
                index=bitrate_index,
                key="batch_fish_bitrate",
                disabled=(fish_format != "mp3")
            )
        
        with col2:
            # Latencia
            default_latency = fish_defaults.get('default_latency', 'normal')
            latency_options = ["normal", "balanced"]
            latency_index = latency_options.index(default_latency) if default_latency in latency_options else 0
            fish_latency = st.selectbox(
                "Latencia",
                latency_options,
                index=latency_index,
                key="batch_fish_latency",
                help="Normal: Mayor estabilidad. Balanced: Menor latencia (300ms)"
            )
            
            # Normalizar texto
            default_normalize = fish_defaults.get('default_normalize', True)
            fish_normalize = st.checkbox(
                "Normalizar texto",
                default_normalize,
                key="batch_fish_normalize",
                help="Mejora la estabilidad para nÃºmeros y texto en inglÃ©s/chino"
            )
            
            # Volumen
            default_volume = app_config.get('video_generation', {}).get('audio', {}).get('default_voice_volume', 1.0)
            tts_volume = st.slider("Volumen Voz", 0.0, 2.0, default_volume, 0.1, key="batch_tts_volume")
        
        # ConfiguraciÃ³n para Fish Audio
        tts_config = {
            'tts_provider': 'fish',
            'tts_fish_model': selected_fish_model,
            'tts_fish_format': fish_format,
            'tts_fish_bitrate': fish_bitrate,
            'tts_fish_latency': fish_latency,
            'tts_fish_normalize': fish_normalize,
            'tts_volume': tts_volume
        }

    # --- MÃšSICA DE FONDO ---
    st.markdown("**ðŸŽµ MÃºsica de Fondo**")
    col_music1, col_music2 = st.columns(2)
    
    with col_music1:
        bg_music_folder = Path("background_music")
        available_music = ["**Ninguna**"] + ([f.name for f in bg_music_folder.iterdir() if f.suffix.lower() in ['.mp3', '.wav']] if bg_music_folder.exists() else [])
        
        # Obtener mÃºsica por defecto desde config.yaml
        audio_defaults = app_config.get('video_generation', {}).get('audio', {})
        default_bg_music = audio_defaults.get('background_music', '')
        default_music_name = Path(default_bg_music).name if default_bg_music else None
        
        # Establecer Ã­ndice por defecto
        default_index = 0  # "**Ninguna**" por defecto
        if default_music_name and default_music_name in available_music:
            default_index = available_music.index(default_music_name)
        
        sel_music = st.selectbox("MÃºsica Fondo", available_music, index=default_index, key="batch_bg_music")
        bg_music_selection = str(bg_music_folder / sel_music) if sel_music != "**Ninguna**" else None
        
    with col_music2:
        # Obtener configuraciÃ³n de audio desde config.yaml
        audio_defaults = app_config.get('video_generation', {}).get('audio', {})
        default_music_volume = audio_defaults.get('default_music_volume', 0.08)
        music_volume = st.slider("Volumen MÃºsica", 0.0, 1.0, default_music_volume, 0.01, "%.2f", key="batch_music_vol", disabled=(not bg_music_selection))
        music_loop = st.checkbox("Loop MÃºsica", True, key="batch_music_loop", disabled=(not bg_music_selection))

    # Combinar configuraciÃ³n TTS con mÃºsica
    audio_config = {
        **tts_config,
        'bg_music_selection': bg_music_selection,
        'music_volume': music_volume,
        'music_loop': music_loop
    }
    
    return audio_config

def _render_batch_subtitles_config(app_config):
    """ConfiguraciÃ³n de subtÃ­tulos especÃ­fica para batch usando valores de config.yaml como defaults"""
    
    # Obtener configuraciÃ³n de subtÃ­tulos desde config.yaml
    subtitles_defaults = app_config.get('video_generation', {}).get('subtitles', {})
    
    sub_config = {}
    sub_config['enable'] = st.checkbox("Incrustar SubtÃ­tulos", subtitles_defaults.get('enable', True), key="batch_sub_enable")
    
    if sub_config['enable']:
        col1, col2, col3 = st.columns(3)
        with col1:
            try:
                available_fonts = get_available_fonts()
                default_font = subtitles_defaults.get('font', 'Arial')
                font_index = available_fonts.index(default_font) if default_font in available_fonts else 0
            except:
                available_fonts = ["Arial", "Helvetica", "Times New Roman", "Calibri", "Impact"]
                default_font = subtitles_defaults.get('font', 'Arial')
                font_index = available_fonts.index(default_font) if default_font in available_fonts else 0
                
            sub_config['font'] = st.selectbox("Fuente", available_fonts, index=font_index, key="batch_sub_font")
            sub_config['size'] = st.slider("TamaÃ±o", 16, 72, subtitles_defaults.get('font_size', 24), key="batch_sub_size")
        with col2:
            sub_config['color'] = st.color_picker("Color Texto", subtitles_defaults.get('font_color', '#FFFFFF'), key="batch_sub_color")
            sub_config['stroke_color'] = st.color_picker("Color Borde", subtitles_defaults.get('stroke_color', '#000000'), key="batch_sub_stroke_color")
        with col3:
            sub_config['stroke_width'] = st.slider("Grosor Borde", 0, 5, int(subtitles_defaults.get('stroke_width', 1.5)), key="batch_sub_stroke_width")
            position_options = ["bottom", "center", "top"]
            default_position = subtitles_defaults.get('position', 'bottom')
            position_index = position_options.index(default_position) if default_position in position_options else 0
            sub_config['position'] = st.selectbox("PosiciÃ³n", position_options, index=position_index, key="batch_sub_pos")
            
        sub_config['max_words'] = st.slider("MÃ¡x. Palabras por Segmento", 1, 10, subtitles_defaults.get('max_words', 7), key="batch_sub_max_words")
        st.caption("Controla cuÃ¡ntas palabras aparecen juntas en pantalla.")
        
    return sub_config