import streamlit as st
import os
import uuid
from pathlib import Path
from datetime import datetime
import json
import math
import asyncio
from moviepy.editor import AudioFileClip

# Importar funciones necesarias
try:
    from utils.config import load_config
    from utils.ai_services import list_openai_models, list_gemini_models, list_ollama_models
    from pages.prompts_manager_page import list_prompts
    from pages.efectos_ui import show_effects_ui
    from pages.overlays_ui import show_overlays_ui
    from utils.subtitle_utils import get_available_fonts
    import edge_tts
except ImportError as e:
    st.error(f"Error importando dependencias: {e}")

def show_batch_processor():
    st.title("üöÄ Procesador por Lotes de Videos")
    
    st.info("""
    **Automatiza completamente** la creaci√≥n de videos desde t√≠tulo + contexto:
    
    üìù Gui√≥n ‚Üí üîä Audio ‚Üí üéØ Transcripci√≥n ‚Üí üé¨ Escenas ‚Üí üñºÔ∏è Im√°genes ‚Üí üé• Video ‚Üí üìù Subt√≠tulos
    """)
    
    st.markdown("---")
    
    # Cargar configuraci√≥n de la aplicaci√≥n
    try:
        app_config = load_config()
    except:
        app_config = {"ai": {"default_models": {}}}
    
    # ===== SECCI√ìN 1: GESTI√ìN DE PROYECTOS =====
    st.header("1. üìã Gesti√≥n de Proyectos por Lotes")
    
    # A√±adir nuevos proyectos
    st.subheader("‚ûï A√±adir Nuevo Proyecto")
    
    # Opci√≥n para elegir tipo de gui√≥n (fuera del formulario para que sea reactiva)
    script_type = st.radio(
        "üìú Tipo de gui√≥n:",
        ["ü§ñ Generar autom√°ticamente con IA", "‚úçÔ∏è Usar gui√≥n manual"],
        index=1,  # Por defecto seleccionar gui√≥n manual
        help="Elige si quieres que la IA genere el gui√≥n o usar tu propio gui√≥n",
        key="script_type_selector"
    )
    
    with st.form("add_project"):
        col1, col2 = st.columns(2)
        
        with col1:
            titulo = st.text_input("üìù T√≠tulo del proyecto", help="Ej: C√≥mo hacer pan casero")
            contexto = st.text_area("üìñ Contexto/Descripci√≥n", help="Informaci√≥n adicional sobre el contenido del video")
        
        with col2:
            guion_manual = None
            if script_type == "‚úçÔ∏è Usar gui√≥n manual":
                guion_manual = st.text_area(
                    "üìù Escribe tu gui√≥n:",
                    height=100,
                    help="Escribe aqu√≠ el gui√≥n completo que quieres usar para el video",
                    placeholder="Ejemplo:\n\nHola y bienvenidos a mi canal...\n\nEn el video de hoy vamos a aprender...\n\n¬°No olviden suscribirse!"
                )
            else:
                st.info("ü§ñ El gui√≥n se generar√° autom√°ticamente con IA usando el t√≠tulo y contexto proporcionados.")
        
        if st.form_submit_button("‚úÖ A√±adir al Batch", use_container_width=True):
            if titulo and contexto:
                # Validar gui√≥n manual si es necesario
                if script_type == "‚úçÔ∏è Usar gui√≥n manual" and not guion_manual:
                    st.error("‚ö†Ô∏è Por favor, escribe el gui√≥n manual.")
                else:
                    if "batch_projects" not in st.session_state:
                        st.session_state.batch_projects = []
                    
                    nuevo_proyecto = {
                        "titulo": titulo,
                        "contexto": contexto,
                        "script_type": script_type,
                        "guion_manual": guion_manual if script_type == "‚úçÔ∏è Usar gui√≥n manual" else None,
                        "id": str(uuid.uuid4())[:8],
                        "fecha_a√±adido": datetime.now().isoformat()
                    }
                    
                    st.session_state.batch_projects.append(nuevo_proyecto)
                    script_info = "con gui√≥n manual" if script_type == "‚úçÔ∏è Usar gui√≥n manual" else "con IA"
                    st.success(f"‚úÖ Proyecto '{titulo}' a√±adido al batch {script_info}!")
                    st.rerun()
            else:
                st.error("‚ö†Ô∏è Por favor, completa el t√≠tulo y contexto.")
    
    # Mostrar proyectos existentes
    if "batch_projects" in st.session_state and st.session_state.batch_projects:
        st.subheader(f"üìä Proyectos en cola ({len(st.session_state.batch_projects)})")
        
        # Mostrar cada proyecto
        for i, proyecto in enumerate(st.session_state.batch_projects):
            # Icono seg√∫n el tipo de gui√≥n
            icon = "‚úçÔ∏è" if proyecto.get("script_type") == "‚úçÔ∏è Usar gui√≥n manual" else "ü§ñ"
            script_label = "Manual" if proyecto.get("script_type") == "‚úçÔ∏è Usar gui√≥n manual" else "IA"
            
            # Detectar si viene del CMS
            is_from_cms = "cms_publicacion_id" in proyecto
            cms_icon = " üìö" if is_from_cms else ""
            
            col1, col2, col3 = st.columns([3, 1, 1])
            
            with col1:
                st.write(f"{icon} **{proyecto['titulo']}** ({script_label}){cms_icon}")
                if is_from_cms:
                    st.caption(f"üì∫ **Canal:** {proyecto.get('cms_canal', 'N/A')} | üÜî **Pub ID:** {proyecto.get('cms_publicacion_id')}")
                st.caption(f"üìñ {proyecto['contexto'][:100]}{'...' if len(proyecto['contexto']) > 100 else ''}")
                
                # Mostrar preview del gui√≥n manual si existe
                if proyecto.get("guion_manual"):
                    if st.button("üëÄ Ver/Ocultar Gui√≥n", key=f"toggle_script_{proyecto['id']}"):
                        show_key = f"show_script_{proyecto['id']}"
                        st.session_state[show_key] = not st.session_state.get(show_key, False)
                    
                    if st.session_state.get(f"show_script_{proyecto['id']}", False):
                        st.text_area(
                            "üìù Gui√≥n completo:",
                            value=proyecto["guion_manual"],
                            height=100,
                            disabled=True,
                            key=f"preview_script_{proyecto['id']}"
                        )
            
            with col2:
                if st.button("‚úèÔ∏è Editar", key=f"edit_{proyecto['id']}"):
                    st.session_state[f"editing_{proyecto['id']}"] = True
                    st.rerun()
            
            with col3:
                if st.button("üóëÔ∏è Eliminar", key=f"delete_{proyecto['id']}"):
                    st.session_state.batch_projects.pop(i)
                    st.success(f"‚úÖ Proyecto '{proyecto['titulo']}' eliminado!")
                    st.rerun()
            
            # Formulario de edici√≥n inline
            if st.session_state.get(f"editing_{proyecto['id']}", False):
                st.markdown("---")
                with st.form(f"edit_project_{proyecto['id']}"):
                    st.subheader("‚úèÔ∏è Editar Proyecto")
                    
                    edit_col1, edit_col2 = st.columns(2)
                    with edit_col1:
                        nuevo_titulo = st.text_input("T√≠tulo", value=proyecto['titulo'])
                        nuevo_contexto = st.text_area("Contexto", value=proyecto['contexto'])
                    
                    with edit_col2:
                        nuevo_script_type = st.radio(
                            "Tipo de gui√≥n:",
                            ["ü§ñ Generar autom√°ticamente con IA", "‚úçÔ∏è Usar gui√≥n manual"],
                            index=1 if proyecto.get("script_type") == "‚úçÔ∏è Usar gui√≥n manual" else 0
                        )
                        
                        nuevo_guion_manual = None
                        if nuevo_script_type == "‚úçÔ∏è Usar gui√≥n manual":
                            nuevo_guion_manual = st.text_area(
                                "Gui√≥n manual:",
                                value=proyecto.get("guion_manual", ""),
                                height=100
                            )
                    
                    col_edit1, col_edit2 = st.columns(2)
                    with col_edit1:
                        if st.form_submit_button("üíæ Guardar cambios"):
                            proyecto.update({
                                "titulo": nuevo_titulo,
                                "contexto": nuevo_contexto,
                                "script_type": nuevo_script_type,
                                "guion_manual": nuevo_guion_manual if nuevo_script_type == "‚úçÔ∏è Usar gui√≥n manual" else None
                            })
                            st.session_state[f"editing_{proyecto['id']}"] = False
                            st.success("‚úÖ Proyecto actualizado!")
                            st.rerun()
                    
                    with col_edit2:
                        if st.form_submit_button("‚ùå Cancelar"):
                            st.session_state[f"editing_{proyecto['id']}"] = False
                            st.rerun()
            
            st.markdown("---")
        
        # Bot√≥n para limpiar todos los proyectos
        if st.button("üßπ Limpiar toda la cola", type="secondary"):
            st.session_state.batch_projects = []
            st.success("‚úÖ Cola de proyectos limpiada!")
            st.rerun()
    else:
        st.info("üìù No hay proyectos en la cola. A√±ade algunos proyectos para comenzar.")
    
    st.markdown("---")
    
    # ===== SECCI√ìN 2: CONFIGURACI√ìN DE INTELIGENCIA ARTIFICIAL =====
    st.header("2. ü§ñ Configuraci√≥n de Inteligencia Artificial")
    
    with st.expander("ü§ñ Opciones de IA", expanded=True):
        # Verificar si hay proyectos que necesitan IA para guiones
        proyectos_con_ia = [p for p in st.session_state.get("batch_projects", []) if p.get("script_type") != "‚úçÔ∏è Usar gui√≥n manual"]
        
        col1, col2 = st.columns(2)
        
        # CONFIGURACI√ìN DE GUIONES
        with col1:
            st.subheader("üìù Generaci√≥n de Guiones")
            if proyectos_con_ia:
                st.info(f"üìä {len(proyectos_con_ia)} proyecto(s) usar√°n IA para generar gui√≥n.")
                
                script_provider = st.selectbox(
                    "Proveedor de IA para Guiones", 
                    ["OpenAI", "Gemini", "Ollama"], 
                    key="batch_script_provider"
                )
                
                if script_provider == "OpenAI":
                    script_model = st.selectbox("Modelo OpenAI", ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"], key="batch_script_model")
                elif script_provider == "Gemini":
                    script_model = st.selectbox("Modelo Gemini", ["gemini-pro", "gemini-pro-vision"], key="batch_script_model")
                else:
                    script_model = st.text_input("Modelo Ollama", "llama2", key="batch_script_model")
                
                try:
                    prompts_guion_list = list_prompts("guion")
                    prompt_guion_names = [p.get("nombre", f"Prompt Inv√°lido {i}") for i, p in enumerate(prompts_guion_list)]
                    default_script_prompt_name = "Guion B√°sico (Default)"
                    default_script_index = prompt_guion_names.index(default_script_prompt_name) if default_script_prompt_name in prompt_guion_names else 0
                    selected_prompt_guion_name = st.selectbox("Plantilla de Gui√≥n", prompt_guion_names, index=default_script_index, key="batch_script_prompt")
                    script_prompt_obj = next((p for p in prompts_guion_list if p.get("nombre") == selected_prompt_guion_name), None)
                except Exception as e:
                    st.warning(f"No se pudieron cargar los prompts de gui√≥n: {e}")
                    script_prompt_obj = None
            else:
                script_provider, script_model, script_prompt_obj = "OpenAI", "gpt-3.5-turbo", None
                st.info("‚ÑπÔ∏è Todos los proyectos usan gui√≥n manual.")
        
        # CONFIGURACI√ìN DE PROMPTS DE IMAGEN
        with col2:
            st.subheader("üñºÔ∏è Generaci√≥n de Prompts de Imagen")
            
            # Inicializar img_style
            img_style = ""
            
            img_prompt_provider = st.selectbox(
                "Proveedor para Prompts de Imagen", 
                ["gemini", "openai", "ollama"], 
                index=0, 
                key="batch_img_prompt_provider"
            )
            
            if img_prompt_provider == "gemini":
                default_gemini_model = app_config.get('ai', {}).get('default_models', {}).get('image_prompt_generation', 'models/gemini-1.5-flash-latest')
                gemini_models = [
                    "models/gemini-1.5-flash-latest",
                    "models/gemini-1.5-pro-latest", 
                    "models/gemini-2.5-flash-lite-preview-06-17",
                    "gemini-pro",
                    "gemini-pro-vision"
                ]
                default_index = gemini_models.index(default_gemini_model) if default_gemini_model in gemini_models else 0
                img_prompt_model = st.selectbox("Modelo Gemini", gemini_models, index=default_index, key="batch_img_prompt_model")
            elif img_prompt_provider == "openai":
                default_openai_model = app_config.get('ai', {}).get('default_models', {}).get('openai', 'gpt-4o-mini')
                openai_models = ["gpt-4", "gpt-3.5-turbo", "gpt-4-turbo", "gpt-4o-mini"]
                default_index = openai_models.index(default_openai_model) if default_openai_model in openai_models else 0
                img_prompt_model = st.selectbox("Modelo OpenAI", openai_models, index=default_index, key="batch_img_prompt_model")
            else:
                default_ollama_model = app_config.get('ai', {}).get('default_models', {}).get('ollama', 'llama3')
                img_prompt_model = st.text_input("Modelo Ollama", default_ollama_model, key="batch_img_prompt_model")
            
            try:
                prompts_img_list = list_prompts("imagenes")
                prompt_img_names = [p.get("nombre", f"Prompt Inv√°lido {i}") for i, p in enumerate(prompts_img_list)]
                default_img_prompt_name = "Escenas Fotorrealistas Hist√≥ricamente Precisas"
                default_img_index = prompt_img_names.index(default_img_prompt_name) if default_img_prompt_name in prompt_img_names else 0
                selected_prompt_img_name = st.selectbox("Plantilla de Im√°genes", prompt_img_names, index=default_img_index, key="batch_image_prompt")
                img_prompt_obj = next((p for p in prompts_img_list if p.get("nombre") == selected_prompt_img_name), None)
                
                # üèõÔ∏è CONFIGURACI√ìN ESPECIAL PARA PROMPT HIST√ìRICO
                if selected_prompt_img_name == "Escenas Fotorrealistas Hist√≥ricamente Precisas":
                    st.markdown("---")
                    st.subheader("üèõÔ∏è Configuraci√≥n Hist√≥rica")
                    st.info("üí° Este prompt requiere informaci√≥n hist√≥rica espec√≠fica para generar im√°genes precisas")
                    
                    # Opci√≥n de configuraci√≥n
                    config_mode = st.radio(
                        "¬øC√≥mo quieres configurar el contexto hist√≥rico?",
                        ["ü§ñ Generar autom√°ticamente con IA", "‚úçÔ∏è Configurar manualmente"],
                        key="batch_historical_config_mode",
                        help="IA analizar√° el t√≠tulo/contexto para extraer informaci√≥n hist√≥rica, o puedes configurarla manualmente"
                    )
                    
                    if config_mode == "‚úçÔ∏è Configurar manualmente":
                        col_hist1, col_hist2 = st.columns(2)
                        with col_hist1:
                            periodo_historico = st.text_input(
                                "üìÖ Per√≠odo Hist√≥rico",
                                placeholder="Ej: Siglo IV d.C., Imperio Romano tard√≠o",
                                key="batch_periodo_historico",
                                help="Especifica la √©poca exacta con fechas aproximadas"
                            )
                            ubicacion = st.text_input(
                                "üåç Ubicaci√≥n Geogr√°fica", 
                                placeholder="Ej: Sebastea, Armenia hist√≥rica",
                                key="batch_ubicacion",
                                help="Regi√≥n, ciudad o √°rea geogr√°fica espec√≠fica"
                            )
                        with col_hist2:
                            contexto_cultural = st.text_area(
                                "üèõÔ∏è Contexto Cultural",
                                placeholder="Ej: Cristianismo primitivo bajo persecuci√≥n...",
                                key="batch_contexto_cultural",
                                help="Contexto religioso, pol√≠tico, social de la √©poca",
                                height=100
                            )
                        
                        # Guardar configuraci√≥n manual
                        historical_config = {
                            "mode": "manual",
                            "periodo_historico": periodo_historico,
                            "ubicacion": ubicacion, 
                            "contexto_cultural": contexto_cultural
                        }
                    else:
                        st.success("ü§ñ La IA analizar√° autom√°ticamente cada proyecto para extraer:")
                        st.write("‚Ä¢ üìÖ Per√≠odo hist√≥rico exacto")
                        st.write("‚Ä¢ üåç Ubicaci√≥n geogr√°fica")
                        st.write("‚Ä¢ üèõÔ∏è Contexto cultural espec√≠fico")
                        
                        # Configuraci√≥n del LLM para an√°lisis hist√≥rico
                        st.markdown("**ü§ñ Configuraci√≥n del LLM para An√°lisis Hist√≥rico:**")
                        col_hist_ai1, col_hist_ai2 = st.columns(2)
                        
                        with col_hist_ai1:
                            from utils.ai_services import get_available_providers_info
                            providers_info = get_available_providers_info()
                            available_providers = [name for name, info in providers_info.items() if info['configured']]
                            
                            if available_providers:
                                provider_display_names = {
                                    'openai': 'OpenAI',
                                    'gemini': 'Google Gemini',
                                    'ollama': 'Ollama (Local)'
                                }
                                
                                # Obtener configuraci√≥n por defecto desde config.yaml
                                historical_config = app_config.get('video_generation', {}).get('historical_analysis', {})
                                config_default_provider = historical_config.get('default_provider', 'gemini')
                                
                                # Usar configuraci√≥n del config.yaml si est√° disponible, sino priorizar Gemini
                                default_provider_index = 0
                                if config_default_provider in available_providers:
                                    default_provider_index = available_providers.index(config_default_provider)
                                elif 'gemini' in available_providers:
                                    default_provider_index = available_providers.index('gemini')
                                
                                historical_ai_provider = st.selectbox(
                                    "Proveedor IA", 
                                    available_providers,
                                    index=default_provider_index,
                                    key="batch_historical_ai_provider",
                                    format_func=lambda x: provider_display_names.get(x, x.title())
                                )
                            else:
                                st.error("‚ùå No hay proveedores de IA configurados")
                                historical_ai_provider = "gemini"  # Fallback
                        
                        with col_hist_ai2:
                            # Modelos seg√∫n el proveedor seleccionado
                            if available_providers and historical_ai_provider in providers_info:
                                available_models = providers_info[historical_ai_provider]['models']
                                
                                # Configurar modelo por defecto seg√∫n el proveedor
                                default_model_index = 0
                                
                                # Primero intentar usar configuraci√≥n espec√≠fica de an√°lisis hist√≥rico
                                historical_config = app_config.get('video_generation', {}).get('historical_analysis', {})
                                config_default_model = historical_config.get('default_model', '')
                                
                                if config_default_model and config_default_model in available_models:
                                    default_model_index = available_models.index(config_default_model)
                                else:
                                    # Fallback a configuraci√≥n general por proveedor
                                    if historical_ai_provider == 'gemini':
                                        default_gemini_model = app_config.get('ai', {}).get('default_models', {}).get('gemini', 'models/gemini-1.5-flash-latest')
                                        if default_gemini_model in available_models:
                                            default_model_index = available_models.index(default_gemini_model)
                                    elif historical_ai_provider == 'openai':
                                        default_openai_model = app_config.get('ai', {}).get('default_models', {}).get('openai', 'gpt-4o-mini')
                                        if default_openai_model in available_models:
                                            default_model_index = available_models.index(default_openai_model)
                                    elif historical_ai_provider == 'ollama':
                                        default_ollama_model = app_config.get('ai', {}).get('default_models', {}).get('ollama', 'llama3')
                                        if default_ollama_model in available_models:
                                            default_model_index = available_models.index(default_ollama_model)
                                
                                historical_ai_model = st.selectbox(
                                    "Modelo", 
                                    available_models, 
                                    index=default_model_index,
                                    key="batch_historical_ai_model"
                                )
                            else:
                                default_gemini_model = app_config.get('ai', {}).get('default_models', {}).get('gemini', 'models/gemini-1.5-flash-latest')
                                historical_ai_model = default_gemini_model  # Fallback
                        
                        # Configuraci√≥n autom√°tica con LLM seleccionado
                        historical_config = {
                            "mode": "auto",
                            "ai_provider": historical_ai_provider,
                            "ai_model": historical_ai_model
                        }
                    
                    # Guardar en session_state para usar despu√©s
                    st.session_state["batch_historical_config"] = historical_config
                else:
                    # Limpiar configuraci√≥n hist√≥rica si no se usa el prompt hist√≥rico
                    if "batch_historical_config" in st.session_state:
                        del st.session_state["batch_historical_config"]
                        
            except Exception as e:
                st.warning(f"No se pudieron cargar los prompts de im√°genes: {e}")
                img_prompt_obj = None
            
            # Configuraci√≥n de estilo (movida aqu√≠ para mayor coherencia)
            st.markdown("---")
            st.subheader("üé® Configuraci√≥n de Estilo para {style}")
            
            # Verificar si la plantilla seleccionada usa la variable {style}
            template_uses_style = False
            if img_prompt_obj and 'style' in img_prompt_obj.get('variables', []):
                template_uses_style = True
            
            if template_uses_style:
                st.info("üí° **La plantilla seleccionada usa la variable `{style}`. Configura qu√© estilo aplicar:**")
                
                # Importar estilos desde el gestor de prompts para consistencia
                from pages.prompts_manager_page import get_style_options
                
                # Estilos predefinidos (sincronizados con el gestor)
                style_options_from_manager = get_style_options()
                style_options = {
                    "sin_estilo": "Usar el estilo definido en la plantilla (no aplicar {style})",
                    **style_options_from_manager,
                    "personalizado": "Escribir estilo personalizado..."
                }
                
                col1, col2 = st.columns([1, 2])
                with col1:
                    style_preset = st.selectbox(
                        "Aplicar Estilo",
                        options=list(style_options.keys()),
                        format_func=lambda x: "Sin estilo adicional" if x == "sin_estilo" else "Personalizado" if x == "personalizado" else x.title(),
                        key="batch_style_preset",
                        help="Solo disponible si la plantilla usa {style}"
                    )
                
                with col2:
                    if style_preset == "sin_estilo":
                        img_style = ""  # No aplicar estilo
                        st.info("‚ú® Se usar√° solo el estilo definido en la plantilla")
                    elif style_preset == "personalizado":
                        img_style = st.text_input(
                            "Estilo Personalizado",
                            value="cinematic, high detail, professional photography",
                            key="batch_img_style"
                        )
                    else:
                        img_style = st.text_input(
                            "Estilo para Variable {style}",
                            value=style_options[style_preset],
                            key="batch_img_style",
                            help="Este texto reemplazar√° {style} en la plantilla"
                        )
            else:
                st.success("‚úÖ **La plantilla seleccionada ya define su propio estilo.** No necesitas configurar nada m√°s.")
                img_style = ""  # No hay variable {style} en la plantilla
        
        # CONFIGURACI√ìN DE OPTIMIZACI√ìN YOUTUBE (CONSOLIDADA AQU√ç)
        st.markdown("---")
        st.subheader("üéØ Optimizaci√≥n para YouTube")
        
        optimization_config = {}
        optimization_config['generate_optimized_content'] = st.checkbox(
            "Generar contenido optimizado para TODOS los videos", 
            value=True, 
            key="batch_optimize_content",
            help="Genera t√≠tulos alternativos, descripci√≥n SEO, tags relevantes y cap√≠tulos con timestamps para cada video"
        )
        
        if optimization_config['generate_optimized_content']:
            st.info("üí° Se generar√°n archivos `content_optimization.txt` y `youtube_metadata.json` en cada carpeta de proyecto")
            
            # Configuraci√≥n del LLM para optimizaci√≥n (en la misma secci√≥n)
            from utils.ai_services import get_available_providers_info
            providers_info = get_available_providers_info()
            available_providers = [name for name, info in providers_info.items() if info['configured']]
            
            if available_providers:
                col_opt1, col_opt2, col_opt3 = st.columns(3)
                
                with col_opt1:
                    provider_display_names = {
                        'openai': 'OpenAI',
                        'gemini': 'Google Gemini',
                        'ollama': 'Ollama (Local)'
                    }
                    
                    # Priorizar Gemini si est√° disponible
                    default_provider_index = 0
                    if 'gemini' in available_providers:
                        default_provider_index = available_providers.index('gemini')
                    
                    optimization_config['optimization_provider'] = st.selectbox(
                        "Proveedor IA para Optimizaci√≥n", 
                        available_providers,
                        index=default_provider_index,
                        key="batch_opt_provider",
                        format_func=lambda x: provider_display_names.get(x, x.title())
                    )
                
                with col_opt2:
                    # Modelos seg√∫n el proveedor seleccionado
                    selected_provider = optimization_config['optimization_provider']
                    if selected_provider in providers_info:
                        available_models = providers_info[selected_provider]['models']
                        
                        # Configurar modelo por defecto seg√∫n el proveedor
                        default_model_index = 0
                        if selected_provider == 'gemini':
                            default_gemini_model = app_config.get('ai', {}).get('default_models', {}).get('gemini', 'models/gemini-1.5-flash-latest')
                            if default_gemini_model in available_models:
                                default_model_index = available_models.index(default_gemini_model)
                        
                        optimization_config['optimization_model'] = st.selectbox(
                            "Modelo", 
                            available_models, 
                            index=default_model_index,
                            key="batch_opt_model"
                        )
                    else:
                        default_openai_model = app_config.get('ai', {}).get('default_models', {}).get('openai', 'gpt-4o-mini')
                        optimization_config['optimization_model'] = default_openai_model  # Fallback
                
                with col_opt3:
                    optimization_config['use_same_style'] = st.checkbox(
                        "Estilo consistente", 
                        value=True,
                        key="batch_opt_consistent",
                        help="Mantener un estilo similar en t√≠tulos y descripciones entre videos"
                    )
                    optimization_config['generate_series_tags'] = st.checkbox(
                        "Tags de serie", 
                        value=True,
                        key="batch_opt_series",
                        help="A√±adir tags que conecten todos los videos como una serie"
                    )
            else:
                st.warning("‚ö†Ô∏è **No hay proveedores de IA configurados**")
                st.info("Ve a la p√°gina de **Configuraci√≥n** para configurar al menos un proveedor (OpenAI, Gemini o Ollama)")
                default_provider = app_config.get('ai', {}).get('default_models', {}).get('openai', 'gpt-4o-mini')
                optimization_config['optimization_provider'] = 'openai'  # Fallback
                optimization_config['optimization_model'] = default_provider  # Fallback
    
    # ===== SECCI√ìN 3: CONFIGURACI√ìN DE CONTENIDO =====
    st.header("3. üé¨ Configuraci√≥n de Contenido")
    
    # ESCENAS - CONSOLIDADO (Segmentaci√≥n + Duraci√≥n)
    with st.expander("üé¨ Configuraci√≥n de Escenas", expanded=True):
        st.subheader("üìë Segmentaci√≥n de Escenas")
        segmentation_mode = st.selectbox(
            "M√©todo de Segmentaci√≥n",
            ["Por P√°rrafos (H√≠brido)", "Por Duraci√≥n (Basado en Audio)", "Autom√°tico (Texto)"],
            index=0,
            key="batch_segmentation_mode",
            help="‚Ä¢ Por P√°rrafos (H√≠brido): Alinea p√°rrafos del guion con el audio (Recomendado).\n‚Ä¢ Por Duraci√≥n: Agrupa palabras del audio para alcanzar una duraci√≥n fija.\n‚Ä¢ Autom√°tico: Divide el texto por p√°rrafos/caracteres."
        )
        
        st.markdown("---")
        st.subheader("‚è±Ô∏è Duraci√≥n de Escenas")
        
        max_scene_duration = st.slider(
            "Duraci√≥n M√°xima por Escena (s)",
            min_value=5.0,
            max_value=25.0,
            value=12.0,
            step=0.5,
            key="batch_max_scene_duration",
            help="Define el tiempo m√°ximo para una escena antes de que se subdivida autom√°ticamente. Afecta principalmente a la segmentaci√≥n 'H√≠brida'."
        )

        # Mostrar informaci√≥n contextual seg√∫n el m√©todo de segmentaci√≥n
        if segmentation_mode == "Por Duraci√≥n (Basado en Audio)":
            st.info("üí° Con segmentaci√≥n por duraci√≥n, se recomienda usar duraci√≥n autom√°tica para consistencia.")
        elif segmentation_mode == "Por P√°rrafos (H√≠brido)":
            st.info("üí° Con segmentaci√≥n h√≠brida, la duraci√≥n autom√°tica se adapta mejor al contenido de cada p√°rrafo.")
        
        col1, col2 = st.columns(2)
        with col1:
            use_auto_duration = st.checkbox(
                "Duraci√≥n autom√°tica basada en audio",
                value=True,
                help="Calcular duraci√≥n por imagen seg√∫n el audio transcrito. Es la opci√≥n recomendada.",
                key="batch_use_auto_duration"
            )
        with col2:
            duration_per_image = st.slider(
                "Duraci√≥n manual por imagen (s)",
                min_value=1.0,
                max_value=15.0,
                value=10.0,
                step=0.5,
                key="batch_duration_manual",
                disabled=use_auto_duration,
                help="Establece una duraci√≥n fija para cada imagen si la duraci√≥n autom√°tica est√° desactivada."
            )
    
    # CONFIGURACI√ìN DE IM√ÅGENES (CONSOLIDADA)
    with st.expander("üñºÔ∏è Configuraci√≥n de Im√°genes", expanded=True):
        st.info("Actualmente configurado para usar Replicate (flux-schnell).")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            img_aspect_ratio = st.selectbox("Aspect Ratio", ["16:9", "1:1", "9:16"], index=0, key="batch_img_aspect")
        with col2:
            img_output_format = st.selectbox("Formato", ["webp", "png", "jpeg"], index=0, key="batch_img_format")
        with col3:
            img_output_quality = st.slider("Calidad", 50, 100, 85, 5, key="batch_img_quality")
        with col4:
            img_megapixels = st.select_slider("Megapixels", ["1", "2", "4"], value="1", key="batch_img_mp")
        
        # Configuraci√≥n movida a la secci√≥n de IA
    
    # CONFIGURACI√ìN DE VIDEO (Transiciones y Efectos)
    with st.expander("üé• Transiciones y Efectos de Video", expanded=True):
        # Transiciones y Fades
        st.subheader("üîÑ Transiciones y Fades")
        col1, col2, col3 = st.columns(3)
        with col1:
            from utils.transitions import TransitionEffect
            transition_type = st.selectbox(
                "Tipo de transici√≥n",
                options=TransitionEffect.get_available_transitions(),
                format_func=lambda x: "Sin transici√≥n" if x == "none" else "Disoluci√≥n" if x == "dissolve" else x.replace('_', ' ').title(),
                index=1,
                key="batch_transition_type"
            )
        with col2:
            transition_duration = st.slider(
                "Duraci√≥n de transici√≥n (s)", 0.0, 5.0, 1.0, 0.1, key="batch_transition_duration"
            )
        with col3:
            fade_in_duration = st.slider(
                "Fade In (s)", 0.0, 5.0, 1.0, 0.1, key="batch_fade_in"
            )
            fade_out_duration = st.slider(
                "Fade Out (s)", 0.0, 5.0, 1.0, 0.1, key="batch_fade_out"
            )

    # EFECTOS Y OVERLAYS
    with st.expander("‚ú® Efectos y Overlays", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("‚ú® Efectos Visuales")
            try:
                effects_sequence = show_effects_ui(key_prefix="batch_")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è La interfaz de efectos no est√° disponible ({e}). Se usar√° configuraci√≥n b√°sica.")
                effects_sequence = []
        
        with col2:
            st.subheader("üñºÔ∏è Superposiciones (Overlays)")
            try:
                overlay_sequence = show_overlays_ui(key_prefix="batch_")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è La interfaz de overlays no est√° disponible ({e}). Se usar√° configuraci√≥n b√°sica.")
                overlay_sequence = []
        
        # Configuraci√≥n avanzada de efectos para batch
        st.markdown("---")
        st.subheader("‚öôÔ∏è Configuraci√≥n Avanzada para Lotes")
        col1, col2 = st.columns(2)
        with col1:
            randomize_effects = st.checkbox(
                "üé≤ Randomizar efectos entre proyectos",
                help="Cada proyecto tendr√° efectos ligeramente diferentes",
                key="batch_randomize_effects"
            )
            if randomize_effects:
                effect_variation = st.slider(
                    "Variaci√≥n de efectos", 0.1, 0.5, 0.2, 0.1, key="batch_effect_variation"
                )
        with col2:
            vary_intensity = st.checkbox(
                "üìä Variar intensidad por proyecto",
                help="La intensidad de efectos aumentar√° gradualmente",
                key="batch_vary_intensity"
            )
            if vary_intensity:
                intensity_range = st.slider(
                    "Rango de intensidad", 0.5, 2.0, (0.8, 1.5), key="batch_intensity_range"
                )

    # Construir el diccionario de configuraci√≥n de video
    video_config = {
        'use_auto_duration': use_auto_duration,
        'duration_per_image_manual': duration_per_image if not use_auto_duration else 10.0,
        'transition_type': transition_type,
        'transition_duration': transition_duration,
        'fade_in': fade_in_duration,
        'fade_out': fade_out_duration,
        'effects': effects_sequence,
        'overlays': overlay_sequence
    }

    # ===== SECCI√ìN 4: CONFIGURACI√ìN DE AUDIO Y SUBT√çTULOS =====
    st.header("4. üîä Configuraci√≥n de Audio y Subt√≠tulos")
    
    # CONFIGURACI√ìN DE AUDIO
    with st.expander("üîä Configuraci√≥n de Audio", expanded=True):
        audio_config = _render_batch_audio_config(app_config)
    
    # CONFIGURACI√ìN DE SUBT√çTULOS
    with st.expander("üìù Configuraci√≥n de Subt√≠tulos", expanded=True):
        subtitles_config = _render_batch_subtitles_config(app_config)

    # ===== SECCI√ìN 5: PROCESAR BATCH =====
    st.header("5. üé¨ Procesar Batch")
    
    # Mostrar resumen antes del procesamiento
    if st.session_state.get("batch_projects"):
        st.subheader("üìã Resumen de Configuraci√≥n")
        
        # M√©tricas principales
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üé¨ Proyectos", len(st.session_state.batch_projects))
        with col2:
            efectos_count = len(video_config.get('effects', [])) if video_config.get('effects') else 0
            st.metric("‚ú® Efectos", efectos_count)
        with col3:
            overlays_count = len(video_config.get('overlays', [])) if video_config.get('overlays') else 0
            st.metric("üñºÔ∏è Overlays", overlays_count)
        with col4:
            music_status = "‚úÖ S√≠" if audio_config.get('bg_music_selection') else "‚ùå No"
            st.metric("üéµ M√∫sica", music_status)
        
        # Detalles de configuraci√≥n
        with st.expander("üîç Ver Detalles de Configuraci√≥n"):
            col_det1, col_det2 = st.columns(2)
            
            with col_det1:
                st.write("**üéµ Audio:**")
                if audio_config.get('bg_music_selection'):
                    try:
                        music_name = Path(audio_config['bg_music_selection']).name
                    except:
                        music_name = audio_config['bg_music_selection']
                    st.write(f"‚Ä¢ M√∫sica: {music_name}")
                    st.write(f"‚Ä¢ Volumen m√∫sica: {audio_config.get('music_volume', 0.06)}")
                else:
                    st.write("‚Ä¢ ‚ùå Sin m√∫sica de fondo")
                
                st.write(f"‚Ä¢ Voz: {audio_config.get('tts_voice', 'N/A')}")
                st.write(f"‚Ä¢ Velocidad: {audio_config.get('tts_speed_percent', 0)}%")
            
            with col_det2:
                st.write("**‚ú® Efectos Visuales:**")
                if efectos_count > 0:
                    st.write(f"‚Ä¢ {efectos_count} efecto(s) configurado(s)")
                else:
                    st.write("‚Ä¢ ‚ùå Sin efectos configurados")
                
                st.write("**üñºÔ∏è Overlays:**")
                if overlays_count > 0:
                    st.write(f"‚Ä¢ {overlays_count} overlay(s) configurado(s)")
                else:
                    st.write("‚Ä¢ ‚ùå Sin overlays configurados")
    
    if st.button("üé¨ PROCESAR TODOS LOS PROYECTOS", type="primary", use_container_width=True):
        if not st.session_state.batch_projects:
            st.warning("‚ö†Ô∏è No hay proyectos para procesar. A√±ade al menos un proyecto.")
            return
        
        # ===== VALIDACIONES ANTES DEL PROCESAMIENTO =====
        validaciones_faltantes = []
        validaciones_recomendadas = []
        continuar_sin_config = False  # Inicializar variable
        
        # Verificar m√∫sica de fondo (recomendado, no obligatorio)
        if not audio_config.get('bg_music_selection'):
            validaciones_recomendadas.append("üéµ **M√∫sica de fondo**: No has seleccionado m√∫sica de fondo")
        
        # Verificar overlays (recomendado, no obligatorio)
        overlays_configurados = video_config.get('overlays', [])
        if not overlays_configurados or len(overlays_configurados) == 0:
            validaciones_recomendadas.append("üñºÔ∏è **Overlays**: No has configurado ning√∫n overlay")
        
        # Verificar efectos (recomendado, no obligatorio)
        efectos_configurados = video_config.get('effects', [])
        if not efectos_configurados or len(efectos_configurados) == 0:
            validaciones_recomendadas.append("‚ú® **Efectos visuales**: No has configurado efectos visuales")
        
        # Mostrar recomendaciones si faltan configuraciones (pero permitir continuar)
        if validaciones_recomendadas:
            st.warning("üí° **Configuraciones recomendadas faltantes:**")
            for validacion in validaciones_recomendadas:
                st.write(f"‚Ä¢ {validacion}")
            
            st.info("‚ÑπÔ∏è **Puedes continuar sin estas configuraciones, pero se recomienda configurarlas para mejores resultados.**")
            
            st.markdown("---")
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("‚öôÔ∏è Configurar Antes de Continuar", type="secondary", use_container_width=True):
                    st.info("üí° **Sugerencias para mejorar tus videos:**")
                    if not audio_config.get('bg_music_selection'):
                        st.write("‚Ä¢ Ve a la secci√≥n **'üîä Configuraci√≥n de Audio'** y selecciona una m√∫sica de fondo")
                    if not overlays_configurados:
                        st.write("‚Ä¢ Ve a la secci√≥n **'‚ú® Efectos y Overlays'** y configura algunos overlays")
                    if not efectos_configurados:
                        st.write("‚Ä¢ Ve a la secci√≥n **'‚ú® Efectos y Overlays'** y configura algunos efectos visuales")
                    return
            
            with col2:
                continuar_sin_config = st.button("üöÄ Continuar de Todas Formas", type="primary", use_container_width=True)
                if not continuar_sin_config:
                    return
                else:
                    st.success("‚úÖ Continuando con la configuraci√≥n actual...")
        else:
            st.success("‚úÖ Todas las configuraciones recomendadas est√°n presentes!")
            # Si no hay configuraciones faltantes, procesar directamente
            continuar_sin_config = True
        
        # Solo procesar si se confirm√≥ continuar
        if not continuar_sin_config:
            return
        
        st.info("üîÑ Iniciando procesamiento por lotes... Esto puede tardar varios minutos.")
        
        # Crear contenedores para la barra de progreso
        progress_container = st.empty()
        status_container = st.empty()
        progress_bar = progress_container.progress(0)
        
        def update_progress(progress: float, message: str):
            progress_bar.progress(progress)
            status_container.text(message)
        
        # Crear carpeta principal de proyectos
        projects_dir = Path("projects")
        projects_dir.mkdir(exist_ok=True)
        update_progress(0.05, "üìÅ Preparando estructura de carpetas...")
        
        resultados = []
        total_projects = len(st.session_state.batch_projects)
        
        # Recopilar configuraci√≥n completa
        batch_config = {
            "script": {
                "provider": script_provider,
                "model": script_model,
                "prompt_obj": script_prompt_obj
            },
            "image": {
                "img_provider": "Replicate",
                "img_model": "black-forest-labs/flux-schnell",
                "img_prompt_provider": img_prompt_provider,
                "img_prompt_model": img_prompt_model,
                "aspect_ratio": img_aspect_ratio,
                "output_format": img_output_format,
                "output_quality": img_output_quality,
                "megapixels": img_megapixels,
                "style": img_style,
                "prompt_obj": img_prompt_obj
            },
            "scenes_config": {
                "segmentation_mode": segmentation_mode,
                "max_scene_duration": max_scene_duration
            },
            "video": video_config,
            "audio": audio_config,
            "subtitles": subtitles_config,
            **optimization_config
        }
        
        # Procesar cada proyecto
        for i, proyecto in enumerate(st.session_state.batch_projects):
            current_progress = (i / total_projects) * 0.9
            update_progress(current_progress, f"üîÑ Procesando {i+1}/{total_projects}: {proyecto['titulo']}")
            
            try:
                resultado = procesar_proyecto_individual(
                    proyecto=proyecto,
                    batch_config=batch_config,
                    progress_callback=lambda prog, msg: update_progress(
                        current_progress + (prog * 0.9 / total_projects),
                        f"üîÑ {proyecto['titulo']}: {msg}"
                    )
                )
                
                resultados.append(resultado)
                
            except Exception as e:
                st.error(f"‚ùå Error procesando '{proyecto['titulo']}': {str(e)}")
                resultados.append({
                    "titulo": proyecto["titulo"],
                    "estado": "error",
                    "error": str(e)
                })
        
        # Progreso final
        update_progress(1.0, "üéâ ¬°Procesamiento completado!")
        
        # Mostrar resultados
        mostrar_resultados_batch(resultados)
        
        # Limpiar autom√°ticamente proyectos completados del CMS de la cola
        proyectos_completados_cms = [r for r in resultados if r.get("cms_updated", False) and r["estado"] == "completado"]
        if proyectos_completados_cms:
            st.session_state.batch_projects = [
                p for p in st.session_state.batch_projects 
                if not (p.get("cms_publicacion_id") in [r.get("cms_publicacion_id") for r in proyectos_completados_cms])
            ]
            st.info(f"üßπ Limpieza autom√°tica: {len(proyectos_completados_cms)} proyecto(s) del CMS eliminados de la cola")
        
        # Limpiar progreso
        progress_container.empty()
        status_container.empty()


def procesar_proyecto_individual(proyecto, batch_config, progress_callback):
    """
    Procesa un proyecto individual del batch con todas las configuraciones reutilizadas.
    """
    try:
        from utils.video_processing import VideoProcessor
        
        progress_callback(0.05, "Preparando procesador de video")
        
        # üèõÔ∏è PROCESAMIENTO ESPECIAL PARA PROMPT HIST√ìRICO
        image_config = batch_config["image"].copy()
        
        # Verificar si se est√° usando el prompt hist√≥rico
        prompt_obj = batch_config["image"].get("prompt_obj", {})
        if prompt_obj and prompt_obj.get("nombre") == "Escenas Fotorrealistas Hist√≥ricamente Precisas":
            progress_callback(0.07, "üèõÔ∏è Analizando contexto hist√≥rico...")
            
            # Obtener configuraci√≥n hist√≥rica del session_state
            historical_config = st.session_state.get("batch_historical_config", {})
            
            if historical_config.get("mode") == "manual":
                # Usar configuraci√≥n manual
                periodo_historico = historical_config.get("periodo_historico", "")
                ubicacion = historical_config.get("ubicacion", "")
                contexto_cultural = historical_config.get("contexto_cultural", "")
                
                progress_callback(0.08, "‚úçÔ∏è Usando configuraci√≥n hist√≥rica manual")
                
            elif historical_config.get("mode") == "auto":
                # Extraer autom√°ticamente con IA
                try:
                    from utils.ai_services import extract_historical_context
                    
                    ai_provider = historical_config.get("ai_provider", "gemini")
                    default_gemini_model = app_config.get('ai', {}).get('default_models', {}).get('gemini', 'models/gemini-1.5-flash-latest')
                    ai_model = historical_config.get("ai_model", default_gemini_model)
                    
                    progress_callback(0.08, f"ü§ñ Extrayendo contexto hist√≥rico con {ai_provider}...")
                    
                    historical_data = extract_historical_context(
                        titulo=proyecto["titulo"],
                        contexto=proyecto["contexto"],
                        provider=ai_provider,
                        model=ai_model
                    )
                    
                    periodo_historico = historical_data.get("periodo_historico", "")
                    ubicacion = historical_data.get("ubicacion", "")
                    contexto_cultural = historical_data.get("contexto_cultural", "")
                    
                    progress_callback(0.09, "‚úÖ Contexto hist√≥rico extra√≠do exitosamente")
                    
                except Exception as e:
                    progress_callback(0.09, f"‚ö†Ô∏è Error extrayendo contexto hist√≥rico: {str(e)}")
                    # Usar valores por defecto si falla
                    periodo_historico = "Informaci√≥n no especificada"
                    ubicacion = "Informaci√≥n no especificada"
                    contexto_cultural = "Informaci√≥n no especificada"
            else:
                # Fallback si no hay configuraci√≥n
                periodo_historico = "Informaci√≥n no especificada"
                ubicacion = "Informaci√≥n no especificada"
                contexto_cultural = "Informaci√≥n no especificada"
            
            # Actualizar la configuraci√≥n de imagen con las variables hist√≥ricas
            image_config["prompt_obj"] = prompt_obj  # Mantener el prompt original
            image_config["historical_context"] = {
                "periodo_historico": periodo_historico,
                "ubicacion": ubicacion,
                "contexto_cultural": contexto_cultural,
                "extraction_mode": historical_config.get("mode", "fallback")
            }
            
            # A√±adir las variables hist√≥ricas a las variables disponibles para el prompt
            image_config["historical_variables"] = {
                "periodo_historico": periodo_historico,
                "ubicacion": ubicacion,
                "contexto_cultural": contexto_cultural
            }

        # Preparar configuraci√≥n completa para el procesador
        full_config = {
            "titulo": proyecto["titulo"],
            "contexto": proyecto["contexto"],
            "script": {
                "mode": "Proporcionar Manualmente" if proyecto.get("script_type") == "‚úçÔ∏è Usar gui√≥n manual" else "Generar con IA",
                "manual_script": proyecto.get("guion_manual"),
                **batch_config["script"]
            },
            "image": image_config,  # Usar la configuraci√≥n de imagen actualizada
            "scenes_config": batch_config["scenes_config"],
            "video": batch_config["video"],
            "audio": batch_config["audio"],
            "subtitles": batch_config["subtitles"],
            # A√±adir configuraci√≥n de optimizaci√≥n
            "generate_optimized_content": batch_config.get("generate_optimized_content", False),
            "use_same_style": batch_config.get("use_same_style", False),
            "generate_series_tags": batch_config.get("generate_series_tags", False)
        }
        
        progress_callback(0.1, "Iniciando procesamiento con VideoProcessor...")
        
        # Usar el VideoProcessor del generador individual
        processor = VideoProcessor(config=batch_config)
        result_path = processor.process_single_video(full_config)
        
        progress_callback(1.0, "¬°Completado!")
        
        # Obtener directorio del proyecto desde el result_path
        if result_path:
            proyecto_dir = Path(result_path).parent.parent  # video/file.mp4 -> project_dir
            
            # Guardar metadata del proyecto
            metadata = {
                "titulo": proyecto["titulo"],
                "contexto": proyecto["contexto"],
                "script_type": proyecto.get("script_type"),
                "fecha_procesado": datetime.now().isoformat(),
                "config_used": full_config,
                "cms_info": {
                    "publicacion_id": proyecto.get("cms_publicacion_id"),
                    "canal": proyecto.get("cms_canal")
                } if "cms_publicacion_id" in proyecto else None
            }
            
            metadata_path = proyecto_dir / "batch_metadata.json"
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # Actualizar estado en CMS si el proyecto viene del CMS
            cms_updated = False
            if "cms_publicacion_id" in proyecto:
                try:
                    # Importar y usar DatabaseManager para actualizar estado
                    import sys
                    project_root = Path(__file__).resolve().parent.parent
                    if str(project_root) not in sys.path:
                        sys.path.append(str(project_root))
                    
                    from utils.database_manager import DatabaseManager
                    db_manager = DatabaseManager()
                    db_manager.update_publicacion_status(
                        proyecto["cms_publicacion_id"], 
                        'Generado', 
                        str(proyecto_dir)
                    )
                    cms_updated = True
                    print(f"‚úÖ CMS actualizado: Publicaci√≥n {proyecto['cms_publicacion_id']} ‚Üí 'Generado'")
                    
                    # Tambi√©n actualizar el metadata con el resultado
                    metadata["cms_update_result"] = "success"
                    metadata["cms_update_timestamp"] = datetime.now().isoformat()
                    
                except Exception as e:
                    # Si falla la actualizaci√≥n del CMS, continuar pero registrar el error
                    print(f"‚ùå Error actualizando CMS: {e}")
                    import traceback
                    traceback.print_exc()
                    
                    # Guardar error en metadata
                    metadata["cms_update_result"] = "error"
                    metadata["cms_update_error"] = str(e)
                    metadata["cms_update_timestamp"] = datetime.now().isoformat()
                    
                # Re-escribir metadata con informaci√≥n de CMS
                try:
                    with open(metadata_path, "w", encoding="utf-8") as f:
                        json.dump(metadata, f, indent=2, ensure_ascii=False)
                except Exception as e:
                    print(f"Warning: No se pudo actualizar metadata: {e}")
            
            return {
                "titulo": proyecto["titulo"],
                "estado": "completado",
                "video_path": str(result_path) if result_path else None,
                "proyecto_dir": str(proyecto_dir),
                "metadata": metadata,
                "cms_updated": cms_updated,
                "cms_publicacion_id": proyecto.get("cms_publicacion_id")
            }
        else:
            return {
                "titulo": proyecto["titulo"],
                "estado": "error",
                "error": "No se gener√≥ video final"
            }
        
    except Exception as e:
        return {
            "titulo": proyecto["titulo"],
            "estado": "error",
            "error": str(e)
        }


def mostrar_resultados_batch(resultados):
    """
    Muestra los resultados del procesamiento por lotes.
    """
    st.header("üìä Resultados del Procesamiento")
    
    # Resumen general
    total = len(resultados)
    completados = len([r for r in resultados if r["estado"] == "completado"])
    errores = len([r for r in resultados if r["estado"] == "error"])
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üìä Total", total)
    with col2:
        st.metric("‚úÖ Completados", completados)
    with col3:
        st.metric("‚ùå Errores", errores)
    
    # Mostrar cada resultado
    for resultado in resultados:
        if resultado["estado"] == "completado":
            st.success(f"‚úÖ **{resultado['titulo']}** - ¬°Completado exitosamente!")
            
            # Mostrar informaci√≥n del video generado
            if "video_path" in resultado and resultado["video_path"]:
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.write(f"üìÅ **Carpeta:** {resultado.get('proyecto_dir', 'N/A')}")
                    st.write(f"üé• **Video:** {resultado['video_path']}")
                    
                    # Mostrar el video si existe
                    if Path(resultado['video_path']).exists():
                        st.video(resultado['video_path'])
                    
                    # Mostrar metadata si est√° disponible
                    if "metadata" in resultado:
                        metadata = resultado["metadata"]
                        with st.expander("üìã Detalles del proyecto"):
                            st.json(metadata)
                
                with col2:
                    # Bot√≥n para descargar si existe el archivo
                    if Path(resultado['video_path']).exists():
                        with open(resultado['video_path'], "rb") as f:
                            st.download_button(
                                "‚¨áÔ∏è Descargar Video",
                                f,
                                file_name=f"{resultado['titulo']}.mp4",
                                mime="video/mp4",
                                key=f"download_{resultado['titulo']}"
                            )
            
        else:  # Error
            st.error(f"‚ùå **{resultado['titulo']}** - Error durante el procesamiento")
            if "error" in resultado:
                st.code(resultado["error"])
        
        st.markdown("---")
    
    # Opciones post-procesamiento
    st.subheader("üìã Acciones")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üßπ Limpiar cola de proyectos"):
            st.session_state.batch_projects = []
            st.success("‚úÖ Cola limpiada!")
            st.rerun()
    
    with col2:
        if completados > 0:
            st.success(f"üéâ ¬°{completados} video(s) generado(s) exitosamente!")
            st.info("üí° Los videos est√°n guardados en la carpeta 'projects/'")

def _render_batch_audio_config(app_config):
    """Configuraci√≥n de audio espec√≠fica para batch (sin duplicaciones de UI)"""
    
    # --- SELECCI√ìN DE PROVEEDOR TTS ---
    st.markdown("**üé§ S√≠ntesis de Voz (TTS)**")
    
    # Obtener configuraci√≥n TTS desde config.yaml
    tts_defaults = app_config.get('tts', {})
    default_provider = tts_defaults.get('default_provider', 'edge')
    
    # Seleccionar proveedor TTS
    provider_options = ["Edge TTS", "Fish Audio"]
    provider_mapping = {"edge": "Edge TTS", "fish": "Fish Audio"}
    default_provider_ui = provider_mapping.get(default_provider, "Edge TTS")
    provider_index = provider_options.index(default_provider_ui) if default_provider_ui in provider_options else 0
    
    tts_provider = st.selectbox(
        "Proveedor TTS",
        provider_options,
        index=provider_index,
        key="batch_tts_provider",
        help="Edge TTS: Gratuito, voces de Microsoft. Fish Audio: Calidad premium, requiere API key."
    )
    
    # Configuraci√≥n espec√≠fica seg√∫n el proveedor
    if tts_provider == "Edge TTS":
        # --- CONFIGURACI√ìN EDGE TTS ---
        col_voz1, col_voz2, col_voz3, col_voz4 = st.columns(4)
        
        async def obtener_voces_es_tts():
            voces = await edge_tts.list_voices()
            return [(v['ShortName'], v['Name']) for v in voces if v['Locale'].startswith('es-')]

        try:
            voces_esp_tuplas = asyncio.run(obtener_voces_es_tts())
            nombres_cortos = [v[0] for v in voces_esp_tuplas]
            nombres_completos = [v[1] for v in voces_esp_tuplas]
            default_voice_short = app_config.get("ai", {}).get("default_models", {}).get("voice", "es-ES-AlvaroNeural")
            voice_index = nombres_cortos.index(default_voice_short) if default_voice_short in nombres_cortos else 0
        except Exception as e:
            st.warning(f"No se pudieron cargar las voces de EdgeTTS: {e}. Usando default.")
            nombres_cortos = ["es-ES-AlvaroNeural"]
            nombres_completos = ["Microsoft Server Speech Text to Speech Voice (es-ES, AlvaroNeural)"]
            voice_index = 0

        with col_voz1:
            selected_voice_short = st.selectbox("Voz", nombres_cortos, index=voice_index, key="batch_tts_voice")
            tts_voice = nombres_completos[nombres_cortos.index(selected_voice_short)]
             
        with col_voz2:
            edge_defaults = tts_defaults.get('edge', {})
            default_rate = edge_defaults.get('default_rate', '+0%')
            # Convertir formato +X% a n√∫mero
            rate_value = int(default_rate.replace('%', '').replace('+', '')) if default_rate != '+0%' else 0
            tts_speed_percent = st.slider("Velocidad (%)", -50, 50, rate_value, 1, key="batch_tts_speed")
        with col_voz3:
            default_pitch = edge_defaults.get('default_pitch', '+0Hz')
            # Convertir formato +XHz a n√∫mero
            pitch_value = int(default_pitch.replace('Hz', '').replace('+', '')) if default_pitch != '+0Hz' else 0
            tts_pitch_hz = st.slider("Tono (Hz)", -50, 50, pitch_value, 1, key="batch_tts_pitch")
        with col_voz4:
            default_volume = app_config.get('video_generation', {}).get('audio', {}).get('default_voice_volume', 1.0)
            tts_volume = st.slider("Volumen Voz", 0.0, 2.0, default_volume, 0.1, key="batch_tts_volume")
        
        # Configuraci√≥n para Edge TTS
        tts_config = {
            'tts_provider': 'edge',
            'tts_voice': tts_voice,
            'tts_speed_percent': tts_speed_percent,
            'tts_pitch_hz': tts_pitch_hz,
            'tts_volume': tts_volume
        }
        
    else:  # Fish Audio
        # --- CONFIGURACI√ìN FISH AUDIO ---
        st.info("üêü **Fish Audio**: Calidad premium de s√≠ntesis de voz. Requiere API key configurada.")
        
        # Verificar si Fish Audio est√° disponible
        try:
            from utils.audio_services import FISH_AUDIO_AVAILABLE
            if not FISH_AUDIO_AVAILABLE:
                st.error("‚ùå Fish Audio SDK no est√° disponible. Instala 'fish-audio-sdk' para usar Fish Audio TTS.")
                st.stop()
        except ImportError:
            st.error("‚ùå No se pudo verificar la disponibilidad de Fish Audio.")
            st.stop()
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Modelo de Fish Audio
            fish_models = [
                ("speech-1.5", "Fish Audio Speech 1.5"),
                ("speech-1.6", "Fish Audio Speech 1.6 (Recomendado)"),
                ("s1", "Fish Audio S1")
            ]
            selected_fish_model = st.selectbox(
                "Modelo",
                [m[0] for m in fish_models],
                index=1,  # speech-1.6 por defecto
                key="batch_fish_model",
                format_func=lambda x: dict(fish_models)[x]
            )
            
            # Formato de salida
            fish_format = st.selectbox(
                "Formato",
                ["mp3", "wav", "pcm"],
                index=0,
                key="batch_fish_format"
            )
            
            # Bitrate para MP3
            fish_defaults = tts_defaults.get('fish_audio', {})
            default_bitrate = fish_defaults.get('default_mp3_bitrate', 128)
            bitrate_options = [64, 128, 192]
            bitrate_index = bitrate_options.index(default_bitrate) if default_bitrate in bitrate_options else 1
            fish_bitrate = st.selectbox(
                "Bitrate MP3",
                bitrate_options,
                index=bitrate_index,
                key="batch_fish_bitrate",
                disabled=(fish_format != "mp3")
            )
        
        with col2:
            # Latencia
            default_latency = fish_defaults.get('default_latency', 'normal')
            latency_options = ["normal", "balanced"]
            latency_index = latency_options.index(default_latency) if default_latency in latency_options else 0
            fish_latency = st.selectbox(
                "Latencia",
                latency_options,
                index=latency_index,
                key="batch_fish_latency",
                help="Normal: Mayor estabilidad. Balanced: Menor latencia (300ms)"
            )
            
            # Normalizar texto
            default_normalize = fish_defaults.get('default_normalize', True)
            fish_normalize = st.checkbox(
                "Normalizar texto",
                default_normalize,
                key="batch_fish_normalize",
                help="Mejora la estabilidad para n√∫meros y texto en ingl√©s/chino"
            )
            
            # Volumen
            default_volume = app_config.get('video_generation', {}).get('audio', {}).get('default_voice_volume', 1.0)
            tts_volume = st.slider("Volumen Voz", 0.0, 2.0, default_volume, 0.1, key="batch_tts_volume")
        
        # Configuraci√≥n para Fish Audio
        tts_config = {
            'tts_provider': 'fish',
            'tts_fish_model': selected_fish_model,
            'tts_fish_format': fish_format,
            'tts_fish_bitrate': fish_bitrate,
            'tts_fish_latency': fish_latency,
            'tts_fish_normalize': fish_normalize,
            'tts_volume': tts_volume
        }

    # --- M√öSICA DE FONDO ---
    st.markdown("**üéµ M√∫sica de Fondo**")
    col_music1, col_music2 = st.columns(2)
    
    with col_music1:
        bg_music_folder = Path("background_music")
        available_music = ["**Ninguna**"] + ([f.name for f in bg_music_folder.iterdir() if f.suffix.lower() in ['.mp3', '.wav']] if bg_music_folder.exists() else [])
        
        # Obtener m√∫sica por defecto desde config.yaml
        audio_defaults = app_config.get('video_generation', {}).get('audio', {})
        default_bg_music = audio_defaults.get('background_music', '')
        default_music_name = Path(default_bg_music).name if default_bg_music else None
        
        # Establecer √≠ndice por defecto
        default_index = 0  # "**Ninguna**" por defecto
        if default_music_name and default_music_name in available_music:
            default_index = available_music.index(default_music_name)
        
        sel_music = st.selectbox("M√∫sica Fondo", available_music, index=default_index, key="batch_bg_music")
        bg_music_selection = str(bg_music_folder / sel_music) if sel_music != "**Ninguna**" else None
        
    with col_music2:
        # Obtener configuraci√≥n de audio desde config.yaml
        audio_defaults = app_config.get('video_generation', {}).get('audio', {})
        default_music_volume = audio_defaults.get('default_music_volume', 0.08)
        music_volume = st.slider("Volumen M√∫sica", 0.0, 1.0, default_music_volume, 0.01, "%.2f", key="batch_music_vol", disabled=(not bg_music_selection))
        music_loop = st.checkbox("Loop M√∫sica", True, key="batch_music_loop", disabled=(not bg_music_selection))

    # Combinar configuraci√≥n TTS con m√∫sica
    audio_config = {
        **tts_config,
        'bg_music_selection': bg_music_selection,
        'music_volume': music_volume,
        'music_loop': music_loop
    }
    
    return audio_config

def _render_batch_subtitles_config(app_config):
    """Configuraci√≥n de subt√≠tulos espec√≠fica para batch usando valores de config.yaml como defaults"""
    
    # Obtener configuraci√≥n de subt√≠tulos desde config.yaml
    subtitles_defaults = app_config.get('video_generation', {}).get('subtitles', {})
    
    sub_config = {}
    sub_config['enable'] = st.checkbox("Incrustar Subt√≠tulos", subtitles_defaults.get('enable', True), key="batch_sub_enable")
    
    if sub_config['enable']:
        col1, col2, col3 = st.columns(3)
        with col1:
            try:
                available_fonts = get_available_fonts()
                default_font = subtitles_defaults.get('font', 'Arial')
                font_index = available_fonts.index(default_font) if default_font in available_fonts else 0
            except:
                available_fonts = ["Arial", "Helvetica", "Times New Roman", "Calibri", "Impact"]
                default_font = subtitles_defaults.get('font', 'Arial')
                font_index = available_fonts.index(default_font) if default_font in available_fonts else 0
                
            sub_config['font'] = st.selectbox("Fuente", available_fonts, index=font_index, key="batch_sub_font")
            sub_config['size'] = st.slider("Tama√±o", 16, 72, subtitles_defaults.get('font_size', 24), key="batch_sub_size")
        with col2:
            sub_config['color'] = st.color_picker("Color Texto", subtitles_defaults.get('font_color', '#FFFFFF'), key="batch_sub_color")
            sub_config['stroke_color'] = st.color_picker("Color Borde", subtitles_defaults.get('stroke_color', '#000000'), key="batch_sub_stroke_color")
        with col3:
            sub_config['stroke_width'] = st.slider("Grosor Borde", 0, 5, int(subtitles_defaults.get('stroke_width', 1.5)), key="batch_sub_stroke_width")
            position_options = ["bottom", "center", "top"]
            default_position = subtitles_defaults.get('position', 'bottom')
            position_index = position_options.index(default_position) if default_position in position_options else 0
            sub_config['position'] = st.selectbox("Posici√≥n", position_options, index=position_index, key="batch_sub_pos")
            
        sub_config['max_words'] = st.slider("M√°x. Palabras por Segmento", 1, 10, subtitles_defaults.get('max_words', 7), key="batch_sub_max_words")
        st.caption("Controla cu√°ntas palabras aparecen juntas en pantalla.")
        
    return sub_config