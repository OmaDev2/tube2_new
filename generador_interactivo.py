#!/usr/bin/env python3
"""
GENERADOR INTERACTIVO DE PROMPTS HISTÃ“RICOS
Flujo completo: Script â†’ TranscripciÃ³n â†’ Escenas â†’ Prompts
"""

import sys
import json
import re
from pathlib import Path
from datetime import datetime
from typing import List, Dict

# Agregar la ruta de utils al path
sys.path.append(str(Path(__file__).parent))

from utils.scene_generator import SceneGenerator
from utils.ai_services import AIServices, extract_historical_context

class GeneradorInteractivo:
    def __init__(self):
        self.ai_services = AIServices()
        self.scene_generator = SceneGenerator()
        
    def mostrar_banner(self):
        print("=" * 80)
        print("ğŸ¬  GENERADOR INTERACTIVO DE PROMPTS HISTÃ“RICOS")
        print("=" * 80)
        print("ğŸ“ Flujo: Script â†’ TranscripciÃ³n â†’ Escenas Narrativas â†’ Prompts")
        print("ğŸ§  Usa el nuevo algoritmo de segmentaciÃ³n inteligente")
        print("â±ï¸  Optimizado para imÃ¡genes de 10-12 segundos")
        print("-" * 80)
    
    def solicitar_script(self) -> str:
        print("\nğŸ“– PASO 1: SCRIPT DE ENTRADA")
        print("-" * 40)
        print("Pega tu script histÃ³rico aquÃ­ (Enter doble para terminar):")
        print("Ejemplo: 'Santa Teresa de Ãvila escribiÃ³ Las Moradas en su celda...'")
        print()
        
        lines = []
        while True:
            try:
                line = input()
                if line.strip() == "" and len(lines) > 0:
                    break
                lines.append(line)
            except KeyboardInterrupt:
                print("\nâŒ Cancelado por el usuario")
                sys.exit(0)
        
        script = "\n".join(lines).strip()
        
        if not script:
            print("âŒ Error: No se proporcionÃ³ ningÃºn script")
            return self.solicitar_script()
        
        print(f"\nâœ… Script recibido ({len(script)} caracteres)")
        return script
    
    def simular_transcripcion(self, script: str) -> List[Dict]:
        print("\nğŸ™ï¸  PASO 2: SIMULACIÃ“N DE TRANSCRIPCIÃ“N")
        print("-" * 40)
        
        # Dividir el script en frases
        sentences = re.split(r'(?<=[.!?])\s+', script)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # Estimar duraciÃ³n por frase (promedio 3-4 segundos por frase)
        transcription_segments = []
        current_time = 0.0
        
        for sentence in sentences:
            # Estimar duraciÃ³n basada en longitud (mÃ¡s realista)
            words = len(sentence.split())
            duration = max(2.0, min(6.0, words * 0.4))  # 2-6 segundos por frase
            
            transcription_segments.append({
                "text": sentence,
                "start": current_time,
                "end": current_time + duration
            })
            current_time += duration
        
        total_duration = current_time
        
        print(f"ğŸ“Š TranscripciÃ³n simulada:")
        print(f"   â€¢ {len(transcription_segments)} segmentos")
        print(f"   â€¢ DuraciÃ³n total: {total_duration:.1f} segundos")
        print(f"   â€¢ Promedio por segmento: {total_duration/len(transcription_segments):.1f}s")
        
        return transcription_segments
    
    def extraer_contexto_historico(self, script: str) -> Dict:
        print("\nğŸ›ï¸  PASO 3: EXTRACCIÃ“N DE CONTEXTO HISTÃ“RICO")
        print("-" * 40)
        
        # Detectar tÃ­tulo/personaje principal
        lines = script.split('\n')
        titulo = "Contenido histÃ³rico"
        
        # Buscar nombres de santos, personajes histÃ³ricos, etc.
        historical_names = [
            'santa teresa', 'san ignacio', 'leonardo da vinci', 'san francisco',
            'san blas', 'napoleon', 'juana de arco', 'san juan', 'santa mÃ³nica'
        ]
        
        for name in historical_names:
            if name.lower() in script.lower():
                titulo = name.title()
                break
        
        print(f"ğŸ” Detectando contexto histÃ³rico para: '{titulo}'")
        print("â³ Analizando con IA (puede tardar 10-20 segundos)...")
        print("   ğŸ“¡ Enviando consulta al modelo de IA...")
        
        try:
            import time
            start_time = time.time()
            
            # Mostrar progreso simulado mientras se procesa
            print("   ğŸ§  Modelo analizando texto histÃ³rico...", end="", flush=True)
            
            contexto_historico = extract_historical_context(titulo, script)
            
            elapsed_time = time.time() - start_time
            print(f" âœ… ({elapsed_time:.1f}s)")
            
            print("\nğŸ“‹ Contexto histÃ³rico extraÃ­do:")
            for key, value in contexto_historico.items():
                print(f"   â€¢ {key}: {value}")
            
            return contexto_historico
            
        except Exception as e:
            print(f"\nâš ï¸  Error extrayendo contexto: {e}")
            print("ğŸ”„ Usando contexto histÃ³rico de fallback...")
            return self._contexto_fallback()
    
    def _contexto_fallback(self) -> Dict:
        return {
            "periodo_historico": "Siglo XVI",
            "ubicacion": "EspaÃ±a",
            "contexto_cultural": "Renacimiento espaÃ±ol",
            "fecha_nacimiento": "1515",
            "fecha_muerte": "1582", 
            "edad_personaje": "45"
        }
    
    def generar_escenas_narrativas(self, transcription_segments: List[Dict]) -> List[Dict]:
        print("\nğŸ¬ PASO 4: GENERACIÃ“N DE ESCENAS NARRATIVAS")
        print("-" * 40)
        print("ğŸ§  Usando algoritmo de segmentaciÃ³n inteligente...")
        
        # Usar el nuevo algoritmo mejorado
        scenes = self.scene_generator._create_semantic_scenes(
            transcription_segments, 
            target_duration=11.0
        )
        
        print(f"\nğŸ“Š Escenas generadas: {len(scenes)}")
        
        # Mostrar resumen
        for i, scene in enumerate(scenes):
            status_icon = "âœ…" if scene['duration'] <= 12 else "âš ï¸" if scene['duration'] <= 15 else "âŒ"
            unit_info = ""
            if 'narrative_unit' in scene and 'visual_moment' in scene:
                unit_info = f" [U{scene['narrative_unit']}-M{scene['visual_moment']}]"
            
            print(f"   {status_icon} Escena {i+1}: {scene['duration']:.1f}s{unit_info}")
            print(f"      ğŸ“ {scene['text'][:60]}...")
        
        return scenes
    
    def generar_prompts_historicos(self, scenes: List[Dict], contexto_historico: Dict) -> List[Dict]:
        print("\nğŸ¨ PASO 5: GENERACIÃ“N DE PROMPTS HISTÃ“RICOS")
        print("-" * 40)
        
        # ConfiguraciÃ³n de prompts de imagen
        project_info = {
            "titulo": "Video HistÃ³rico Interactivo",
            "descripcion": "Generado con algoritmo de segmentaciÃ³n inteligente",
            "contexto_historico": contexto_historico
        }
        
        image_prompt_config = {
            "provider": "gemini",
            "model": "models/gemini-2.5-flash-lite-preview-06-17",
            "style": "historical_realistic",
            "quality": "high",
            "aspect_ratio": "16:9"
        }
        
        print(f"â³ Generando prompts para {len(scenes)} escenas...")
        print("   (Cada prompt puede tardar 3-5 segundos)")
        
        try:
            import time
            start_time = time.time()
            
            print("   ğŸ¨ Generando prompts con contexto histÃ³rico...", end="", flush=True)
            
            scenes_with_prompts = self.scene_generator.generate_prompts_for_scenes(
                scenes, project_info, image_prompt_config, self.ai_services
            )
            
            elapsed_time = time.time() - start_time
            print(f" âœ… ({elapsed_time:.1f}s)")
            
            print(f"âœ… Prompts generados para {len(scenes_with_prompts)} escenas")
            return scenes_with_prompts
            
        except Exception as e:
            print(f"\nâš ï¸  Error generando prompts: {e}")
            print("ğŸ”„ Generando prompts bÃ¡sicos como fallback...")
            # Generar prompts bÃ¡sicos como fallback
            return self._generar_prompts_basicos(scenes, contexto_historico)
    
    def _generar_prompts_basicos(self, scenes: List[Dict], contexto: Dict) -> List[Dict]:
        """Genera prompts bÃ¡sicos como fallback"""
        for scene in scenes:
            scene['image_prompt'] = f"""
            Imagen histÃ³rica realista del {contexto['periodo_historico']} en {contexto['ubicacion']}.
            Escena: {scene['text'][:100]}...
            Estilo: pintura renacentista, iluminaciÃ³n natural, colores histÃ³ricos autÃ©nticos.
            Edad del personaje: {contexto['edad_personaje']} aÃ±os.
            """
        return scenes
    
    def mostrar_resultados_finales(self, scenes_with_prompts: List[Dict]):
        print("\n" + "="*80)
        print("ğŸ¯ RESULTADOS FINALES")
        print("="*80)
        
        total_duration = sum(scene['duration'] for scene in scenes_with_prompts)
        avg_duration = total_duration / len(scenes_with_prompts)
        
        ideal_count = sum(1 for s in scenes_with_prompts if s['duration'] <= 12)
        acceptable_count = sum(1 for s in scenes_with_prompts if 12 < s['duration'] <= 15)
        
        print(f"ğŸ“Š ESTADÃSTICAS:")
        print(f"   â€¢ Total de escenas: {len(scenes_with_prompts)}")
        print(f"   â€¢ DuraciÃ³n total: {total_duration:.1f}s")
        print(f"   â€¢ DuraciÃ³n promedio: {avg_duration:.1f}s")
        print(f"   â€¢ Escenas ideales (â‰¤12s): {ideal_count} ({ideal_count/len(scenes_with_prompts)*100:.1f}%)")
        print(f"   â€¢ Escenas aceptables (12-15s): {acceptable_count}")
        
        print(f"\nğŸ¬ ESCENAS DETALLADAS:")
        print("-" * 80)
        
        for i, scene in enumerate(scenes_with_prompts):
            print(f"\nğŸ­ ESCENA {i+1} ({scene['duration']:.1f}s)")
            print(f"   â±ï¸  Tiempo: {scene['start']:.1f}s - {scene['end']:.1f}s")
            
            if 'narrative_unit' in scene:
                print(f"   ğŸ“– Unidad Narrativa: {scene['narrative_unit']}, Momento Visual: {scene.get('visual_moment', 1)}")
            
            print(f"   ğŸ“ Texto: {scene['text']}")
            
            if 'image_prompt' in scene:
                prompt_preview = scene['image_prompt'][:150].replace('\n', ' ').strip()
                print(f"   ğŸ¨ Prompt: {prompt_preview}...")
            
            print("-" * 40)
    
    def guardar_resultados(self, scenes_with_prompts: List[Dict], contexto_historico: Dict):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"generacion_interactiva_{timestamp}.json"
        
        data = {
            "timestamp": timestamp,
            "contexto_historico": contexto_historico,
            "estadisticas": {
                "total_escenas": len(scenes_with_prompts),
                "duracion_total": sum(s['duration'] for s in scenes_with_prompts),
                "duracion_promedio": sum(s['duration'] for s in scenes_with_prompts) / len(scenes_with_prompts)
            },
            "escenas": scenes_with_prompts
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            print(f"\nğŸ’¾ Resultados guardados en: {filename}")
            
        except Exception as e:
            print(f"âš ï¸  Error guardando archivo: {e}")
    
    def ejecutar_flujo_completo(self):
        try:
            # Mostrar banner
            self.mostrar_banner()
            
            # Paso 1: Obtener script
            script = self.solicitar_script()
            
            # Paso 2: Simular transcripciÃ³n
            transcription_segments = self.simular_transcripcion(script)
            
            # Paso 3: Extraer contexto histÃ³rico
            contexto_historico = self.extraer_contexto_historico(script)
            
            # Paso 4: Generar escenas narrativas
            scenes = self.generar_escenas_narrativas(transcription_segments)
            
            # Paso 5: Generar prompts histÃ³ricos
            scenes_with_prompts = self.generar_prompts_historicos(scenes, contexto_historico)
            
            # Paso 6: Mostrar resultados
            self.mostrar_resultados_finales(scenes_with_prompts)
            
            # Paso 7: Guardar resultados
            self.guardar_resultados(scenes_with_prompts, contexto_historico)
            
            print("\nğŸ‰ Â¡GeneraciÃ³n completada exitosamente!")
            
        except KeyboardInterrupt:
            print("\n\nâŒ Proceso cancelado por el usuario")
        except Exception as e:
            print(f"\nâŒ Error durante la ejecuciÃ³n: {e}")
            import traceback
            traceback.print_exc()

def main():
    generador = GeneradorInteractivo()
    generador.ejecutar_flujo_completo()

if __name__ == "__main__":
    main() 