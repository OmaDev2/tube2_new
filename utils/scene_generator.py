# utils/scene_generator.py
import json
from pathlib import Path
from typing import List, Dict, Optional, Callable
import logging
import math
import os
import yaml
import datetime # Added for save_scenes
import re

# Importar AIServices desde el m√≥dulo correcto
try:
    from utils.ai_services import AIServices
except ImportError:
    logging.error("No se pudo importar AIServices desde utils.ai_services.")
    # Define un placeholder si no se encuentra para evitar errores al cargar
    class AIServices:
        def generate_content(self, *args, **kwargs):
            return "[ERROR] AIServices no disponible."

logger = logging.getLogger(__name__)

# --- NUEVA CONSTANTE ---
# Si una escena dura m√°s que esto (en segundos), se subdividir√° para mantener el dinamismo.
MAX_SCENE_DURATION = 12.0

class SceneGenerator:
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or self._load_void_config()
        self.video_gen_config = self.config.get('video_generation', {})
        # AIServices ahora se pasar√° como argumento donde se necesite
        # para evitar inicializarlo si no se usa.
        # self.ai_service = AIServices() 
        self.duration_per_image = self.video_gen_config.get('timing', {}).get('default_duration_per_image', 10.0)
        logger.info(f"SceneGenerator inicializado con duraci√≥n/imagen base: {self.duration_per_image:.2f}s")

    def _load_void_config(self) -> Dict:
        try:
            root_dir = Path(__file__).resolve().parent.parent
            voidrules_path = root_dir / ".voidrules"
            if not voidrules_path.exists():
                logger.warning(f".voidrules file not found at {voidrules_path}. Returning empty config.")
                return {}
            with open(voidrules_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.error(f"Error cargando .voidrules en SceneGenerator: {e}", exc_info=True)
            return {} # Devolver config vac√≠a en caso de error

    def set_duration_per_image(self, duration: float):
        """Actualiza la duraci√≥n por imagen."""
        self.duration_per_image = max(1.0, duration) # Asegura m√≠nimo 1s
        logger.info(f"Duraci√≥n por imagen actualizada a {self.duration_per_image:.2f} segundos")
        return self.duration_per_image

    def calculate_optimal_duration(self, audio_duration: float, desired_num_images: Optional[int] = None, transition_duration: float = 1.0, transition_type: str = "dissolve") -> float:
        if desired_num_images is None:
             estimated_images = self.estimate_num_images(audio_duration) 
             if estimated_images == 0: return self.duration_per_image 
             desired_num_images = estimated_images

        if desired_num_images <= 0: # Avoid division by zero or invalid calculations
            logger.warning("calculate_optimal_duration: desired_num_images es 0 o negativo. Devolviendo duraci√≥n base.")
            return self.duration_per_image

        if transition_type.lower() == "none" or transition_duration <= 0 or desired_num_images <= 1:
            optimal_duration = audio_duration / desired_num_images
        else:
            total_overlap = (desired_num_images - 1) * transition_duration
            effective_audio_duration = audio_duration + total_overlap
            optimal_duration = effective_audio_duration / desired_num_images

        optimal_duration = max(min(optimal_duration, 30.0), 5.0) 
        logger.info(f"Duraci√≥n √≥ptima calculada por imagen: {optimal_duration:.2f}s para {desired_num_images} im√°genes y {audio_duration:.2f}s de audio.")
        return optimal_duration

    def estimate_num_images(self, audio_duration: float, min_images: int = 4, max_duration_per_image: float = 15.0) -> int:
        if audio_duration <= 0: return min_images
        if max_duration_per_image <= 0: max_duration_per_image = 15.0
        
        num_images = max(min_images, int(math.ceil(audio_duration / max_duration_per_image)))
        logger.info(f"Estimadas {num_images} im√°genes para {audio_duration:.2f}s de audio (max_dur_img: {max_duration_per_image}s).")
        return num_images

    def _segment_transcription_by_duration(self, transcription_segments: List[Dict], target_duration: float) -> List[Dict]:
        if not transcription_segments:
            return []
        
        timed_scenes = []
        current_scene_text_list = []
        current_scene_start_time = transcription_segments[0].get('start', 0) # Default to 0 if not present
        current_scene_accumulated_duration = 0
        scene_idx = 0

        for i, seg in enumerate(transcription_segments):
            seg_text = seg.get('text', '').strip()
            seg_start = seg.get('start')
            seg_end = seg.get('end')
            
            if seg_text is None or seg_start is None or seg_end is None: 
                logger.warning(f"Saltando segmento inv√°lido en transcripci√≥n (faltan claves start/end/text): {seg}")
                continue
            
            seg_duration = seg_end - seg_start
            if seg_duration < 0:
                logger.warning(f"Segmento con duraci√≥n negativa: {seg}. Saltando.")
                continue

            # Condition to finalize the current scene
            # Finalize if:
            # 1. Current scene is not empty AND adding the current segment would make it too long (e.g., > 125% of target)
            # 2. It's the last segment (must be added to some scene)
            finalize_this_scene = False
            if current_scene_text_list and (current_scene_accumulated_duration + seg_duration > target_duration * 1.25):
                finalize_this_scene = True
            
            if i == len(transcription_segments) - 1: # If it's the last segment
                current_scene_text_list.append(seg_text)
                current_scene_accumulated_duration += seg_duration
                finalize_this_scene = True # Force finalization

            if finalize_this_scene:
                scene_text_final = " ".join(current_scene_text_list)
                scene_end_time = current_scene_start_time + current_scene_accumulated_duration
                
                timed_scenes.append({
                    'index': scene_idx,
                    'text': scene_text_final.strip(),
                    'start': current_scene_start_time,
                    'end': scene_end_time,
                    'duration': current_scene_accumulated_duration
                })
                scene_idx += 1
                
                # Reset for the next scene (if the current segment was not the one that got included in the finalized scene *and* it's not the last one)
                if i < len(transcription_segments) - 1 and not (i == len(transcription_segments) - 1 and seg_text in current_scene_text_list) : 
                    # If the current segment (seg) caused overflow and wasn't the last one, it starts the new scene.
                    current_scene_text_list = [seg_text]
                    current_scene_start_time = seg_start
                    current_scene_accumulated_duration = seg_duration
                else: # Last segment was processed and included, or current segment was included.
                    current_scene_text_list = []
                    current_scene_accumulated_duration = 0
                    # next scene start time will be set by the next segment that isn't skipped
            
            else: # Segment fits or scene is empty, so add it
                if not current_scene_text_list: # If this is the first segment for the current_scene
                    current_scene_start_time = seg_start
                current_scene_text_list.append(seg_text)
                current_scene_accumulated_duration += seg_duration
                 
        # Safety check for any remaining text (should be covered by last segment logic)
        if current_scene_text_list:
            scene_text_final = " ".join(current_scene_text_list)
            scene_end_time = current_scene_start_time + current_scene_accumulated_duration
            timed_scenes.append({
                'index': scene_idx,
                'text': scene_text_final.strip(),
                'start': current_scene_start_time,
                'end': scene_end_time,
                'duration': current_scene_accumulated_duration
            })

        logger.info(f"Transcripci√≥n segmentada en {len(timed_scenes)} escenas basadas en duraci√≥n objetivo de {target_duration:.2f}s.")
        return timed_scenes

    def _segment_script_by_paragraphs(self, script_text: str) -> List[str]:
        """Divide el gui√≥n en p√°rrafos usando saltos de l√≠nea dobles."""
        paragraphs = re.split(r'\n\s*\n', script_text)
        return [p.strip() for p in paragraphs if p.strip()]

    def _create_semantic_scenes(self, transcription_segments: List[Dict], target_duration: float = 12.0) -> List[Dict]:
        """
        Crea escenas sem√°nticamente coherentes con subdivisi√≥n inteligente.
        
        L√ìGICA:
        1. Detecta unidades narrativas completas
        2. Si unidad > 20-25s ‚Üí subdividir en momentos visuales de 10-12s
        3. Mantiene sincronizaci√≥n exacta con audio
        """
        if not transcription_segments:
            return []
        
        # PAR√ÅMETROS AJUSTADOS
        MAX_NARRATIVE_UNIT = 20.0  # M√°ximo para unidad narrativa (20-25s l√≠mite)
        TARGET_IMAGE_DURATION = 11.0  # Duraci√≥n ideal por imagen (10-12s)
        MAX_IMAGE_DURATION = 15.0   # M√°ximo absoluto por imagen
        MIN_NARRATIVE_DURATION = 8.0  # M√≠nimo para considerar subdivisi√≥n
        
        logger.info(f"Creando escenas con subdivisi√≥n inteligente:")
        logger.info(f"  ‚Ä¢ Unidad narrativa m√°xima: {MAX_NARRATIVE_UNIT}s")
        logger.info(f"  ‚Ä¢ Duraci√≥n objetivo por imagen: {TARGET_IMAGE_DURATION}s")
        logger.info(f"  ‚Ä¢ Duraci√≥n m√°xima por imagen: {MAX_IMAGE_DURATION}s")
        
        # PASO 1: Detectar unidades narrativas completas
        narrative_units = self._detect_narrative_units(transcription_segments, MAX_NARRATIVE_UNIT)
        
        # PASO 2: Procesar cada unidad narrativa
        final_scenes = []
        
        for unit_idx, unit in enumerate(narrative_units):
            unit_duration = unit['duration']
            unit_text = unit['text']
            
            logger.info(f"Unidad {unit_idx+1}: {unit_duration:.1f}s - {unit_text[:60]}...")
            
            # Si la unidad es corta, usar como una sola escena
            if unit_duration <= MAX_NARRATIVE_UNIT:
                final_scenes.append({
                    "index": len(final_scenes),
                    "text": unit_text,
                    "start": unit['start'],
                    "end": unit['end'],
                    "duration": unit_duration,
                    "narrative_unit": unit_idx + 1,
                    "visual_moment": 1
                })
                logger.info(f"  ‚Üí Escena √∫nica ({unit_duration:.1f}s)")
            
            else:
                # Unidad larga: subdividir en momentos visuales
                logger.info(f"  ‚Üí Subdividiendo unidad larga ({unit_duration:.1f}s)")
                visual_moments = self._create_visual_moments(unit, TARGET_IMAGE_DURATION, MAX_IMAGE_DURATION)
                
                for moment_idx, moment in enumerate(visual_moments):
                    final_scenes.append({
                        "index": len(final_scenes),
                        "text": moment['text'],
                        "start": moment['start'],
                        "end": moment['end'],
                        "duration": moment['duration'],
                        "narrative_unit": unit_idx + 1,
                        "visual_moment": moment_idx + 1
                    })
                    logger.info(f"    ‚Ä¢ Momento {moment_idx+1}: {moment['duration']:.1f}s - {moment['text'][:50]}...")
        
        logger.info(f"Resultado final: {len(final_scenes)} escenas visuales de {len(narrative_units)} unidades narrativas")
        return final_scenes

    def _detect_narrative_units(self, transcription_segments: List[Dict], max_unit_duration: float) -> List[Dict]:
        """
        Detecta unidades narrativas completas que pueden durar m√°s que una imagen individual.
        Una unidad narrativa es una secuencia de eventos que deben mantenerse juntos conceptualmente.
        """
        if not transcription_segments:
            return []
        
        units = []
        current_unit_text = []
        current_unit_start = transcription_segments[0]['start']
        current_unit_duration = 0.0
        
        logger.info(f"Detectando unidades narrativas (m√°x: {max_unit_duration}s)...")
        
        for i, segment in enumerate(transcription_segments):
            segment_text = segment['text'].strip()
            segment_duration = segment['end'] - segment['start']
            
            # Agregar segmento a la unidad actual
            current_unit_text.append(segment_text)
            current_unit_duration = segment['end'] - current_unit_start
            
            # Determinar si es momento de cerrar la unidad narrativa
            is_narrative_break = self._is_strong_narrative_break(segment_text, current_unit_text)
            is_too_long = current_unit_duration >= max_unit_duration
            is_last_segment = i == len(transcription_segments) - 1
            
            should_close_unit = False
            close_reason = ""
            
            if is_last_segment:
                should_close_unit = True
                close_reason = "√∫ltimo segmento"
            elif is_too_long:
                should_close_unit = True  
                close_reason = f"duraci√≥n m√°xima ({current_unit_duration:.1f}s)"
            elif is_narrative_break and current_unit_duration >= 8.0:  # Solo si ya tiene contenido suficiente
                should_close_unit = True
                close_reason = "ruptura narrativa fuerte"
            
            if should_close_unit:
                unit_text = " ".join(current_unit_text).strip()
                if unit_text:
                    units.append({
                        "text": unit_text,
                        "start": current_unit_start,
                        "end": segment['end'],
                        "duration": current_unit_duration,
                        "segments_count": len(current_unit_text)
                    })
                    logger.debug(f"  Unidad {len(units)}: {current_unit_duration:.1f}s ({close_reason})")
                
                # Iniciar nueva unidad (si no es el √∫ltimo)
                if not is_last_segment:
                    current_unit_text = []
                    current_unit_start = segment['end']
                    current_unit_duration = 0.0
        
        logger.info(f"Detectadas {len(units)} unidades narrativas")
        return units

    def _is_strong_narrative_break(self, current_segment: str, unit_text_so_far: List[str]) -> bool:
        """
        Detecta rupturas narrativas FUERTES que justifican cerrar una unidad narrativa completa.
        M√°s estricto que _is_narrative_break para evitar cortes prematuros.
        """
        if not unit_text_so_far or len(unit_text_so_far) < 3:  # Necesita al menos 3 segmentos
            return False
            
        current_text = current_segment.lower().strip()
        
        # INDICADORES DE RUPTURA NARRATIVA FUERTE
        strong_break_indicators = [
            # Cambios temporales grandes
            "a√±os despu√©s", "tiempo despu√©s", "m√°s tarde", "al d√≠a siguiente",
            "en otra ocasi√≥n", "posteriormente", "tiempo m√°s tarde",
            
            # Cambios de escenario grandes  
            "en otro lugar", "en otra ciudad", "mientras tanto en",
            "en una ciudad diferente", "lejos de all√≠",
            
            # Nuevas secuencias narrativas
            "la historia contin√∫a", "ahora", "por otro lado", "sin embargo",
            "pero la historia", "mientras esto ocurr√≠a",
            
            # Transiciones de biograf√≠a/narraci√≥n
            "la vida de", "su biograf√≠a", "su historia", "el relato",
            "imagina que", "transport√©monos", "veamos ahora",
            
            # Conclusiones/cierres
            "finalmente", "en conclusi√≥n", "para terminar", "cerramos",
            "el resultado", "as√≠ fue como"
        ]
        
        # INDICADORES DE CONTINUIDAD FUERTE (previenen corte)
        strong_continuity_indicators = [
            # Acciones f√≠sicas en progreso
            "sujeta en sus brazos", "llevaba en brazos", "caminaba con",
            "mientras caminaba", "al mismo tiempo", "en ese momento",
            
            # Secuencias de di√°logo
            "le dijo", "respondi√≥", "pregunt√≥", "exclam√≥", "murmur√≥",
            "entonces √©l", "entonces ella", "luego a√±adi√≥",
            
            # Descripciones f√≠sicas continuas
            "su rostro", "sus manos", "sus ojos", "su cuerpo",
            "golpeando", "respirando", "llorando", "gritando"
        ]
        
        # Verificar continuidad fuerte
        has_strong_continuity = any(indicator in current_text for indicator in strong_continuity_indicators)
        
        # Verificar ruptura fuerte
        has_strong_break = any(indicator in current_text for indicator in strong_break_indicators)
        
        # DECISI√ìN: Solo romper si hay ruptura fuerte Y no hay continuidad fuerte
        if has_strong_continuity:
            logger.debug(f"    üîó Continuidad fuerte detectada - NO romper unidad")
            return False
        elif has_strong_break:
            logger.debug(f"    ‚úÇÔ∏è Ruptura fuerte detectada - Cerrar unidad narrativa")
            return True
        else:
            logger.debug(f"    ‚û°Ô∏è Sin indicadores fuertes - Continuar unidad")
            return False

    def _create_visual_moments(self, narrative_unit: Dict, target_duration: float, max_duration: float) -> List[Dict]:
        """
        Subdivide una unidad narrativa larga en momentos visuales de duraci√≥n apropiada.
        Mantiene coherencia sem√°ntica mientras respeta l√≠mites de duraci√≥n.
        """
        unit_text = narrative_unit['text']
        unit_start = narrative_unit['start']
        unit_end = narrative_unit['end']
        unit_duration = narrative_unit['duration']
        
        # Calcular n√∫mero √≥ptimo de momentos visuales
        num_moments = max(2, round(unit_duration / target_duration))
        moment_duration = unit_duration / num_moments
        
        # Ajustar si los momentos quedan demasiado largos
        if moment_duration > max_duration:
            num_moments = int(unit_duration / max_duration) + 1
            moment_duration = unit_duration / num_moments
        
        logger.info(f"    Subdividiendo en {num_moments} momentos de ~{moment_duration:.1f}s cada uno")
        
        # Dividir el texto en frases/segmentos l√≥gicos
        sentences = self._split_into_logical_segments(unit_text)
        
        # Distribuir frases entre momentos
        moments = []
        sentences_per_moment = max(1, len(sentences) // num_moments)
        
        for moment_idx in range(num_moments):
            start_idx = moment_idx * sentences_per_moment
            
            # Para el √∫ltimo momento, incluir todas las frases restantes
            if moment_idx == num_moments - 1:
                end_idx = len(sentences)
            else:
                end_idx = (moment_idx + 1) * sentences_per_moment
            
            moment_sentences = sentences[start_idx:end_idx]
            moment_text = " ".join(moment_sentences).strip()
            
            # Calcular tiempos basados en proporci√≥n
            moment_start = unit_start + (moment_idx * moment_duration)
            moment_end = unit_start + ((moment_idx + 1) * moment_duration)
            
            # Ajustar el √∫ltimo momento para que termine exactamente con la unidad
            if moment_idx == num_moments - 1:
                moment_end = unit_end
            
            actual_duration = moment_end - moment_start
            
            if moment_text:  # Solo agregar si hay texto
                moments.append({
                    "text": self._enhance_visual_moment_text(moment_text, moment_idx + 1, num_moments),
                    "start": moment_start,
                    "end": moment_end,
                    "duration": actual_duration
                })
        
        return moments

    def _split_into_logical_segments(self, text: str) -> List[str]:
        """
        Divide el texto en segmentos l√≥gicos para distribuir entre momentos visuales.
        """
        import re
        
        # Dividir por puntos, pero mantener frases completas
        sentences = re.split(r'(?<=[.!?])\s+', text)
        
        # Limpiar y filtrar
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # Si hay muy pocas frases, dividir por comas
        if len(sentences) < 3:
            segments = re.split(r',\s+', text)
            sentences = [s.strip() for s in segments if s.strip()]
        
        return sentences

    def _enhance_visual_moment_text(self, text: str, moment_num: int, total_moments: int) -> str:
        """
        Mejora el texto del momento visual para generar mejores prompts de imagen.
        Agrega contexto visual espec√≠fico seg√∫n la posici√≥n en la secuencia.
        """
        # Agregar descriptores visuales seg√∫n la posici√≥n
        if moment_num == 1 and total_moments > 1:
            # Primer momento: establecer escena
            if "madre" in text.lower():
                text += " [Enfoque inicial en la expresi√≥n de desesperaci√≥n]"
            elif "blas" in text.lower() and "camina" in text.lower():
                text += " [Vista de apertura de la escena]"
        elif moment_num == total_moments and total_moments > 1:
            # √öltimo momento: momento culminante
            if "ni√±o" in text.lower() or "hijo" in text.lower():
                text += " [Close-up del momento cr√≠tico]"
            elif "milagro" in text.lower() or "san√≥" in text.lower():
                text += " [Momento clim√°tico de la curaci√≥n]"
        
        return text

    def _align_paragraphs_to_transcription(self, paragraphs: List[str], transcription_segments: List[Dict]) -> List[Dict]:
        """
        NUEVO: Usa segmentaci√≥n sem√°ntica en lugar de alineaci√≥n compleja con fuzzywuzzy.
        Esto es m√°s confiable y siempre produce escenas sincronizadas.
        """
        logger.info("Usando segmentaci√≥n sem√°ntica inteligente (sin fuzzywuzzy)")
        
        # Calcular duraci√≥n objetivo basada en el n√∫mero de p√°rrafos
        if not transcription_segments:
            return []
        
        total_duration = transcription_segments[-1]['end'] - transcription_segments[0]['start']
        num_paragraphs = len([p for p in paragraphs if p.strip()])
        target_duration = total_duration / max(num_paragraphs, 1) if num_paragraphs > 0 else 12.0
        
        # Ajustar duraci√≥n objetivo para que sea razonable (8-15 segundos)
        target_duration = max(8.0, min(target_duration, 15.0))
        
        logger.info(f"Duraci√≥n objetivo por escena: {target_duration:.1f}s (total: {total_duration:.1f}s, p√°rrafos: {num_paragraphs})")
        
        # Crear escenas sem√°nticas
        return self._create_semantic_scenes(transcription_segments, target_duration)
    
    def generate_scenes_from_script(self, script_content: str, transcription_segments: List[Dict], mode: str, project_info: Dict, image_prompt_config: Dict, ai_service: AIServices) -> List[Dict]:
        """Genera escenas con el nuevo modo h√≠brido por p√°rrafos y una subdivisi√≥n robusta."""
        logger.info(f"Generando escenas con modo: '{mode}'...")
        
        if mode == "Por P√°rrafos (H√≠brido)":
            # --- L√ìGICA POR P√ÅRRAFOS (H√çBRIDA) ---
            paragraphs = self._segment_script_by_paragraphs(script_content)
            timed_scenes = self._align_paragraphs_to_transcription(paragraphs, transcription_segments)
            
            final_scenes_base = []
            for scene in timed_scenes:
                # --- INICIO DE LA L√ìGICA CORREGIDA ---
                if scene['duration'] > MAX_SCENE_DURATION:
                    logger.info(f"Escena {scene['index']} es muy larga ({scene['duration']:.1f}s > {MAX_SCENE_DURATION}s). Subdividiendo de forma robusta.")

                    # 1. Encontrar todos los segmentos de la transcripci√≥n que pertenecen a esta escena larga.
                    # Se usa una l√≥gica de solapamiento para no perder ning√∫n segmento.
                    scene_segments = [
                        seg for seg in transcription_segments
                        if seg['start'] < scene['end'] and seg['end'] > scene['start']
                    ]

                    if not scene_segments:
                        logger.warning(f"No se encontraron segmentos para la escena larga {scene['index']}, no se puede subdividir. Se usar√° como est√°.")
                        scene_copy = scene.copy()
                        scene_copy["index"] = len(final_scenes_base)
                        final_scenes_base.append(scene_copy)
                        continue

                    # 2. Determinar en cu√°ntas sub-escenas dividir.
                    # Se apunta a una duraci√≥n ideal un poco menor que el m√°ximo.
                    target_sub_duration = MAX_SCENE_DURATION * 0.9
                    num_sub_scenes = max(2, round(scene['duration'] / target_sub_duration))

                    # 3. Dividir la *lista de segmentos* en N grupos.
                    # Esto garantiza que todos los segmentos se distribuyen.
                    k, m = divmod(len(scene_segments), num_sub_scenes)
                    segment_groups = [scene_segments[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(num_sub_scenes)]

                    # 4. Crear sub-escenas a partir de los grupos de segmentos.
                    for group in segment_groups:
                        if not group:
                            continue

                        # El texto, inicio y fin se derivan directamente de los segmentos del grupo.
                        sub_scene_text = " ".join(s['text'].strip() for s in group)
                        sub_start_time = group[0]['start']
                        sub_end_time = group[-1]['end']
                        sub_duration = sub_end_time - sub_start_time

                        if sub_duration <= 0:
                            continue

                        final_scenes_base.append({
                            "index": len(final_scenes_base),
                            "text": sub_scene_text,
                            "start": sub_start_time,
                            "end": sub_end_time,
                            "duration": sub_duration
                        })
                # --- FIN DE LA L√ìGICA CORREGIDA ---
                else:
                    # La escena no es demasiado larga, se a√±ade directamente.
                    scene_copy = scene.copy()
                    scene_copy["index"] = len(final_scenes_base)
                    final_scenes_base.append(scene_copy)
            
            logger.info(f"Segmentaci√≥n por p√°rrafos result√≥ en {len(final_scenes_base)} escenas base.")
            
            # Generar prompts para estas escenas finales.
            final_scenes_with_prompts = self.generate_prompts_for_scenes(
                final_scenes_base, project_info, image_prompt_config, ai_service
            )
            logger.info(f"Se generaron prompts para {len(final_scenes_with_prompts)} escenas.")

            return final_scenes_with_prompts
        
        else:
            # Fallback a m√©todos anteriores (sin cambios)
            return self._generate_scenes_legacy(script_content, transcription_segments, mode)

    def _generate_scenes_legacy(self, script_content: str, transcription_segments: List[Dict], mode: str) -> List[Dict]:
        """M√©todos de segmentaci√≥n anteriores para compatibilidad."""
        if mode == "Por Duraci√≥n (Basado en Audio)":
            # L√≥gica original por duraci√≥n
            scenes = []
            for i, seg in enumerate(transcription_segments):
                scenes.append({
                    "index": i,
                    "text": seg['text'],
                    "start": seg['start'],
                    "end": seg['end'],
                    "duration": seg['end'] - seg['start']
                })
            return scenes
        else:
            # Autom√°tico (Texto) - dividir por p√°rrafos simples
            paragraphs = script_content.split('\n\n')
            scenes = []
            duration_per_scene = 10.0  # duraci√≥n fija
            
            for i, paragraph in enumerate(paragraphs):
                if paragraph.strip():
                    scenes.append({
                        "index": i,
                        "text": paragraph.strip(),
                        "start": i * duration_per_scene,
                        "end": (i + 1) * duration_per_scene,
                        "duration": duration_per_scene
                    })
            return scenes

    def generate_prompts_for_scenes(self, scenes: List[Dict], project_info: Dict, image_prompt_config: Dict, ai_service: AIServices) -> List[Dict]:
        """Genera prompts para las escenas con sistema de fallback robusto."""
        
        # üîç DEBUG INICIAL - CONFIGURACI√ìN RECIBIDA
        logger.info("=" * 100)
        logger.info("üîç DEBUG COMPLETO - INICIANDO GENERACI√ìN DE PROMPTS")
        logger.info("=" * 100)
        logger.info(f"üìä Proyecto: {project_info.get('titulo', 'Sin t√≠tulo')}")
        logger.info(f"üìä Total de escenas: {len(scenes)}")
        logger.info(f"üìä Configuraci√≥n inicial recibida:")
        prompt_obj_name = "No definido"
        if image_prompt_config.get('prompt_obj') and hasattr(image_prompt_config['prompt_obj'], 'get'):
            prompt_obj_name = image_prompt_config['prompt_obj'].get('nombre', 'Sin nombre')
        logger.info(f"  ‚Ä¢ prompt_obj inicial: {prompt_obj_name}")
        logger.info(f"  ‚Ä¢ historical_variables inicial: {image_prompt_config.get('historical_variables', 'No definidas')}")
        logger.info(f"  ‚Ä¢ providers: {image_prompt_config.get('img_prompt_providers_priority', ['gemini'])}")
        
        # üèõÔ∏è DETECCI√ìN AUTOM√ÅTICA DE CONTEXTO HIST√ìRICO
        logger.info("üèõÔ∏è Ejecutando detecci√≥n autom√°tica de contexto hist√≥rico...")
        original_config = image_prompt_config.copy()
        image_prompt_config = self._force_historical_prompt_if_needed(project_info, image_prompt_config)
        
        # DEBUG: Mostrar si cambi√≥ la configuraci√≥n
        if original_config != image_prompt_config:
            logger.info("‚úÖ Configuraci√≥n modificada por detecci√≥n autom√°tica")
            logger.info(f"  ‚Ä¢ Prompt nuevo: {image_prompt_config.get('prompt_obj', {}).get('nombre', 'No definido')}")
            logger.info(f"  ‚Ä¢ Variables hist√≥ricas aplicadas: {list(image_prompt_config.get('historical_variables', {}).keys())}")
        else:
            logger.info("‚ÑπÔ∏è Configuraci√≥n no modificada (ya era correcta o no aplicable)")
        
        # VERIFICACI√ìN CR√çTICA DEL AI_SERVICE
        if not ai_service:
            logger.error("üö® ai_service es None! No se pueden generar prompts de imagen.")
            for scene in scenes:
                scene['image_prompt'] = f"[ERROR] AIServices no disponible. Prompt b√°sico: {scene.get('text', '')[:350]}"
            return scenes
        
        prompt_obj = image_prompt_config.get('prompt_obj')
        provider_priority_list = image_prompt_config.get('img_prompt_providers_priority', ['gemini'])
        
        logger.info(f"üîç CONFIGURACI√ìN FINAL PARA GENERACI√ìN:")
        logger.info(f"  ‚Ä¢ prompt_obj: {prompt_obj.get('nombre', 'Sin nombre') if prompt_obj else 'None'}")
        logger.info(f"  ‚Ä¢ provider_priority_list: {provider_priority_list}")
        logger.info(f"  ‚Ä¢ ai_service disponible: {ai_service is not None}")
        logger.info(f"  ‚Ä¢ variables hist√≥ricas finales: {image_prompt_config.get('historical_variables', {})}")
        logger.info("=" * 100)
        
        if not prompt_obj:
            logger.warning("No se proporcion√≥ plantilla de prompt. Usando fallback simple.")
            for scene in scenes:
                scene['image_prompt'] = f"Photorealistic, cinematic: {scene.get('text', '')[:350]}"
            return scenes

        # üé≠ GENERACI√ìN DE DOSSIER DE PERSONAJE PARA COHERENCIA VISUAL (FASE 2)
        character_dossier = None
        if self._should_use_character_dossier(project_info):
            logger.info("üé≠ INICIANDO GENERACI√ìN DE DOSSIER PARA COHERENCIA VISUAL")
            character_dossier = self._generate_character_dossier(project_info, ai_service)
            if character_dossier:
                logger.info(f"‚úÖ Dossier generado exitosamente ({len(character_dossier)} caracteres)")
                logger.info("üé≠ Coherencia visual del personaje ACTIVADA para todas las escenas")
            else:
                logger.warning("‚ö†Ô∏è No se pudo generar el dossier, continuando sin coherencia de personaje")

        system_prompt = prompt_obj.get("system_prompt", "")
        user_prompt_template = prompt_obj.get("user_prompt", "Generate an image for: {scene_text}")

        for i, scene in enumerate(scenes):
            # Preparar todas las variables disponibles para el template
            template_variables = {
                'scene_text': scene['text'],
                'titulo': project_info.get("titulo", ""),
                'contexto': project_info.get("contexto", ""),
                'style': image_prompt_config.get('style', '')  # Variable de estilo
            }
            
            # üèõÔ∏è A√ëADIR VARIABLES HIST√ìRICAS SI EST√ÅN DISPONIBLES
            historical_variables = image_prompt_config.get('historical_variables', {})
            if historical_variables:
                # üîß VALIDAR VARIABLES HIST√ìRICAS - detectar si est√°n vac√≠as y usar detecci√≥n autom√°tica como fallback
                valid_historical_vars = {}
                empty_vars = []
                
                for key, value in historical_variables.items():
                    if value and str(value).strip():  # Variable tiene contenido
                        valid_historical_vars[key] = value
                    else:  # Variable vac√≠a
                        empty_vars.append(key)
                
                if valid_historical_vars:
                    template_variables.update(valid_historical_vars)
                    logger.info(f"[Escena {i+1}] üèõÔ∏è Variables hist√≥ricas v√°lidas a√±adidas: {list(valid_historical_vars.keys())}")
                
                if empty_vars:
                    logger.warning(f"[Escena {i+1}] ‚ö†Ô∏è Variables hist√≥ricas vac√≠as detectadas: {empty_vars}")
                    logger.info(f"[Escena {i+1}] ü§ñ Aplicando detecci√≥n autom√°tica para variables faltantes...")
                    
                    # Detectar contexto autom√°ticamente para variables faltantes
                    titulo = project_info.get("titulo", "")
                    auto_context = self._detect_historical_context_from_title(titulo)
                    
                    # Solo usar las variables autom√°ticas que estaban vac√≠as
                    filled_vars = []
                    for var in empty_vars:
                        if var in auto_context and auto_context[var]:
                            template_variables[var] = auto_context[var]
                            filled_vars.append(var)
                            logger.info(f"[Escena {i+1}] ü§ñ Variable '{var}' completada autom√°ticamente")
                    
                    if filled_vars:
                        logger.info(f"[Escena {i+1}] ‚úÖ Variables completadas autom√°ticamente: {filled_vars}")
                    else:
                        logger.warning(f"[Escena {i+1}] ‚ùå No se pudieron completar autom√°ticamente las variables vac√≠as")
            else:
                logger.debug(f"[Escena {i+1}] No hay variables hist√≥ricas disponibles")
            
            # Obtener las variables requeridas por la plantilla
            template_vars_required = prompt_obj.get('variables', [])
            
            # üé≠ INTEGRACI√ìN CON DOSSIER DE PERSONAJE (FASE 2)
            if character_dossier:
                logger.info(f"[Escena {i+1}] üé≠ APLICANDO COHERENCIA VISUAL DEL PERSONAJE")
                
                # Detectar edad del personaje en esta escena
                scene_text = scene.get('text', '')
                project_context = project_info.get('contexto', '')
                detected_age_stage = self._detect_character_age_stage(scene_text, project_context)
                
                # Extraer descripci√≥n espec√≠fica del dossier
                character_description = self._extract_character_description_from_dossier(character_dossier, detected_age_stage)
                
                if character_description:
                    # A√±adir la descripci√≥n del personaje como variable separada
                    template_variables['character_description'] = character_description
                    
                    logger.info(f"[Escena {i+1}] ‚úÖ Descripci√≥n del personaje aplicada")
                    logger.info(f"[Escena {i+1}] üéØ Edad detectada: {detected_age_stage.upper()}")
                    logger.info(f"[Escena {i+1}] üìù Descripci√≥n: {character_description[:100]}...")
                else:
                    # Si no hay descripci√≥n espec√≠fica, usar string vac√≠o para evitar errores
                    template_variables['character_description'] = ""
                    logger.warning(f"[Escena {i+1}] ‚ö†Ô∏è No se pudo extraer descripci√≥n para edad: {detected_age_stage}")
            else:
                # Si no hay dossier, usar string vac√≠o para la descripci√≥n del personaje
                template_variables['character_description'] = ""
            
            # Filtrar solo las variables que realmente necesita la plantilla
            filtered_variables = {
                var: template_variables.get(var, '') 
                for var in template_vars_required 
                if var in template_variables
            }
            
            # üèõÔ∏è LOGGING ESPECIAL PARA PROMPT HIST√ìRICO
            if prompt_obj.get('nombre') == "Escenas Fotorrealistas Hist√≥ricamente Precisas":
                logger.info(f"[Escena {i+1}] üèõÔ∏è PROMPT HIST√ìRICO DETECTADO")
                logger.info(f"[Escena {i+1}] üèõÔ∏è Variables hist√≥ricas: {historical_variables}")
                logger.info(f"[Escena {i+1}] üèõÔ∏è Variables filtradas: {filtered_variables}")
                
                # üé≠ LOGGING ESPECIAL PARA COHERENCIA DE PERSONAJE
                if character_dossier:
                    logger.info(f"[Escena {i+1}] üé≠ COHERENCIA DE PERSONAJE ACTIVA")
                    if 'character_description' in template_variables:
                        logger.info(f"[Escena {i+1}] üé≠ Descripci√≥n integrada en prompt hist√≥rico")
            
            try:
                user_prompt = user_prompt_template.format(**filtered_variables)
            except KeyError as e:
                logger.warning(f"[Escena {i+1}] Variable faltante en template: {e}. Usando template b√°sico.")
                user_prompt = f"Generate an image for: {scene['text']}"
            
            generated_prompt = None
            
            # üîç DEBUG COMPLETO DEL PROMPT
            logger.info(f"[Escena {i+1}] =" * 80)
            logger.info(f"[Escena {i+1}] üîç DEBUG COMPLETO - GENERACI√ìN DE PROMPT")
            logger.info(f"[Escena {i+1}] =" * 80)
            logger.info(f"[Escena {i+1}] üìã Prompt template: {prompt_obj.get('nombre', 'Sin nombre')}")
            logger.info(f"[Escena {i+1}] üîß Proveedores disponibles: {provider_priority_list}")
            logger.info(f"[Escena {i+1}] üìä Variables del template requeridas: {template_vars_required}")
            logger.info(f"[Escena {i+1}] ‚úÖ Variables filtradas disponibles: {list(filtered_variables.keys())}")
            logger.info(f"[Escena {i+1}] üèõÔ∏è Variables hist√≥ricas pasadas: {historical_variables}")
            
            # DEBUG: Mostrar cada variable y su valor
            logger.info(f"[Escena {i+1}] üìù VALORES DE VARIABLES:")
            for var_name, var_value in filtered_variables.items():
                logger.info(f"[Escena {i+1}]   ‚Ä¢ {var_name}: '{var_value[:100]}{'...' if len(str(var_value)) > 100 else ''}'")
            
            # DEBUG: Mostrar el system prompt completo
            logger.info(f"[Escena {i+1}] ü§ñ SYSTEM PROMPT ENVIADO A GEMINI:")
            logger.info(f"[Escena {i+1}] {'-' * 60}")
            logger.info(f"[Escena {i+1}] {system_prompt}")
            logger.info(f"[Escena {i+1}] {'-' * 60}")
            
            # DEBUG: Mostrar el user prompt completo
            logger.info(f"[Escena {i+1}] üë§ USER PROMPT ENVIADO A GEMINI:")
            logger.info(f"[Escena {i+1}] {'-' * 60}")
            logger.info(f"[Escena {i+1}] {user_prompt}")
            logger.info(f"[Escena {i+1}] {'-' * 60}")
            
            for provider in provider_priority_list:
                try:
                    logger.info(f"[Escena {i+1}] Intentando generar prompt con: {provider.upper()}")
                    
                    # Usar modelos espec√≠ficos si est√°n disponibles, sino usar por defecto
                    provided_models = image_prompt_config.get('img_prompt_models', {})
                    if provider in provided_models:
                        model = provided_models[provider]
                    else:
                        # Fallback a modelos por defecto
                        model_map = {
                            'gemini': 'models/gemini-2.5-flash-lite-preview-06-17',
                            'openai': 'gpt-3.5-turbo',
                            'ollama': 'llama3.2'
                        }
                        model = model_map.get(provider, 'default')
                    
                    logger.info(f"[Escena {i+1}] üîç DEBUG - Usando modelo: {model}")
                    logger.info(f"[Escena {i+1}] üîç DEBUG - Llamando ai_service.generate_content...")
                    
                    # A√±adir delay entre requests para evitar rate limits
                    if i > 0 and provider == "gemini":
                        delay = 0.5  # 500ms entre requests de Gemini
                        logger.info(f"[Escena {i+1}] ‚è±Ô∏è Delay de {delay}s para evitar rate limits...")
                        import time
                        time.sleep(delay)
                    
                    generated_text = ai_service.generate_content(
                        provider=provider, 
                        model=model, 
                        system_prompt=system_prompt, 
                        user_prompt=user_prompt
                    )
                    
                    # üîç DEBUG COMPLETO DE LA RESPUESTA
                    logger.info(f"[Escena {i+1}] ü§ñ RESPUESTA COMPLETA DE {provider.upper()}:")
                    logger.info(f"[Escena {i+1}] {'=' * 60}")
                    logger.info(f"[Escena {i+1}] Tipo: {type(generated_text)}")
                    logger.info(f"[Escena {i+1}] Longitud: {len(str(generated_text)) if generated_text else 0} caracteres")
                    logger.info(f"[Escena {i+1}] Contenido completo:")
                    logger.info(f"[Escena {i+1}] {'-' * 40}")
                    if generated_text:
                        # Mostrar respuesta completa con numeraci√≥n de l√≠neas
                        lines = str(generated_text).split('\n')
                        for line_num, line in enumerate(lines, 1):
                            logger.info(f"[Escena {i+1}] {line_num:3d}: {line}")
                    else:
                        logger.info(f"[Escena {i+1}] [RESPUESTA VAC√çA O NULA]")
                    logger.info(f"[Escena {i+1}] {'-' * 40}")
                    logger.info(f"[Escena {i+1}] {'=' * 60}")
                    
                    if generated_text and "[ERROR]" not in generated_text:
                        logger.info(f"[Escena {i+1}] ‚úÖ √âXITO con {provider.upper()}")
                        generated_prompt = generated_text.strip()
                        break
                    else:
                        logger.warning(f"[Escena {i+1}] ‚ùå FALLO con {provider.upper()}")
                        logger.warning(f"[Escena {i+1}] Motivo: {'Texto vac√≠o o nulo' if not generated_text else 'Contiene [ERROR]'}")
                except Exception as e:
                    logger.error(f"[Escena {i+1}] ‚ùå Fallo grave con {provider.upper()}: {e}. Intentando siguiente proveedor.")
            
            if not generated_prompt:
                logger.error(f"[Escena {i+1}] üö® Todos los proveedores fallaron. Usando prompt de emergencia. Texto de escena: {scene['text'][:100]}...")
                scene['image_prompt'] = f"Photorealistic, cinematic, high detail: {scene['text'][:350]}"
            else:
                scene['image_prompt'] = generated_prompt
            logger.info(f"[Escena {i+1}] Prompt final asignado: {scene['image_prompt'][:100]}...")
        
        return scenes

    # --- FUNCI√ìN HEREDADA PARA COMPATIBILIDAD ---
    def _generate_prompts_for_scenes(self, scenes: List[Dict], project_info: Dict, img_prompt_config: Dict, ai_service: AIServices) -> List[Dict]:
        """Funci√≥n heredada para compatibilidad con c√≥digo existente."""
        return self.generate_prompts_for_scenes(scenes, project_info, img_prompt_config, ai_service)

    def generate_scenes_and_prompts_from_text(self, script_content: str, project_info: Dict, image_prompt_config: Dict, ai_service: AIServices) -> List[Dict]:
        project_id_log = project_info.get('id', 'SCENE_TEXT')
        logger.info(f"[{project_id_log}] Generating scenes and prompts from TEXT...")

        # Get segmentation settings from video_gen_config -> script_segmentation or use defaults
        script_segmentation_config = self.video_gen_config.get('script_segmentation', {})
        max_chars_per_scene = script_segmentation_config.get('max_chars_per_scene', 350)
        split_on_double_newline = script_segmentation_config.get('split_on_double_newline', True)
        
        scenes_text = []
        if split_on_double_newline:
            paragraphs = [p.strip() for p in script_content.split('\n\n') if p.strip()]
            current_scene_text = ""
            for p_idx, p_text in enumerate(paragraphs):
                if not current_scene_text: # First paragraph for this scene
                    current_scene_text = p_text
                elif len(current_scene_text) + len(p_text) + 1 < max_chars_per_scene : # +1 for space
                    current_scene_text += " " + p_text
                else: # Paragraph doesn't fit, finalize current_scene_text
                    if current_scene_text: scenes_text.append(current_scene_text)
                    current_scene_text = p_text # Start new scene with current paragraph
            if current_scene_text: scenes_text.append(current_scene_text) # Add the last accumulated scene
        
        if not scenes_text: 
             scenes_text = [script_content[i:i+max_chars_per_scene] for i in range(0, len(script_content), max_chars_per_scene)]
        
        if not scenes_text and script_content: 
            scenes_text = [script_content]

        logger.info(f"[{project_id_log}] Script divided into {len(scenes_text)} text scenes.")
        
        scenes_base = []
        placeholder_duration = self.duration_per_image 
        for i, texto in enumerate(scenes_text):
             scenes_base.append({
                 'index': i,
                 'text': texto,
                 'start': i * placeholder_duration, 
                 'end': (i + 1) * placeholder_duration, 
                 'duration': placeholder_duration, 
                 'image_prompt': '' 
             })

        scenes_with_prompts = self.generate_prompts_for_scenes(scenes_base, project_info, image_prompt_config, ai_service)
        return scenes_with_prompts


    def generate_prompts_for_timed_scenes(self, transcription_segments: List[Dict], target_duration_per_scene: float, project_info: Dict, image_prompt_config: Dict, ai_service: AIServices) -> List[Dict]:
        project_id_log = project_info.get('id', 'SCENE_TIMED')
        logger.info(f"[{project_id_log}] Generating scenes and prompts from AUDIO transcription (Target duration/scene: {target_duration_per_scene:.2f}s)...")

        if not transcription_segments:
            logger.warning(f"[{project_id_log}] No transcription segments provided. Cannot generate timed scenes.")
            return []

        timed_scenes = self._segment_transcription_by_duration(transcription_segments, target_duration_per_scene)
        if not timed_scenes:
             logger.error(f"[{project_id_log}] Failed to create timed scenes from transcription.")
             return []

        scenes_with_prompts = self.generate_prompts_for_scenes(timed_scenes, project_info, image_prompt_config, ai_service)
        
        logger.info(f"[{project_id_log}] Generated {len(scenes_with_prompts)} timed scenes with prompts.")
        return scenes_with_prompts

    def save_scenes(self, scenes_data: List[Dict], output_path_str: str, project_info: Dict) -> str:
        output_path = Path(output_path_str)
        serializable_project_info = {
            k: v for k, v in project_info.items() 
            if isinstance(v, (str, int, float, bool, list, dict, type(None)))
        }
        
        total_duration_calculated = 0.0
        if scenes_data:
            last_scene = scenes_data[-1]
            if 'end' in last_scene and isinstance(last_scene['end'], (int, float)):
                total_duration_calculated = last_scene['end']
            else: # Fallback: sum durations if 'end' is not reliable on last scene
                total_duration_calculated = sum(
                    s.get('duration', 0.0) for s in scenes_data 
                    if isinstance(s.get('duration'), (int, float))
                )
        
        data_to_save = {
            'project_info_summary': { 
                'id': serializable_project_info.get('id'),
                'titulo': serializable_project_info.get('titulo'),
                'last_modified': datetime.datetime.now().isoformat()
            },
            'scenes': scenes_data,
            'generation_settings': {
                'source_type': project_info.get('scene_generation_mode', 'unknown'),
                'default_duration_per_image_setting': self.duration_per_image,
                'calculated_total_duration': total_duration_calculated
            }
        }
        
        try:
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            logger.info(f"Scene data saved to {output_path}")
        except TypeError as e:
            logger.error(f"TypeError during JSON serialization of scene data: {e}. Data snippet: {str(data_to_save)[:500]}", exc_info=True)
            try:
                simplified_data = {'scenes_count': len(scenes_data), 'error_type': type(e).__name__, 'error_message': str(e)}
                simplified_path = output_path.with_name(output_path.stem + "_serialization_error.json")
                with open(simplified_path, 'w', encoding='utf-8') as f_err:
                    json.dump(simplified_data, f_err, ensure_ascii=False, indent=2)
                logger.warning(f"Saved simplified error report for scene data to {simplified_path}")
            except Exception as e2:
                logger.error(f"Failed to save even a simplified error report for scene data: {e2}", exc_info=True)
        except Exception as e:
            logger.error(f"Unexpected error saving scene data to {output_path}: {e}", exc_info=True)
        
        return str(output_path)

    def _detect_historical_context_from_title(self, titulo: str) -> Dict[str, str]:
        """
        Detecta autom√°ticamente el contexto hist√≥rico basado en el t√≠tulo del proyecto.
        Retorna las variables hist√≥ricas apropiadas.
        """
        titulo_lower = titulo.lower().strip()
        
        # DEBUG: Mostrar proceso de detecci√≥n
        logger.info(f"üîç DEBUG - Detectando contexto hist√≥rico para: '{titulo}'")
        logger.info(f"üîç DEBUG - T√≠tulo normalizado: '{titulo_lower}'")
        
        # Base de datos de contextos hist√≥ricos conocidos
        historical_contexts = {
            "san blas": {
                "periodo_historico": "Siglo IV d.C. (circa 280-316 d.C.), Imperio Romano tard√≠o, era de las persecuciones cristianas bajo Diocleciano",
                "ubicacion": "Sebastea, Armenia hist√≥rica (actual Sivas, Turqu√≠a), regi√≥n monta√±osa del Asia Menor bajo dominio romano",
                "contexto_cultural": "Cristianismo primitivo bajo persecuci√≥n sistem√°tica del emperador Diocleciano, comunidades cristianas clandestinas, tradici√≥n m√©dica greco-romana, conflicto entre paganismo y cristianismo emergente"
            },
            "san bl√°s": {
                "periodo_historico": "Siglo IV d.C. (circa 280-316 d.C.), Imperio Romano tard√≠o, era de las persecuciones cristianas bajo Diocleciano",
                "ubicacion": "Sebastea, Armenia hist√≥rica (actual Sivas, Turqu√≠a), regi√≥n monta√±osa del Asia Menor bajo dominio romano",
                "contexto_cultural": "Cristianismo primitivo bajo persecuci√≥n sistem√°tica del emperador Diocleciano, comunidades cristianas clandestinas, tradici√≥n m√©dica greco-romana, conflicto entre paganismo y cristianismo emergente"
            },
            "napoleon": {
                "periodo_historico": "1796-1815, Era Napole√≥nica, Imperio Franc√©s, Consulado y Primer Imperio",
                "ubicacion": "Europa occidental y central, principalmente Francia, Austria, Prusia, Rusia, pen√≠nsula ib√©rica",
                "contexto_cultural": "Post-Revoluci√≥n Francesa, nacionalismo europeo emergente, c√≥digos napole√≥nicos, Ilustraci√≥n tard√≠a, guerras de coalici√≥n"
            },
            "maya": {
                "periodo_historico": "800-900 d.C., Per√≠odo Cl√°sico Tard√≠o Maya, colapso de las ciudades-estado",
                "ubicacion": "Tierras bajas mayas: Pet√©n guatemalteco, Yucat√°n, Belice, Chiapas, Honduras occidental",
                "contexto_cultural": "Civilizaci√≥n maya cl√°sica, sistema de ciudades-estado, escritura jerogl√≠fica, astronom√≠a avanzada, religi√≥n polite√≠sta, colapso ambiental"
            }
        }
        
        logger.info(f"üîç DEBUG - Contextos hist√≥ricos disponibles: {list(historical_contexts.keys())}")
        
        # Buscar coincidencias en el t√≠tulo
        for key, context in historical_contexts.items():
            logger.info(f"üîç DEBUG - Probando match con '{key}'")
            if key in titulo_lower:
                logger.info(f"‚úÖ MATCH ENCONTRADO - Contexto hist√≥rico detectado para '{titulo}': '{key}'")
                logger.info(f"‚úÖ CONTEXTO APLICADO:")
                logger.info(f"  ‚Ä¢ periodo_historico: {context['periodo_historico']}")
                logger.info(f"  ‚Ä¢ ubicacion: {context['ubicacion']}")
                logger.info(f"  ‚Ä¢ contexto_cultural: {context['contexto_cultural']}")
                return context
            else:
                logger.debug(f"üîç DEBUG - '{key}' no encontrado en '{titulo_lower}'")
        
        # Si no encuentra coincidencia, retornar contexto gen√©rico
        logger.warning(f"‚ùå NO MATCH - No se detect√≥ contexto hist√≥rico espec√≠fico para '{titulo}'. Usando contexto gen√©rico.")
        fallback_context = {
            "periodo_historico": "Per√≠odo hist√≥rico a determinar seg√∫n el contenido",
            "ubicacion": "Ubicaci√≥n geogr√°fica a determinar seg√∫n el contexto",
            "contexto_cultural": "Contexto cultural a determinar seg√∫n la √©poca y regi√≥n"
        }
        logger.warning(f"‚ö†Ô∏è CONTEXTO GEN√âRICO APLICADO: {fallback_context}")
        return fallback_context

    def _should_use_historical_prompt(self, titulo: str) -> bool:
        """
        Determina si un proyecto deber√≠a usar autom√°ticamente el prompt hist√≥rico
        basado en su t√≠tulo.
        """
        titulo_lower = titulo.lower().strip()
        
        # DEBUG: Mostrar t√≠tulo analizado
        logger.info(f"üîç DEBUG - Analizando t√≠tulo para detecci√≥n hist√≥rica: '{titulo}'")
        logger.info(f"üîç DEBUG - T√≠tulo normalizado: '{titulo_lower}'")
        
        # Palabras clave que indican contenido hist√≥rico/biogr√°fico
        historical_keywords = [
            "san ", "santa ", "santo ",  # Santos
            "napoleon", "alejandro", "cesar", "cleopatra",  # Figuras hist√≥ricas
            "maya", "azteca", "inca", "romano", "griego",  # Civilizaciones
            "medieval", "renacimiento", "barroco",  # Per√≠odos
            "vida de", "biograf√≠a", "historia de"  # Indicadores biogr√°ficos
        ]
        
        logger.info(f"üîç DEBUG - Keywords hist√≥ricos a buscar: {historical_keywords}")
        
        for keyword in historical_keywords:
            if keyword in titulo_lower:
                logger.info(f"‚úÖ MATCH ENCONTRADO - T√≠tulo '{titulo}' requiere prompt hist√≥rico (keyword: '{keyword}')")
                return True
            else:
                logger.debug(f"üîç DEBUG - Keyword '{keyword}' no encontrado en t√≠tulo")
        
        logger.info(f"‚ùå NO MATCH - T√≠tulo '{titulo}' NO requiere prompt hist√≥rico autom√°tico")
        return False

    def _force_historical_prompt_if_needed(self, project_info: Dict, image_prompt_config: Dict) -> Dict:
        """
        Fuerza el uso del prompt hist√≥rico si el proyecto lo requiere,
        incluso si no fue seleccionado manualmente.
        """
        titulo = project_info.get("titulo", "")
        
        if not self._should_use_historical_prompt(titulo):
            return image_prompt_config
        
        # Verificar si ya est√° usando el prompt hist√≥rico
        current_prompt = image_prompt_config.get("prompt_obj", {})
        if current_prompt and current_prompt.get("nombre") == "Escenas Fotorrealistas Hist√≥ricamente Precisas":
            logger.info(f"üèõÔ∏è Proyecto '{titulo}' ya usa prompt hist√≥rico correcto")
            
            # üîß IMPORTANTE: Incluso si ya usa el prompt hist√≥rico, verificar que tenga variables hist√≥ricas
            if not image_prompt_config.get("historical_variables"):
                logger.info(f"üèõÔ∏è Prompt hist√≥rico detectado pero sin variables hist√≥ricas. Aplicando detecci√≥n autom√°tica...")
                historical_context = self._detect_historical_context_from_title(titulo)
                new_config = image_prompt_config.copy()
                new_config["historical_variables"] = historical_context
                return new_config
            
            return image_prompt_config
        
        # Cargar el prompt hist√≥rico desde el archivo
        try:
            import json
            
            prompts_file = Path(__file__).parent.parent / "prompts" / "imagenes_prompts.json"
            with open(prompts_file, 'r', encoding='utf-8') as f:
                all_prompts = json.load(f)
            
            # Buscar el prompt hist√≥rico
            historical_prompt = None
            for prompt in all_prompts:
                if prompt.get("nombre") == "Escenas Fotorrealistas Hist√≥ricamente Precisas":
                    historical_prompt = prompt
                    break
            
            if not historical_prompt:
                logger.error("üö® No se encontr√≥ el prompt hist√≥rico en imagenes_prompts.json")
                return image_prompt_config
            
            # Detectar contexto hist√≥rico autom√°ticamente
            historical_context = self._detect_historical_context_from_title(titulo)
            
            # Crear nueva configuraci√≥n con prompt hist√≥rico COMPLETO
            new_config = image_prompt_config.copy()
            new_config["prompt_obj"] = historical_prompt  # Configuraci√≥n completa del archivo JSON
            new_config["historical_variables"] = historical_context
            
            logger.info(f"üèõÔ∏è FORZANDO prompt hist√≥rico para '{titulo}'")
            logger.info(f"üèõÔ∏è Prompt completo cargado: {historical_prompt.get('nombre')}")
            logger.info(f"üèõÔ∏è Variables requeridas: {historical_prompt.get('variables', [])}")
            logger.info(f"üèõÔ∏è Contexto aplicado: {historical_context}")
            
            return new_config
            
        except Exception as e:
            logger.error(f"‚ùå Error forzando prompt hist√≥rico: {e}")
            return image_prompt_config

    def _generate_character_dossier(self, project_info: Dict, ai_service: AIServices) -> Optional[str]:
        """
        Genera un dossier completo del personaje principal del proyecto.
        
        Args:
            project_info: Informaci√≥n del proyecto con titulo y contexto
            ai_service: Servicio de IA para generaci√≥n de contenido
            
        Returns:
            str: Dossier completo del personaje con secciones por edad, o None si falla
        """
        logger.info("üé≠ GENERANDO DOSSIER DE PERSONAJE PRINCIPAL")
        logger.info("=" * 60)
        
        # Verificar que tenemos la informaci√≥n b√°sica necesaria
        titulo = project_info.get("titulo", "")
        contexto = project_info.get("contexto", "")
        
        if not titulo or not contexto:
            logger.warning(f"‚ö†Ô∏è Informaci√≥n insuficiente para generar dossier")
            logger.warning(f"  ‚Ä¢ T√≠tulo: {'‚úì' if titulo else '‚úó'} ({titulo})")
            logger.warning(f"  ‚Ä¢ Contexto: {'‚úì' if contexto else '‚úó'} ({len(contexto)} chars)")
            return None
        
        # Cargar la plantilla de dossier
        try:
            import json
            prompts_file = Path(__file__).parent.parent / "prompts" / "imagenes_prompts.json"
            
            with open(prompts_file, 'r', encoding='utf-8') as f:
                all_prompts = json.load(f)
            
            # Buscar la plantilla de dossier
            dossier_template = None
            for prompt in all_prompts:
                if prompt.get("nombre") == "Dossier de Personaje Principal":
                    dossier_template = prompt
                    break
            
            if not dossier_template:
                logger.error("‚ùå No se encontr√≥ la plantilla 'Dossier de Personaje Principal'")
                return None
                
            logger.info(f"‚úÖ Plantilla de dossier cargada exitosamente")
            
        except Exception as e:
            logger.error(f"‚ùå Error cargando plantilla de dossier: {e}")
            return None
        
        # Preparar variables para la plantilla
        template_variables = {
            'titulo': titulo,
            'contexto': contexto
        }
        
        # Formatear prompts con las variables
        system_prompt = dossier_template.get("system_prompt", "")
        user_prompt_template = dossier_template.get("user_prompt", "")
        
        try:
            user_prompt = user_prompt_template.format(**template_variables)
        except KeyError as e:
            logger.error(f"‚ùå Variable faltante en plantilla de dossier: {e}")
            return None
        
        # Configuraci√≥n para generaci√≥n
        provider_priority = ['gemini', 'openai', 'ollama']  # Priorizar Gemini para mejor calidad
        
        logger.info(f"ü§ñ GENERANDO DOSSIER:")
        logger.info(f"  ‚Ä¢ Proyecto: {titulo}")
        logger.info(f"  ‚Ä¢ Proveedores: {provider_priority}")
        logger.info(f"  ‚Ä¢ Contexto: {len(contexto)} caracteres")
        
        # DEBUG: Mostrar prompts que se enviar√°n
        logger.info(f"üîç SYSTEM PROMPT PARA DOSSIER:")
        logger.info(f"{'-' * 40}")
        logger.info(f"{system_prompt}")
        logger.info(f"{'-' * 40}")
        
        logger.info(f"üîç USER PROMPT PARA DOSSIER:")
        logger.info(f"{'-' * 40}")
        logger.info(f"{user_prompt}")
        logger.info(f"{'-' * 40}")
        
        # Intentar generar dossier con cada proveedor
        for provider in provider_priority:
            try:
                logger.info(f"ü§ñ Intentando generar dossier con {provider.upper()}...")
                
                # Usar modelo espec√≠fico seg√∫n proveedor
                model_map = {
                    'gemini': 'models/gemini-2.5-flash-lite-preview-06-17',
                    'openai': 'gpt-3.5-turbo',
                    'ollama': 'llama3.2'
                }
                model = model_map.get(provider, 'default')
                
                # Generar dossier
                dossier_content = ai_service.generate_content(
                    provider=provider,
                    model=model,
                    system_prompt=system_prompt,
                    user_prompt=user_prompt
                )
                
                if dossier_content and len(str(dossier_content).strip()) > 100:
                    logger.info(f"‚úÖ DOSSIER GENERADO EXITOSAMENTE con {provider.upper()}")
                    logger.info(f"üìä Longitud del dossier: {len(str(dossier_content))} caracteres")
                    
                    # DEBUG: Mostrar preview del dossier
                    dossier_str = str(dossier_content)
                    preview_lines = dossier_str.split('\n')[:10]  # Primeras 10 l√≠neas
                    logger.info(f"üîç PREVIEW DEL DOSSIER GENERADO:")
                    logger.info(f"{'=' * 50}")
                    for i, line in enumerate(preview_lines, 1):
                        logger.info(f"{i:2d}: {line}")
                    if len(dossier_str.split('\n')) > 10:
                        logger.info(f"... (y {len(dossier_str.split('\n')) - 10} l√≠neas m√°s)")
                    logger.info(f"{'=' * 50}")
                    
                    return dossier_str
                else:
                    logger.warning(f"‚ö†Ô∏è Dossier vac√≠o o muy corto desde {provider}")
                    
            except Exception as e:
                logger.error(f"‚ùå Error generando dossier con {provider}: {e}")
                continue
        
        # Si llegamos aqu√≠, todos los proveedores fallaron
        logger.error(f"‚ùå FALL√ì LA GENERACI√ìN DE DOSSIER con todos los proveedores")
        logger.error(f"‚ùå Proveedores intentados: {provider_priority}")
        return None

    def _detect_character_age_stage(self, scene_text: str, project_context: str = "") -> str:
        """
        Detecta la etapa de edad del personaje principal en una escena espec√≠fica.
        
        Args:
            scene_text: Texto de la escena a analizar
            project_context: Contexto adicional del proyecto
            
        Returns:
            str: Etapa de edad detectada ('infancia', 'juventud', 'adultez', 'madurez')
        """
        logger.info(f"üîç DETECTANDO EDAD DEL PERSONAJE EN ESCENA")
        logger.info(f"üìù Texto de escena: {scene_text[:100]}...")
        
        # Normalizar texto para an√°lisis
        text_lower = scene_text.lower().strip()
        
        # Palabras clave por etapa de vida
        age_keywords = {
            'infancia': [
                'ni√±o', 'ni√±a', 'infancia', 'peque√±o', 'peque√±a', 'hijo', 'hija',
                'crianza', 'padres', 'familia', 'hogar paterno', 'juventud temprana',
                'nacimiento', 'nacer', 'naci√≥', 'crecer', 'criado', 'crianza',
                'a√±os de ni√±ez', 'desde peque√±o', 'siendo ni√±o', 'cuando era ni√±o'
            ],
            'juventud': [
                'joven', 'juventud', 'adolescente', 'estudios', 'aprendizaje', 
                'formaci√≥n', 'educaci√≥n', 'maestro', 'disc√≠pulo', 'estudiante',
                'vocaci√≥n', 'llamado', 'ordenaci√≥n', 'seminarista', 'noviciado',
                'a√±os de juventud', 'siendo joven', 'en su juventud', 'a√±os mozos'
            ],
            'adultez': [
                'adulto', 'maduro', 'obispo', 'sacerdote', 'ministerio', 'pastoral',
                'comunidad', 'liderazgo', 'responsabilidad', 'cargo', 'posici√≥n',
                'm√©dico', 'sanador', 'milagros', 'curaciones', 'servicio',
                'a√±os de ministerio', 'siendo obispo', 'como l√≠der', 'en la madurez'
            ],
            'madurez': [
                'anciano', 'mayor', 'vejez', 'sabidur√≠a', 'experiencia', 'veterano',
                'persecuci√≥n', 'martirio', 'sufrimiento', 'tortura', 'final',
                '√∫ltimos a√±os', 'muerte', 'morir', 'muri√≥', 'falleci√≥',
                'al final de su vida', 'en sus √∫ltimos d√≠as', 'anciano venerable'
            ]
        }
        
        # Contadores de coincidencias por etapa
        age_scores = {stage: 0 for stage in age_keywords.keys()}
        
        # Buscar palabras clave y acumular puntuaciones
        for stage, keywords in age_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    age_scores[stage] += 1
                    logger.debug(f"üîç Keyword '{keyword}' encontrada para etapa '{stage}'")
        
        # An√°lisis de contexto num√©rico (a√±os, edades espec√≠ficas)
        import re
        
        # Buscar referencias a edades espec√≠ficas
        age_patterns = [
            r'(\d+)\s*a√±os?',
            r'edad\s*de\s*(\d+)',
            r'(\d+)\s*a√±os?\s*de\s*edad',
            r'a\s*los\s*(\d+)',
            r'cuando\s*ten√≠a\s*(\d+)'
        ]
        
        found_ages = []
        for pattern in age_patterns:
            matches = re.findall(pattern, text_lower)
            found_ages.extend([int(age) for age in matches if age.isdigit()])
        
        # Si encontramos edades espec√≠ficas, ajustar puntuaciones
        if found_ages:
            for age in found_ages:
                logger.info(f"üî¢ Edad espec√≠fica detectada: {age} a√±os")
                if 0 <= age <= 12:
                    age_scores['infancia'] += 3
                elif 13 <= age <= 25:
                    age_scores['juventud'] += 3
                elif 26 <= age <= 50:
                    age_scores['adultez'] += 3
                elif age > 50:
                    age_scores['madurez'] += 3
        
        # Determinar etapa con mayor puntuaci√≥n
        detected_stage = max(age_scores, key=age_scores.get)
        max_score = age_scores[detected_stage]
        
        # Si no hay puntuaci√≥n clara, usar l√≥gica de fallback
        if max_score == 0:
            logger.warning(f"‚ö†Ô∏è No se detectaron indicadores de edad claros")
            
            # Fallback basado en contexto general
            if any(word in text_lower for word in ['obispo', 'ministerio', 'liderazgo']):
                detected_stage = 'adultez'
            elif any(word in text_lower for word in ['persecuci√≥n', 'martirio', 'muerte']):
                detected_stage = 'madurez'
            elif any(word in text_lower for word in ['estudios', 'formaci√≥n', 'vocaci√≥n']):
                detected_stage = 'juventud'
            else:
                detected_stage = 'adultez'  # Default para contextos neutrales
            
            logger.info(f"üîÑ Usando fallback: '{detected_stage}' basado en contexto")
        
        logger.info(f"üéØ RESULTADO DETECCI√ìN DE EDAD:")
        logger.info(f"  ‚Ä¢ Etapa detectada: {detected_stage.upper()}")
        logger.info(f"  ‚Ä¢ Puntuaciones: {age_scores}")
        logger.info(f"  ‚Ä¢ Edades espec√≠ficas: {found_ages}")
        
        return detected_stage

    def _extract_character_description_from_dossier(self, dossier: str, age_stage: str) -> str:
        """
        Extrae la descripci√≥n espec√≠fica del personaje para una etapa de edad del dossier.
        
        Args:
            dossier: Dossier completo del personaje
            age_stage: Etapa de edad ('infancia', 'juventud', 'adultez', 'madurez')
            
        Returns:
            str: Descripci√≥n espec√≠fica para la etapa, o descripci√≥n gen√©rica si no se encuentra
        """
        logger.info(f"üìã EXTRAYENDO DESCRIPCI√ìN PARA ETAPA: {age_stage.upper()}")
        
        if not dossier or not age_stage:
            logger.warning("‚ö†Ô∏è Dossier o etapa de edad vac√≠os")
            return ""
        
        # Mapeo de etapas a patrones de b√∫squeda en el dossier
        stage_patterns = {
            'infancia': [r'\*\*INFANCIA.*?\*\*.*?(?=\*\*[A-Z]|\Z)', r'INFANCIA.*?(?=\*\*[A-Z]|\Z)'],
            'juventud': [r'\*\*JUVENTUD.*?\*\*.*?(?=\*\*[A-Z]|\Z)', r'JUVENTUD.*?(?=\*\*[A-Z]|\Z)'],
            'adultez': [r'\*\*ADULTEZ.*?\*\*.*?(?=\*\*[A-Z]|\Z)', r'ADULTEZ.*?(?=\*\*[A-Z]|\Z)'],
            'madurez': [r'\*\*MADUREZ.*?\*\*.*?(?=\*\*[A-Z]|\Z)', r'MADUREZ.*?(?=\*\*[A-Z]|\Z)', 
                       r'\*\*VEJEZ.*?\*\*.*?(?=\*\*[A-Z]|\Z)', r'VEJEZ.*?(?=\*\*[A-Z]|\Z)']
        }
        
        import re
        
        # Buscar la secci√≥n correspondiente
        patterns = stage_patterns.get(age_stage, [])
        
        for pattern in patterns:
            matches = re.findall(pattern, dossier, re.DOTALL | re.IGNORECASE)
            if matches:
                description = matches[0].strip()
                
                # Limpiar la descripci√≥n
                description = re.sub(r'\*\*[^*]+\*\*', '', description)  # Remover encabezados
                description = re.sub(r'\s+', ' ', description).strip()   # Normalizar espacios
                
                # Filtrar l√≠neas vac√≠as y bullets
                lines = [line.strip() for line in description.split('\n') if line.strip()]
                clean_lines = []
                
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('*') and len(line) > 10:
                        # Remover bullets y limpiar
                        line = re.sub(r'^\*\s*', '', line)
                        line = re.sub(r'^\*\*.*?\*\*\s*', '', line)
                        if line:
                            clean_lines.append(line)
                
                final_description = ' '.join(clean_lines)
                
                if final_description and len(final_description) > 50:
                    logger.info(f"‚úÖ Descripci√≥n extra√≠da para '{age_stage}':")
                    logger.info(f"  ‚Ä¢ Longitud: {len(final_description)} caracteres")
                    logger.info(f"  ‚Ä¢ Preview: {final_description[:150]}...")
                    return final_description
        
        # Si no se encuentra la secci√≥n espec√≠fica, crear descripci√≥n gen√©rica
        logger.warning(f"‚ö†Ô∏è No se encontr√≥ secci√≥n espec√≠fica para '{age_stage}' en el dossier")
        
        # Extraer informaci√≥n general del dossier para crear descripci√≥n gen√©rica
        generic_description = self._create_generic_description_from_dossier(dossier, age_stage)
        
        logger.info(f"üîÑ Usando descripci√≥n gen√©rica para '{age_stage}':")
        logger.info(f"  ‚Ä¢ Longitud: {len(generic_description)} caracteres")
        logger.info(f"  ‚Ä¢ Preview: {generic_description[:150]}...")
        
        return generic_description

    def _create_generic_description_from_dossier(self, dossier: str, age_stage: str) -> str:
        """
        Crea una descripci√≥n gen√©rica basada en el contenido general del dossier.
        """
        # Extraer caracter√≠sticas f√≠sicas generales
        physical_keywords = ['cabello', 'ojos', 'complexi√≥n', 'estatura', 'rostro', 'facciones']
        clothing_keywords = ['t√∫nica', 'vestimenta', 'manto', 'sandalias']
        
        physical_traits = []
        clothing_traits = []
        
        dossier_lower = dossier.lower()
        
        for keyword in physical_keywords:
            if keyword in dossier_lower:
                # Buscar contexto alrededor de la palabra clave
                import re
                pattern = rf'.{{0,50}}{keyword}.{{0,50}}'
                matches = re.findall(pattern, dossier_lower)
                if matches:
                    physical_traits.extend(matches)
        
        for keyword in clothing_keywords:
            if keyword in dossier_lower:
                pattern = rf'.{{0,50}}{keyword}.{{0,50}}'
                matches = re.findall(pattern, dossier_lower)
                if matches:
                    clothing_traits.extend(matches)
        
        # Construir descripci√≥n gen√©rica
        base_description = f"Personaje en etapa de {age_stage}"
        
        if physical_traits:
            base_description += f", con {', '.join(physical_traits[:2])}"
        
        if clothing_traits:
            base_description += f", vistiendo {', '.join(clothing_traits[:2])}"
        
        return base_description

    def _should_use_character_dossier(self, project_info: Dict) -> bool:
        """
        Determina si un proyecto deber√≠a usar el sistema de dossier de personaje
        para mantener coherencia visual.
        
        Args:
            project_info: Informaci√≥n del proyecto
            
        Returns:
            bool: True si debe usar dossier, False caso contrario
        """
        titulo = project_info.get("titulo", "").lower().strip()
        contexto = project_info.get("contexto", "").lower().strip()
        
        # Palabras clave que indican contenido biogr√°fico/hist√≥rico con personaje principal
        biographical_keywords = [
            "vida de", "biograf√≠a", "historia de", "san ", "santa ", "santo ",
            "napoleon", "alejandro", "cesar", "cleopatra", "martin luther",
            "teresa", "ignacio", "francisco", "juan", "mar√≠a", "jos√©",
            "m√°rtir", "santo", "beato", "venerable"
        ]
        
        historical_keywords = [
            "hist√≥rico", "historia", "biograf√≠a", "documental biogr√°fico",
            "personaje hist√≥rico", "figura hist√≥rica"
        ]
        
        # Verificar si el t√≠tulo o contexto sugieren contenido biogr√°fico
        for keyword in biographical_keywords + historical_keywords:
            if keyword in titulo or keyword in contexto:
                logger.info(f"üé≠ Dossier requerido - Keyword detectada: '{keyword}'")
                return True
        
        # Verificar si ya usa prompt hist√≥rico (muy probable que necesite dossier)
        if self._should_use_historical_prompt(titulo):
            logger.info("üé≠ Dossier requerido - Proyecto usa prompt hist√≥rico")
            return True
        
        logger.info("üé≠ Dossier NO requerido - Proyecto no parece biogr√°fico/hist√≥rico")
        return False
